--- 
title: "BIOESTATÍSTICA USANDO O R"
author: "Petrônio Fagundes de Oliveira Filho"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---

# Dados

## O que são dado? 
Em qualquer lugar que depositarmos o nosso olhar, encontramos uma infinidade de dados e seus resumos estatísticos e interpretações. Por exemplo:  

**Exemplo 1.1: PIB dos EUA cai há dois trimestres**  
“Dados divulgados ontem pelo departamento de Comércio mostram  que o PIB caiu 0,9%, na comparação anualizada, e 0,2% em relação ao 1º trimestre” ^[Valor Econômico, Sexta-feira, 29 de julho de 2022, Ano 23, Número 5552]. A esta notícia segue-se a interpretação da Casa Branca de que a economia dos EUA não se encontra em uma recessão.  
Isso pode ser verdade? Aparentemente, é o desejo do presidente Biden. Não temos outras informações para melhor analisar os dados.  

**Exemplo 1.2:  Prevalência, mortalidade e fatores de risco associados aos nascimentos de prematuros**    Um estudo realizado em Pelotas, RS buscou verificar a prevalência, mortalidade e fatores de risco associados aos nascimentos de prematuros de muito baixo peso ao nascer (MBPN) ao longo de 33 anos^[Victora JD, Silveira MF, Tonial CT, Victora CG, Barros FC, Horta BL, et al. Prevalence, mortality and risk factors associated with very low birth weight preterm infants: an analysis of 33 years. J Pediatr (Rio J). 2020;96:327-32]. Este estudo incluiu uma série de quatro estudos transversais utilizando dados das entrevistas perinatais das coortes de nascimento da cidade de Pelotas coletados em 1982, 1993, 2004 e 2015, envolvendo19.625 recém-nascidos.  
Em 1982, 1993, 2004 e 2015 ocorreram, respectivamente, 5.909, 5.232, 4.226 e 4.258 nascimentos. A prevalência de prematuros de muito baixo peso ao nascer naqueles anos foi, respectivamente, de 1,1% (n = 64), 0,9% (n = 46), 1,4% (n = 61) e 1,3% (n = 54). A tendência de aumento durante o período não alcançou significância estatística (P = 0,11). Entre os fatores de risco, a renda familiar nos três quintis mais pobres esteve associada a prevalências cerca de duas vezes mais altas do que no quintil mais rico (p = 0,003). A mortalidade por 1.000 nascidos vivos para os neonatos com peso < 1500 g caiu de 688 para 259 por mil ao longo dos anos (p < 0,001), mas ainda representa 61% dos óbitos neonatais em 2015.
Aqui, temos uma pesquisa científica com dados relevantes em Saúde Pública.  

Como vemos, as pesquisas manuseiam dados. Cada conjunto de dados está relacionado às variáveis que estão sendo estudadas em uma pesquisa. [Variável](anchor) é toda característica ou condição de interesse que pode de ser mensurada ou observada em cada elemento de uma amostra ou população. Como o próprio nome diz, seus valores são passíveis variar de um indivíduo a outro ou no mesmo indivíduo. Em contraste com a variável, o valor de uma constante é fixo. As variáveis podem ter valores numéricos ou não numéricos. O resultado da mensuração ou observação de uma variável é denominado  [dado](anchor) .


## População e Amostra
Na pesquisa em saúde, a não ser quando se realiza um censo, coleta-se dados de um subconjunto de indivíduos denominado de [amostra](anchor), pertencente a um grupo maior, conhecido como [população](anchor). A população de interesse é, geralmente, chamada de [população-alvo](anchor). A amostra para ser representativa da população deve ter as mesmas características desta. A partir dos dados encontrados na amostra, presume-se o resultado é condizente com a população. Este processo é denominado de [inferência estatística](anchor). O interesse na amostra não está propriamente nela, mas na informação que ela fornece ao investigador sobre a população de onde ela provém. A amostra fornece estimativas (estatísticas) da população.  
Em decorrência do acaso, diferentes amostras de uma mesma população fornecem resultados diferentes. Este fato deve ser levado em consideração ao usar uma amostra para fazer inferência sobre uma população. Este fenômeno é denominado de [variação amostral](anchor) ou [erro amostral](anchor) e é a essência da estatística. O grau de certeza na inferência estatística depende da representatividade da amostra.   
O processo de obtenção da amostra é chamado de [amostragem](anchor). Mesmo que este processo seja adequado, a amostra nunca será uma cópia perfeita da população de onde ela foi extraída. Desta forma, em qualquer conclusão baseada em dados de uma amostra, sempre haverá o que é conhecido como erro amostral. Este erro deve ser tratado estatisticamente tendo em mente a teoria da amostragem, baseada em probabilidades.


## Estimativas e Parâmetros  

[Estimativa](anchor) é uma característica que resume os dados de uma amostra (estatística amostral) e o [parâmetro](anchor) é uma característica estabelecida para toda a população. Os valores dos parâmetros são normalmente desconhecidos, porque é inviável medir uma população inteira. A estimativa é um valor aproximado do parâmetro. As estimativas são representadas por letras romanas e os parâmetros por letras gregas (Tabela 1.1). Na maioria dos estudos, são utilizadas amostras que fornecem estimativas que, para serem representativas da população, devem ser probabilísticas. Ou seja, a amostra deve ser recrutada de forma aleatória, permitindo que cada um dos membros da população tenha a mesma probabilidade de ser incluído na amostra. Além disso, uma amostra deve ter um tamanho adequado para permitir inferências válidas.

**Tabela 1.1** Estimativas (estatísticas amostrais) e parâmetros.

Medidas | Estimativas | Parâmetros
:--- | :-----------:  | :--------:
Média | $\overline{x}$ | $\mu$
Desvio Padrão | *s* | $\sigma$
Variância | $s^2$ | $\sigma^2$
Proporção | $\hat{p}$ | $p$
Número de elementos | $n$  | $N$
      |  
      
## Escalas de medição
Em um estudo científico, há necessidade de registrar os dados para que eles representem acuradamente as variáveis observadas. Este registro de valores necessita de escalas de medição. [Mensuração](anchor) ou [medição](anchor) é o processo de atribuir números ou rótulos a objetos, pessoas, estados ou eventos de acordo com regras específicas para representar quantidades ou qualidades dos dados. Para a mensuração das variáveis são usadas as escalas nominal, ordinal, intervalar e de razão.

### Escala Nominal  
As escalas nominais são meramente classificativas, permitindo descrever as variáveis ou designar os sujeitos, sem recurso à quantificação. É o nível mais elementar de representação. São usados nomes, números ou outros símbolos para designar a variável. Os números, quando usados, representam códigos e como tal não permitem operações matemáticas. As variáveis nominais não podem ser ordenadas. Podem apenas ser comparadas utilizando as relações de igualdade ou de diferença, através de [contagens](anchor). Os números atribuídos às variáveis servem como identificação, ou para associá-la uma dada categoria. As categorias de uma escala nominal são exaustivas e mutuamente exclusivas.   
Quando existem duas categorias, a variável é dita dicotômica e com três ou mais categorias, politômicas. Os nomes e símbolos que designam as categorias podem ser intercambiáveis sem alterar a informação essencial.
*Exemplos*: Tipos sanguíneos: A, B, AB, O; variáveis dicotômicas: morto/vivo, homem/mulher, sim/não; cor dos olhos, etc.

### Escala Ordinal
As variáveis são medidas em uma escala ordinal quando ocorre uma ordem, crescente ou decrescente, inerente entre as categorias, estabelecida sob determinado critério. A diferença entre as categorias não é necessariamente igual e nem sempre mensuráveis. Geralmente, designam-se os valores de uma escala ordinal em termos de numerais ou postos (ranks), sendo estes apenas modos diferentes de expressar o mesmo tipo de dados. Também não faz sentido realizar operações matemática com variáveis ordinais. Pode-se continuar a usar contagem.
*Exemplos*: classe social (baixa, média, alta); estado geral do paciente: bom, regular, mau; estágios do câncer: 0, 1, 2, 3 e 4; escore de Apgar: 0, 1, 2... 10. 

### Escala Intervalar  
Uma escala intervalar contém todas as características das escalas ordinais com a diferença de que se conhece as distâncias entre quaisquer números. Em outras palavras, existe um espectro ordenado com intervalos quantificáveis. Este tipo de escala permite que se verifique a ordem e a diferença entre as variáveis, porém não tem um zero verdadeiro, o zero é arbitrário. 
O *exemplo* clássico é a mensuração da temperatura, usando as escalas de: Celsius ou Fahrenheit. Aqui é legítimo ordenar, fazer soma ou médias. No entanto, 0ºC não significa ausência de temperatura, portanto a operação divisão não é possível. Uma temperatura de 40ºC não é o dobro de 20ºC. Se 40ºC e 20ºC forem transformados para a escala Fahrenheit, passarão, respectivamente, para 104ºF e 68ºF e, sem dúvida, 104 não é o dobro de 68!  

### Escala de Razão  
Há um espectro ordenado com intervalos quantificáveis como na escala intervalar. Entretanto, as medidas iniciam a partir de um zero verdadeiro e a escala tem intervalos iguais, permitindo as comparações de magnitude entre os valores. Refletem a quantidade real de uma variável, permitindo qualquer operação matemática.  
Os dados tanto na escala intervalar como na de razão, podem ser contínuos ou discretos. Dados contínuos necessitam de instrumentos para a sua mensuração e assumem qualquer valor em um certo intervalo. Por exemplo, o tempo para terminar qualquer tarefa pode assumir qualquer valor, 10 min, 20 min, 35 min, etc., de acordo com o tipo de tarefa. Outros exemplos: peso, dosagem de colesterol, glicemia. Dados discretos possuem valores iguais a números inteiros, não existindo valores intermediários. A mensuração é feita através da contagem. Por exemplo: número de filhos, número de fraturas, número de pessoas.  

## Tipos de Variáveis  

A primeira etapa na descrição e análise dos dados é classificar as variáveis, pois a apresentação dos dados e os métodos estatísticos variam de acordo com os seus tipos.   As variáveis, primariamente, podem ser divididas em dois tipos: numéricas ou quantitativas e categóricas ou qualitativas.   

### Variáveis Numéricas  

As variáveis numéricas são classificadas em dois tipos de acordo com a escala de mensuração: continuas e discretas.  
As [variáveis contínuas](anchor) são aquelas cujos dados foram mensurados em uma escala intervalar ou de razão, podendo assumir como visto, qualquer valor dentro de um intervalo de números reais, dependendo da precisão do instrumento de medição. O tratamento estatístico tanto para variável intervalar como de a razão é o mesmo. A diferença entre elas está na presença do zero absoluto. As variáveis numéricas contínuas têm unidade de medida. Por exemplo, um menino de 4 anos tem 104 cm.
Uma variável numérica é considerada [discreta](anchor) quando é apenas possível quantificar os resultados possíveis através do processo de contagem. Também têm unidades de medida – “número de elementos”.  

### Variáveis Categóricas  

As variáveis categóricas ou qualitativas são de dois tipos: nominal e ordinal, de acordo com a escala de mensuração. Um tipo particularmente comum é uma variável binária (também conhecida como variável dicotômica), que tem apenas dois valores possíveis. Por exemplo, o sexo é masculino ou feminino. Este tipo de variável é bastante utilizado na área da saúde, em Epidemiologia. As variáveis nominais não têm quaisquer unidades de medida e a nominação das categorias é completamente arbitrária e pertencer a uma categoria não significa ter maior importância do que pertencer à outra.  
Uma variável é dita ordinal quando ocorre uma ordem inerente ou hierarquia entre as categorias. Do mesmo modo que as variáveis nominais, as variáveis ordinais não têm unidades de medida. Entretanto, a ordenação das categorias não é arbitrária. Assim, é possível ordená-las de modo lógico. Um exemplo comum de uma variável categórica ordinal é a classe social, que tem um ordenamento natural da maioria dos mais desfavorecidos para os mais ricos. As escalas, como a escore de Apgar e a escala de coma de Glasgow, também são variáveis ordinais. Mesmo que pareçam numéricas, elas apenas mostram uma ordem no estado dos pacientes. O escore de Apgar é uma escala, desenvolvida para a avaliação clínica do recém-nascido imediatamente após o nascimento. Originalmente, a escala foi usada para avaliar a adaptação imediata do recém-nascido à vida extrauterina. A pontuação pode variar de zero a 10. Uma pontuação igual ou maior do que oito, indica um recém-nascido normal. Uma pontuação de sete ou menos pode significar depressão do sistema nervoso e abaixo de quatro, depressão grave. 
As variáveis ordinais, da mesma forma que as nominais, não são números reais e não convém aplicar as regras da aritmética básica para estes tipos de dados. Este fato gera uma limitação na análise dos dados.  

## Variáveis dependentes e independentes  

De um modo geral as pesquisas são realizadas para testar as hipóteses dos pesquisadores e, para isso, eles medem variáveis com a finalidade de compará-las. A maioria das hipóteses podem ser expressas por duas variáveis: uma variável explicativa ou preditora e uma variável desfecho. 
A [variável preditora](anchor) ou explanatória é a que se acredita ser a causa e também é conhecida como variável independente, porque o seu valor não depende de outras variáveis. Em Epidemiologia, é com frequência referida como exposição ou fator de risco. A [variável desfecho](anchor) é aquela que é o efeito, consequência ou resultado da ação de outra variável, por isso, também chamada de variável dependente. Em estudo que tenta verificar se o tabagismo, durante a gestação, pode interferir no peso do recém-nascido, tem o fumo (variável categórica) como variável preditora (exposição ou fator de risco) e o peso do recém-nascido (variável numérica contínua) como variável desfecho.  

## Leitura Adicional  

1.	Altman DG. **Practical Statistics for Medical Research**. London: Chapman & Hall/CRC; 1991. Types of data; p.10-8.
2.	Kirkwood BR, Sterne JAC. **Essential Medical Statistics**. Fourth Edition. Oxford: Blackwell Science Ltd; 2003. Defining the data; p.9-14.
3.	Oliveira Filho PF. **Epidemiologia e Bioestatística: fundamentos para a leitura crítica**. 2ª ed. Rio de Janeiro: Editora Rubio Ltda; 2022. Natureza dos dados;p.3-6.


</br>
</br>


<!--chapter:end:index.Rmd-->

# Ambiente do R

## Instalação do software R no Windows

O R é o programa "cérebro" necessário para as análises de dados que serão realizadas. Este tutorial visa auxiliar na instalação. Assista o [vídeo](https://www.youtube.com/watch?v=xxmqTA8MkCA) e/ou use o tutorial como guia.

* Baixe a última versão do instalador do **R** diretamente do repositório oficial, usando o [link](<https://cran.r-project.org/bin/windows/base/>).  
* Após clicar em <span style="color:blue"> Download R 4.2.1 for Windows </span> (última versão do **R**, nesta data), você deve salvar o arquivo `R-4.2.1-win.exe` em qualquer diretório (eu uso: `"C:\Users\T.S\Downloads\R-4.2.1-win.exe"`. Ao fazer isso,  aparece na tela de seu computador,no canto esquerdo, em baixo, o arquivo salvo. Execute este arquivo com um clique sobre ele.  
* Aparecerá na tela uma imagem perguntando <span style="color:green">"Deseja permitir que este aplicativo faça alterações no seu dispositivo?"</span>. Clique em <span style="color:blue"> Sim </span>.
* A seguir o Instalador pedirá para escolher o Idioma. Selecione Português Brasileiro.  
* Em sequência aparecerão informações sobre o diretório no qual o **R** será instalado em seu computador. Recomenda-se aceitar a configuração padrão sugerida pelo instalador do software.  
* A próxima janela pedirá para personalizar os componentes que serão instalados. Recomenda-se usar as configurações sugeridas pelo instalador que irá reconhecer automaticamente.  
* A partir daqui, siga as recomendações padrão propostas pelo instalador até completar a instalação, clicando em <span style="color:blue"> Concluir </span> (Figura 1).


$~$
<center>

![Figura 1. Término da Instalação](https://i.imgur.com/6rOqk1d.png) 
 
</center> 
$~$
 
*** 
## Instalação do R Studio no Windows

Siga os seguintes passos para a instalação do **R Studio** que é o "gerente" e "porta voz" do **R**. O tutorial do vídeo também mostra os passos a serem realizados.

* Clique sobre este [link](https://www.rstudio.com/products/rstudio/download/#download) e realize o download para o seu sistema operacional do `RStudio-2022.07.1-554`, da mesma maneira que para o **R**.  
* Abra o arquivo executável baixado, no canto esquerdo embaixo.  
* Será repetida a mesma pergunta feita para o **R**. Clique <span style="color:blue"> Sim </span>.  
* Siga os passos apresentados pelo instalador, lendo com atenção. 
* Aguarde a conclusão da instalação e clique em <span style="color:blue"> Terminar </span>.  

Para verifcar se a instalação foi concluída com sucesso, abra o **R Studio** através do menu Iniciar do Windows ou clicando no ícone do **R Studio**. Segue a imagem da tela que será aberta (Figura 2).


$~$
<center>

![Figura 2. Tela Inicial do **R Studio**](https://i.imgur.com/8TmnTYs.png) 
 
</center> 
$~$

O painel da esquerda é o *Console*  é a parte do **R Studio** que dialoga com o **R**. Pode-se dizer que é a mais importante, pois é nele que os códigos são executados. Quando o programa é aberto, aparece a versão corrente do **R** e algumas informações sobre o mesmo. Se isto acontecer, é sinal de que está tudo certo!  
No painel superior, à direita, é o *ambiente de trabalho* e *histórico* dos comandos.  
No painel inferior, à direita, encontramos os *gráficos*, os *arquivos*, a *ajuda* e os *pacotes* instalados, além do *visualizador*.
Em outro *post* e à medida que as aulas acontecerem, mostraremos as funcionalidades do **R Studio**. O objetivo agora é apenas instalar e apresentar o **R Studio**.  
É importante salientar que o **R Studio** funciona apenas com o **R** instalado, não havendo necessidade de carregar o **R** para que isso aconteça. Basta carregar o **R Studio** e *voilá*!

Recomenda-se baixar para um diretório específico, por exemplo, *Bioestatística_R*. Abra o arquivo a partir dele para que os comandos possam ser executados. Usar sempre este diretório para o seu trabalho com Bioestatística

<!--chapter:end:02-ambienteR.Rmd-->

# Iniciando o *RStudio*

## Interface do *RStudio*

Ao abrir o **RStudio**, você verá a seguinte tela. As cores e fontes podem variar dependendo do seu sistema operacional, mas o layout será o mesmo.

$~$
<center>

![](https://i.imgur.com/DDwe5uI.png) 
 
</center> 
$~$

Os quadros coloridos (vermelho, azul e amarelo) foram acrescentados para melhor identificação dos painéis principais.  
No <span style="color:red"> Console </span> os comandos serão executados e é onde aparecerá a saída com os resultados.  
No <span style="color:blue"> Ambiente </span> aparecerá uma lista organizada do que foi criados, bem como as variáveis.  
Na janela em <span style="color:gold"> amarelo </span> estão os gráficos criados (aba *Plots*), os arquivos do computador (aba *Files*), os pacotes baixados (aba *Packages*), a ajuda (aba *Help*) e o visualizador (aba *Viewer*).

Um quarto painel aparece quando se cria um novo **R Script**. Este é criado através do menu *File* > *New File* > *R Script* ou clicando no botão verde com o sinal (+), na barra de ferramentas de acesso rápido, na parte superior à esquerda. Ao criar um novo *R Script*, o painel do script, espécie de bloco de notas, será aberto.  
$~$
<center>

![](https://i.imgur.com/kzxtXQu.png) 
 
</center> 
$~$

Apesar de ser possível escrever seus códicos e executá-los diretamente no *Console*, preferencialmente, digite-os neste novo painel e envie para serem executados no *Console*, utilizando o botão <span style="color:blue"> Run </span> ou o atalho <span style="color:blue"> Ctrl + Enter </span>.  

Quando o **R Script** é aberto, ele aparece sem título (**Untitled1**) e ao salvá-lo devemos dar um título. A partir daí, ele estrá disponível para ser novamente utilizado. Esta é uma das diferenças importantes com o *Console*. Todos os comandos usados no *Console* não podem ser salvos, porisso o *Console* é utilizado para realizar comandos temporários e rápidos que não necessitam ser salvos.  
Os nossos scripts devem ser salvos em um diretório relacionados a eles. O ideal é criarmos um novo projeto para cada análise.  

## Iniciando um novo projeto

Quando começamos um trabalho com um novo banco de dados, um *Novo Projeto* deve ser criado. Para isso, clicar *File* > *New Project* ou clicar no menu que está na parte superior, à direita, *Project (none)* > *New Project...*. Abrirá a janela abaixo. Clique em *New Directory* para criar um novo diretório. Por exemplo, para as aulas de **Bioestatística usando o R**, pode-se criar um diretório com este nome ou qualquer outro nome. 

$~$
<center>

![](https://i.imgur.com/6N4p3VY.png) 
 
</center> 
$~$

Quaisquer documentos Excel ou arquivos de texto associados podem ser salvos nesta nova pasta e facilmente acessados de dentro de R, indo ao menu *Project (none)* > *Open Project...*. Você pode então realizar análises de dados ou produzir visualizações com seus dados importados.  

## Primeiro Script

O *R Script*, como foi dito antes, é o local preferido para entrar com os comandos. Inserir 3 ou mais caracteres de um comando em um script abrirá o menu de comando sugerido. Este menu sugere comandos ou nomes de variáveis que você pretendeu digitar, junto com uma descrição e uso sugerido. Vamos imaginar que queremos saber o logaritimo na base 10 de um número. Quando digitamos dentro do *R Script* a palavra <span style="color:blue"> log </span>, abre-se o menu de autocompletar, como mostrado na figura. 

$~$
<center>

![](https://i.imgur.com/iJLDHtx.png) 
 
</center> 
$~$

Completando o *R Script* e executando, veremos o resultado no no Console:

```{r}
log10(100)
```

Selecione, Copie e cole em um *R Script* os comandos abaixo. Execute-os clicando no botão <span style="color:blue"> Run </span> ou usando o atalho <span style="color:blue"> Ctrl + Enter </span>.Veja os resultados no seu *Console*:

```{r eval=FALSE}
x=1:500
y=cumsum (sample (0:1,500, rep=TRUE))
plot (x,y/1:500, 
      ylab="Probabilidade", xlab = "Lançamentos da moeda",
      ylim=c (0.3,0.8), xlim=c (0,500), 
      pch=16, 
      col="steelblue")
abline(h = 0.5, col = "red", lty = 2)
```

Complicado? Sim, a primeira vista parece complicado, complexo, mas à medida que os conhecimentos forem se acumulando estes comandos ficarão simples.  
Na aba *Plot*, no painel inferior, à direita, aparecerá o resultado dos comandos acima que deve ser:

```{r echo=FALSE}
x=1:500
y=cumsum (sample (0:1,500, rep=TRUE))
plot (x,y/1:500, 
      ylab="Probabilidade", xlab = "Lançamentos da moeda",
      ylim=c (0.3,0.8), xlim=c (0,500), 
      pch=16, 
      col="steelblue")
abline(h = 0.5, col = "red", lty = 2)
```

><font size=2>**Observação**: É importante o acompanhamento do tutorial com o *RStudio* aberto. Crie um *R Script*. Copie os comandos do tutorial (retangulos cinza claro) e execute os mesmos para ver o resultado no *Console* ou na aba *Plots*. Compare com o tutorial.  

$~$
<center>

![](https://i.imgur.com/s4kS2qv.png) 
 
</center> 
$~$


<!--chapter:end:03-iniRStudio.Rmd-->

# Matemática Básica no *RStudio*

## Operadores  

Para termos uma visão geral dos operadores usados para realizar operações com variáveis e valores, clique [aqui](https://www.w3schools.com/r/r_operators.asp)

Por exemplo, o operador $+$ (adição) é usado para somar dois valores:

```{r}
10 + 5
```

### Operadores aritméticos

No *R*, você pode usar operadores aritméticos para realizar operações matemáticas comuns

Operador| Nome | Exemplo |
:--: | :-- | :--: | 
+ | adição | $x + y$ |
- | subtração | $x - y$ |
* | multiplicação | $x*y$ |
/ | divisão | $x/y$ |
^ | expoente | $x^y$ |
%% | módulo (resto da divisão) | x%%y |
%/% | divisão inteira| x%/%y |
 |  |  |


```{r}
10 + 5
10 - 5
10 * 5
10 / 5
10 ^ 5
10 %% 3
10 %/% 3
```

O resultado da 5ª operação é exibido como notação científica, onde $e+05$ significa $10^5$.

### Operadores de atribuição

Operadores de atribuição são usados para atribuir valores a variáveis:

```{r}
minha_var <- 5
5 ->  minha_var
minha_var # imprime minha_var
```

É possível, como vimos, mudar a direção do operador de atribuição.

<center>
x <- 5 é igual a 5 -> x
<center>

### Operadores de comparação

São usados para comparar dois valores.

Operador| Nome | Exemplo |
:--: | :-- | :--: | 
== | igual | $x == y$ |
!= | não é igual | $x != y$ |
> | maior que | $x>y$ |
< | menor que | $x<y$ |
>= | maior ou igual que | $x>=y$ |
<= | menor ou igual que | $x<=y$ |
   |  |  |
   
```{r}
3 == 3
3 == 4
3 != 4
3 < 4
5 >= 3
```

### Operadores lógicos

Operadores lógicos são usados para combinar declarações condicionais:

Operador| Descrição |
:-: | :---- |  
& | Operador lógico E (AND). Retorna TRUE se ambos os elementos forem TRUE | 
&& | Operador lógico E (AND) - Retorna TRUE se ambas as instruções forem TRUE |
$|$ | Operador lógico OU (OR). Retorna TRUE se uma das instruções for TRUE |
$||$ | Operador lógico OU (OR). Retorna TRUE se uma das instruções for TRUE |
! | Operador lógico NÃO (NOT). Retorna FALSE se a instrução for TRUE |
   |  |
   
```{r}
6 == 6 & 7 == 8
6 == 6 | 7 == 8
```

## Logarítimo

```{r}
log (10)         # log natural
log10 (10)       # log base 10
```


## Raiz quadrada

```{r}
sqrt (81)
```


## Resultado absoluto

```{r}
abs (3 - 6)
```


## Potenciação

```{r}
2^2
10^5
```

## Exercícios

1) Coloque em linguagem do R: $(1 + 3 + 2 + 12 + 8)/5$

```{r}
(1 + 3 + 2 + 12 + 8)/5
```

2) Coloque em linguagem do R: $1 + 3 + 2 + 12 + 8/5$

```{r}
1 + 3 + 2 + 12 + 8/5
```

3) Coloque em linguagem do R: $((2 - 1)^2 + (1 - 3)^2)^{1/2}$

```{r}
((2 - 1)^2 + (1 - 3)^2 )^(1/2)
```

4) Coloque em linguagem do R: $\sqrt{(4 + 3)(2 + 1)}$

```{r}
sqrt((4 + 3)*(2 + 1))
```

5) Coloque em linguagem do R: $1 + 2 \times 3^4$ 

```{r}
1 + 2 * 3^4
```

6) Coloque em linguagem do R: $\pi \times 2$

```{r}
pi
pi*2
```

7) Coloque em linguagem do R: $4^3 + 3^{2 + 1}$

```{r}
4^3 + 3^(3+1)
```

8) Coloque em linguagem do R: $e^2$

```{r eval=FALSE}
e^2
```

O número de Euler(*e*) é uma constante matemática como o $\pi$. Entretanto, ao contrário do $\pi$, ela não está incluída no *R* e a execução do comando retorna uma mensagem de erro. Deve-se criar o objeto *e* e dar um valor igual a exponencial de 1 que é o número de Euler:

```{r}
e = exp(1)
e
e^2
```

9) Coloque em linguagem do R: x = 34. y = 47, $\sqrt{x \times y}$

```{r}
x <- 34
y <- 47
sqrt(x * y)
```

10) Coloque em linguagem do R: $\pi \times 10 -log_{10}2$

```{r}
pi*10 - log(2,10)       # Ou
pi * 10 - log10(2)      # Ou
pi * 10 - log (2, base = 10)
```


<!--chapter:end:04-matematica.Rmd-->

# Pacotes

Para que o **R** cumpra a sua função de dialogar com o usuário para realizar análises estatística e construir gráficos, ele necessita ter instalado **pacotes**.  Quando se instala o **R** básico, ele vem com vários pacotes que permitem uma grande quantidade de análises. Entretanto, à medida que vamos utilizando o **R**, torna-se necessário instalar novos pacotes criados pela comunidade do **R**. Esses novos pacotes contêm novas funções e novos comandos que aumentarão a funcionalidade do **R**.  
Um **pacote** é uma coleção de *funções*, *dados* e *documentação* que expande os recursos do **R** base. O uso dos pacotes é a chave para o uso bem-sucedido do **R**. Eles são instalados à medida que o trabalho com o **R** exigir.

## Repositórios de pacotes

Quando identificamos a necessisdade de um novo pacote, precisamos saber onde ele se encontra. O principal repositório de pacotes é o CRAN (*Comprehensible R Archive Network*). Para acessar este repositório, use o [link](<https://cran.r-project.org/mirrors.html>) e escolha um espelho (*0-Cloud* ou o mais próximo geograficamente de você).  
Estando na página do **CRAN**, no menu, à esquerda, clique em <span style="color:blue"> **Packages** </span>. Isto o colocará na página dos *Contributed Packages*, onde a maioria dos pacotes podem ser encontrados em <span style="color:blue"> **Table of available packages, sorted by name** </span>. També é possível clicar em <span style="color:blue"> **CRAN Task Views** </span>, onde encontramos os pacotes separados por tópicos.

## Instalação de um pacote

Uma maneira simples de instalar um pacote é usar a função `install.packges ()`, colocando entre os parênteses o nome do pacote entre aspas. Por exemplo, para instalar um pacote bastante utilizado na construção de gráficos:

```{r eval=FALSE}
install.packages("ggplot2")
```

No painel inferior direito, na aba <span style="color:blue"> **Packages** </span> é possível ver todos os pacotes instalados. Nesta aba, na parte superior, à esquerda, existe um botão *Install*. Clicando nele, abre-se a caixa de diálogo *Install Packages*. Escreva o nome do pacote que deseja instalar no campo *Package*s e clique em instalar. Isso instalará o pacote que você pesquisou ou fornecerá uma lista de pacotes correspondentes com base no que foi digitado. Por padrão, o *R Studio* busca no repositório CRAN e salva no diretório onde está instalado o **R**. Certifique-se que a caixa *Install dependencies* esteja marcada (Figura 1).

$~$
<center>

![Figura 1. Install Packages](https://i.imgur.com/1UX7WJE.png) 
 
</center> 
$~$

Uma outra forma de abrir a caixa de diálogo da Figura 1 é ir em *Tools* na barra de menus e clicar em *Install Packages...*.  
Assim que ele estiver instalado, o pacote aparecerá na aba *Packages*, o nome do pacote. Os pacotes somente precisam ser instalados apenas uma vez. Entretanto, quando o **R** for atualizado para uma nova versão, os pacotes deverão ser novamente instalados. Um pacote do **R** base não precisa ser instalado.

## Carregar um pacote

Para utilizar um pacote instalado, há necessidade de carregá-lo. Para isso, existem duas maneiras mais frequentes, uma usando a função `library ()` e outra usando a função `require ()`. Para carregar o pacote `ggplot2`, procede-se da seguinte maneira:

```{r eval=FALSE}
library (ggplot2)
```

Ou

```{r eval=FALSE}
require (ggplot2)
```

Existe pouca diferença entre elas. Se você usar a `library (ggplot2)` e o `ggplot2` não tiver sido instalado, seu programa irá parar com a mensagem <span style="color:red"> Error in library(ggplot2) : there is no package called 'ggplot2' </span>. Se você usar `require (ggplot2)`, receberá um aviso (<span style="color:red"> Warning message: </span>), mas não uma mensagem de erro. Na prática, toinnn...
Uma maneira de evitar as mensagens, se isso preocupa você, é usar o seguinte comando:

```{r eval=FALSE}
if (!require("ggplot2")) install.packages("ggplot2")
library(ggplot2)
```

Estes comandos irão instalar o `ggpplot2` se ele não estiver instalado e, depois, irão carregá-lo. Se ele já estiver instalado, será simplesmente carregado.

NOTA: Esta é uma outra característica importante do **R**: existe múltiplas maneiras de se fazer a mesma coisa! A escolha é nossa!  

Outra maneira de carregar o pacote é, na aba *Pacakges*, **User Library** e clicar no pacote desejado. Observe no *Console* que  aparece a execução de `library (ggplot2)`, carregando o pacote `ggplot2`.

Para conhecer todas as funcionalidades e documentação de um pacote, podemos usar a função `help ()`:

```{r eval=FALSE}
help(package = ggplot2)

```

Ou, simplesmente

```{r eval=FALSE}
?ggplot2
```

### Carregar mais de um pacote
usar uma das funções `libraries ()` ou `packages ()`do pacote `easypackages`:

```{r eval=FALSE}
install.packages("easypackages")
library(easypackages)
```

Com o pacote `easypackages` instalado, basta usar a função `libraries()`, com o nome dos pacotes entre aspas.

```{r eval=FALSE}
libraries("readxl", "dplyr", "ggplot2", "car")
```

O mesmo pode ser feito com a função `packages ()`.  

Outro pacote que gerencia pacotes do *R* é o `pacman`. Este pacote tem uma função `p_load ()` que instala e carrega um ou mais pacotes. 

```{r eval=FALSE}
install.packages("pacman")
library(pacman)
```

Com o `pacman` instalado, usar a função `p_load()`, escrevendo o nome dos pacotes sem necessidade de aspas:

```{r eval=FALSE}
p_load(readxl, dplyr, ggplot2, car)
```

Ou:

```{r eval=FALSE}
pacman::p_load(readxl, dplyr, ggplot2, car)
```

O pacote `pacman` tem outras funções, entre elas uma que atualiza os pacotes: `p_update()`. Se usada sem especificar o pacote , ela atualiza todos. Para saber mais sobre o pacote `pacman`, use a ajuda.


<!--chapter:end:05-pacotes.Rmd-->

# Funções

## O que são funções?

As funções automatizam as tarefas no **R**. Elas podem ser criadas pelo pesquisador, de acordo com as suas necessidades. Entretanto, na maioria das vezes, elas são encontradas prontas, fazendo parte de um pacote. Pacotes contêm muitas funções que para serem executadas necessitam que o pacote esteja instalado e carregado. As funções para exercerem a sua ação devem receber dentro delas (entre parênteses) os argumentos que ela exige.
Por exemplo, a função `mean ()`, contida no **R** base, calcula a média de uma série de números (vetor numérico):

É possível colocar este vetor em um objeto que pode receber qualquer nome, por exemplo, um conjunto de seis números, concatenados pela função `c ()`, que receberão o nome de `meus_dados`:

```{r}
meus_dados <- c(3, 5, 7, 9, 6, 7)
mean(meus_dados)
```

A execução da função `mean ()`, retorna o resultado arredondado de `r round(mean(meus_dados), 2)`. Este mesmo resultado poderia ser obtido colocando o vetor dentro da função:

```{r}
mean(c(3, 5, 7, 9, 6, 7))
```

Para se saber quais argumentos necessários para uma determinada função basta consulta a ajuda, onde se encontrará a documentação da mesma:

```{r eval=FALSE}
?mean
```

Os principais argumentos da função `mean ()` são:

Argumento | Significado
:- | :--------
x         | é um objeto **R**, numérico
trim      | é a fração das observações (varia de 0 a 0,5) extraída de cada extremidade de x para calcular a média aparada
na.rm     | valor lógico (TRUE ou FALSE) que indicam se os valores "perdidos" (NA) devem ser removidos antes que o cálculo continue

## Criando funções

### Fórmula geral

As funções têm uma fórmula geral:

 
```{r eval=FALSE}
nome.da.função <- function (x){transformar x}
```

Por exemplo, a área de um circulo é igual a $\pi\times raio^2$. Usando o **R** para calcular a área do círculo, podemos criar uma função que faça este trabalho:

```{r}
area.circ <- function(r){
  area <- pi*r^2
  return(area)                
}
```
 
Ao executar essa função, é possível usá-la para calcular a área de um círculo, cujo raio é igual a 5 cm:

```{r}
r = 5
area.circ(5)
```

### Outros exemplos

Podemos criar uma função para o Indice de Massa Corporal, sabendo que ele é igual ao peso (kg) dividido pela $altura^2$, em metros:

```{r}
imc <- function(peso, altura){
  res <- peso/altura^2
  return(res)
}
```

Logo, o IMC de um indivíduo que tenha 67 kg e 1,7 m é:

```{r}
peso <-  67
altura <-  1.70
imc(67, 1.70)
```

### Ativação de uma função

Para ativar uma função previamente criada, usa-se a função nativa `source ()`. O argumento desta função é o caminho (no exemplo é o diretório do autor) onde se encontra a função buscada. Por exemplo, temos uma função, denominada `coef_var ()` para calcular o coeficiente de variação:

```{r}
source ("C:/Users/petro/Dropbox/Estatística/Bioestatística usando o R/Funções/coef_var.R")
```

Vamos supor que tenhamos o seguinte conjunto de dados, referentes aos pesos de recém-nascidos a termo:

```{r}
pesoRN <- c (3340,3345,3750,3650,3220,4070,3380,3970,3060,3180,  
             2865,2815,3245,2051,2630)
coef_var(pesoRN)

```

Isto significa que o desvio padrão dos pesos dos recém-nascidos equivale a aproximadamente 16% da sua média.

<!--chapter:end:06-funcoes.Rmd-->

# Manipulando Dados no RStudio

## Vetores

**Vetor** é uma estrutura de dados básica que desempenha um papel importante no **R**. É uma sequência de elementos que compartilham o mesmo tipo de dados (lógicos, inteiros, numéricos, caracteres, complexos ou brutos).  
Por exemplo, o vetor contendo 5 valores numéricos 1 , 2, 3, 4 e 5.

```{r}
v1 <- c(1, 2, 3, 4, 5)
v1
```

E o vetor contendo valores lógicos:

```{r}
v2 <- c(TRUE, FALSE, TRUE, FALSE, FALSE)
v2
```

Um vetor pode conter caracteres que devem ser colocado entre aspas. Observe que os números na variável `numChamada` não são números propriamente ditos, representam cada um dos alunos, por exemplo, o número 1 é a aluna Clara:

```{r}
nomeAlunos <-  c("Gabriel", "Felix", "Geraldo", "Nadine", "Silvia", "Clara")
nomeAlunos
numChamada <- c("3", "2", "4", "5", "6", "1")
numChamada
```

O vetor abaixo contém 5 números, sendo o número 3, colocado entre aspas, caracterizando um caractere e não um número. Veja o resultado! O **R** transformou todos em caracteres.

```{r}
v3 <- c(1, 2, "3", 4, 5)
v3
```

Para recuperar valores em um vetor, declara-se um índice dentro de operador [ ](anchor) colchetes. Por exemplo, o seguinte comando mostra como recuperar um membro do vetor. Como índice usamos a posição 3 para recuperar o terceiro membro.

```{r}
s <-  c ("aa", "bb", "cc", "dd", "ee")
s [3]
```

Se o índice for negativo, ele excluirá o membro cuja posição tem o mesmo valor absoluto que o índice negativo. Por exemplo, o seguinte comando exclui o terceiro membro.

```{r}
s <-  c ("aa", "bb", "cc", "dd", "ee")
s [-3]
```

Se um índice estiver fora do intervalo, um valor ausente será relatado por meio do símbolo NA.

```{r}
s <-  c ("aa", "bb", "cc", "dd", "ee")
s [10]
```

Os vetores podem ser combinados por meio da função `cbind ()`. Por exemplo, os dois vetores `nomeAlunos` e `numChamada` são combinados em um novo vetor contendo elementos de ambos os vetores.

```{r}
escola <- c(nomeAlunos, numChamada)
escola
```

Escrito dessa maneira, a variável `escola` tem pouca utilidade. Se usarmos a função` matrix ()` que é uma estrutura bidimensional que necessita atributos de dimensão como numero de linhas (`nrow =`) e número de colunas (`ncol =`)

```{r}
escola <- matrix(escola, nrow=2, ncol = 6, byrow = TRUE)
escola
```

Agora, passa a ter mais sentido. Na primeira linha, temos os nomes dos alunos e, na segunda, os seus números na chamada. Assim, basta olhar para ver que a Clara é aluno número 1.
Observe que os colchetes ([]) representam as linhas e as colunas. Quando representam uma linha temos primeiro um número e depois a virgula, por exemplo, a primeira linha é igual a [[1,]](anchor). Na coluna, o número vem depois da vírgula. Se quisermos, recuperar o aluno da quinta coluna, temos que executar o seguinte comando, onde entre colchetes temos 1, como a primeira linha e 5 a quinta coluna:

```{r}
escola[1,5]
```

## Objetos

**Objeto** é um pequeno espaço na memória do computador onde o **R** armazenará um valor ou o resultado de um comando, utilizando um nome arbitrariamente definido. Tudo criado pelo **R** pode se constituir em um objeto, por exemplo: uma variável, uma operação aritmética, um gráfico, uma matriz ou um modelo estatístico. Através de um objeto torna-se simples acessar os dados armazenados na memória. Ao criar um objeto, se faz uma declaração. Isto significa que se está afirmando, por exemplo, que uma determinada operação aritmética irá, agora, tornar-se um objeto que irá armazenar um determinado valor. As declarações são feitas uma em cada linha do *RScript*. 

Os comandos do **R** são compostos por duas partes: objetos e funções. Eles são separados por um operador de atribuição [<−](anchor), que deve ser entendido como “recebe” ou “criado a partir de”. Para digitar este operador basta digitar o sinal menor que (<), seguido de hífen (–), sem espaços. Existe um atalho, clicando em `Alt` e `hífen (-)`. O símbolo [=](anchor) pode ser usado no lugar de <−, mas não é recomendado.  

O **R** possui várias classes de objetos. São eles:

- **character**: são caracteres – “a”, “sim”, “masculino” (escritos entre aspas)
 **numeric**: são decimais – 4.0, 2.34, 50.0 (no **R** o separador de decimal é o ponto)
-	**integer**: inteiro – para criar uma variável que é um valor inteiro, chama-se a função `as.integer ()`. Por exemplo, será criado o objeto x que receberá os valores 4.0, 2.34, 50.0, usando a função `c ()`, que significa combinar ou concatenar:

```{r}
x <- c (4.0, 2.34,50.0)
as.integer (x)
```

A execução da função exibiu no *Console* apenas os valores inteiros 4, 2, 50 do objeto `x`, ignorando os decimais.

-	**logical**: retorna [TRUE](anchor) ou [FALSE](anchor). A função `is.integer()` questiona se os valores são inteiros. Por exemplo, 

```{r}
is.integer (x)
```

A saída foi [FALSE](anchor), pois existem valores decimais.

Para saber qual o tipo de objeto que está sendo usado, basta usar a função `class ()`.

## Manipulando dados numéricos

Dados numéricos permitem qualquer operação matemática.  

Suponha que o salário de um empregado seja R$ 3800,00 para um trabalho de 220h mensais (ch):

```{r}
salario <- 3800.00
ch <- 220
```

Utilizando estes dados podemos fazer outros cálculos. Por exemplo: o salário-hora (`sh`), salário-hora arredondado para duas casas decimais (`sh_r`), usando a função `round ()` e e o salário-hora como numero inteiro (`sh_i`), usando a função `as.integer ()`.

```{r}
sh <- salario/ch
sh_r <- round (salario/ch, 2)
sh_i <- as.integer((salario/ch))
```

A execução destes comandos não gerou nenhum um tipo de saída. Para ver a saída, temos que chamar cada uma delas:

```{r}
sh
sh_r
sh_i
```

## Manipulando dados categóricos

Vamos criar três objetos do tipo [caractere](anchor) (*character*). O primeiro. `nome1`, receberá o meu nome, o segundo, reberá o nome `Epaminondas` e o terceiro, o numero `10`, escritos todos *entre aspas*. Observe que o número 10, na realidade, não está como um número, está caracterizando algo, por exemplo, um jogador de futebol, o camisa 10.

```{r}
nome1 <- "Petronio"
nome2 <- "Epaminondas"
camisa <- "10"
```

Estes dados não permitem operações matemáticas, como por exemplo:

```{r eval=FALSE}
camisa + 5
nomes <- nome1 + nome2
```

Esta operação vai gerar uma mensagem de erro: <span style="color:red"> Error in camisa + 5 : non-numeric argument to binary operator </span>

Entretanto, estes comandos geram resultados compreensíveis:

```{r}
nomes <- c(nome1, nome2)
nomes
nomes[1]
nomes[2]
```

Para se saber a que classe um objeto pertence, usa-se a função `class ()`.

```{r}
class("10")
```

Uma outra maneira de representar objetos é como [fator](anchor)(*factor*). Os fatores são variáveis no **R** que assumem um número limitado de valores diferentes; são variáveis categóricas. Um dos usos mais importantes de fatores é na modelagem estatística. O armazenamento de dados como fatores garante que as funções de modelagem tratem esses dados corretamente.
Os fatores no **R** são armazenados como um vetor de valores inteiros. A função `factor ()` é usada para criar um fator. O único argumento necessário é um vetor de valores. Ambas as variáveis numéricas e de caractere podem ser transformadas em fatores, mas os níveis de um fator sempre serão valores de caractere. Você pode ver os níveis possíveis para um fator por meio do comando `levels ()`.

O objeto `dados` recebe vários números:

```{r}
dados <- c(1,2,2,3,1,2,3,3,1,2,3,3,1)
dados
class(dados)
```

A executar estes comandos, temos 13 números que constituem a variável `dados.` Esta variável é da classe numérica. Portanto, podemos realizar qualquer operação matemática. Por exemplo, a soma deles com a função `sum ()` ou a raiz quadrada da soma com a função `sqrt ()`:

```{r}
soma <- sum(dados)
soma
sqrt (soma) 
```

Entretanto, se transformarmos a variável `dados` em fator, não será possível realizar operações matemática, os números passarão a ser níveis, que podem apenas ser ordenados. Por exemplo, usar estes níveis para representar gravidade de uma doença: 1 = leve, 2 = moderada e 3 = grave.

```{r}
dados <- factor(dados)
dados
```
Observe que os valores são os mesmos, mas o significado é completamente diferente. Temos agora três níveis que podem ser ordenados e rotulados, acrescentando argumentos à função `factor ()`:

```{r}
dados <- factor(dados,
                levels = c(1, 2, 3),
                labels = c("leve", "moderada", "grave"),
                ordered = TRUE)
dados
```

Todos os números **1** foram trocados por `leve`, os **2** por `moderada` e os **3** por `grave`. A saída ainda mostra que existe uma hierarquia entre eles `leve < moderada < grave`. Se não tivéssemos ordenado, o resultado no **R** seria em ordem alfabética, como é o seu padrão. Já sabemos que são três níveis, mas ser quiséssemos apenas observar os níveis, basta usar a função `levels ()`:

```{r}
levels(dados)
```

## Dataframes ou Banco de dados

Um banco de dados ([dataframe](anchor)) é uma tabela ou uma estrutura semelhante a uma matriz bidimensional em que cada coluna contém valores de uma variável e cada linha contém um conjunto de valores de cada coluna, representado um caso.

As características de um banco de dados são:

* Os nomes das colunas não devem estar vazios.
* Os nomes das linhas devem ser exclusivos.
* Os dados armazenados em um banco de dados podem ser numéricos, fator ou tipo de caractere.
* Cada coluna deve conter o mesmo número de itens de dados.

### Criando um banco de dados

Em primeiro lugar vamos criar algumas variáveis. É importante nomear a variável de uma maneira que faça sentido e ter um padrão que permita a fácil memorização. 

```{r}
pesoRN <- c (3340, 3345, 3750, 3650, 3220, 4070,3380, 3970, 3060, 3180, 2865, 
             2815, 3245, 2051, 2630)  
compRN <- c (50, 48, 52, 48, 50, 51, 50, 51, 47, 47, 47, 49, 51, 50, 44)
sexo <- c (2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2)
tipoParto <- c (1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1)
idadeMae <- c (40, 19, 26, 19, 32, 24, 27, 20, 21, 19, 23, 36, 21, 23, 23) 

```

Estas são um grupo de variáveis isoladas pertencentes a dados de 15 partos de uma maternidade, onde:

*	**pesoRN**: peso do recém-nascido em gramas;
*	**compRN**: comprimento do recém-nascido em cm;
*	**sexo**: sexo do recém-nascido, 1 = M e 2 = F;
*	**tipoParto**: se o parto foi 1 = normal ou 2 = cesáreo;
* **idadeMae**: idade da mãe do recém-nascido em anos.

Essas variáveis podem ser reunidas em um banco dados, usando a função `data.frame()`. Será dado o nome de `dadosNeonatos` ao banco de dados criado.

```{r}
dadosNeonatos <- data.frame (pesoRN, 
                             compRN, 
                             sexo, 
                             tipoParto, 
                             idadeMae)
dadosNeonatos
```

Para acrecentar variáveis a este banco de dados, basta digitar no *R Script* o comando:

```{r}
dadosNeonatos$utiNeo <- c (2,2,2,2,1,2,1,2,2,2,2,1,2,2,2)
dadosNeonatos
```

Na nova variável `dadosNeonatos$utiNeo`, temos que 1 = necessitou de UTI e 2 = não necessitou de UTI. Após o comando para criar a variável `utiNeo`, foi digitado o nome do banco de dados (`dadosNeonatos`) para visualizar o mesmo

Para listar os nomes das variáveis (colunas) do banco de dados, basta usar a função `names ()`:

```{r}
names(dadosNeonatos)
```
Para ver a estrutura do banco de dados é útil a variável `str ()`:

```{r}
str(dadosNeonatos)
```

Observa-se que todas as variáveis do banco de dados estão como numéricas. Entretanto, as variáveis `sexo`, `tipoParto` e `utiNeo` não são numéricas, são categóricas, onde na variável `sexo`, 1 = masculino e 2 = feminino, na variável `tipoParto`, 1 = normal e 2 = cesareo e na variável `utiNeo`, 1 = sim e 2 = não. Sem qualquer transformação, é possível realizar operações matemáticas, o que é "non sense"!  
Para transformar essas variáveis em um fator, é usada, como vimos, a função `factor ()`:

```{r}
dadosNeonatos$sexo <- factor (dadosNeonatos$sexo, 
                              levels = c (1,2), 
                              label = c ("masculino", "feminino"))

dadosNeonatos$tipoParto <- factor (dadosNeonatos $tipoParto,
                                   levels = c (1,2),
                                   labels = c ("normal",                      
                                               "cesareo"))

dadosNeonatos$utiNeo <- factor (dadosNeonatos$utiNeo,
                                levels = c (1,2), 
                                labels = c ("sim", "não"))

dadosNeonatos

```

O banco de dados, agora, tem um aspecto mais amigável e compreensível. Se olharmos a sua estrutura, após as transformações, temos:

```{r}
str(dadosNeonatos)
```

Depois das transformações, as variáveis passaram a ser classificadas como fatores, cada uma delas com dois níveis.

### Salvando os arquivos no seu diretório

Crie um diretório de trabalho em seu computador. Coloque um nome sugestivo, por exemplo, [Bioestatística_R](anchor) e salve todos os arquivos, relacionados ao tema, nele.
Para obter o arquivo `dadosMater.xlsx`, você deve clicar [aqui](https://github.com/petronioliveira/Arquivos/blob/main/dadosMater15.xlsx) e baixar para o para seu diretório de trabalho, por exemplo, [Bioestatística_R](anchor).

Para o arquivo `dadosMater15.csv`, clique [aqui](https://github.com/petronioliveira/Arquivos/blob/main/dadosMater15.csv) e proceda da mesma maneira que para o `dadosMater.xlsx`.

Feito! Os arquivos `dadosMater.xlsx` e `dadosMater15.csv`, agora, estão em seu diretório de trabalho, prontos para serem manipulados!

### Importando um banco de dados
#### Importando dados de um arquivo CSV

A função `read.csv ()` e `read.csv2 ()` podem ser utilizadas para importar arquivos CSV. Existe uma pequena diferença entre elas. Dois argumentos dessas funções têm padrão diferentes em cada uma. São eles: *sep* (separador de colunas) e *dec* (separador de decimais). Em `read.csv ()`, o padrão é` sep = ”,”` e `dec = ”.”` e em `read.csv2 ()` o padrão é `sep = “;”` e `dec = ”,”`.   
Quando se usa o `read.csv ()` há necessidade de informar o separador e o decimal, pois senão ele usará o padrão inglês e o arquivo não será lido. Já com `read.csv2()`, que o usa o padrão brasileiro, não há necessidade de informar ao **R** qual o separador de colunas e nem o separador dos decimais.  
Quando o arquivo se encontra no diretório de trabalho, como é o caso do `dadosMater15.csv`, procede-se da seguinte maneira:

```{r eval=FALSE}
dadosMater<- read.csv2 ("dadosMater15.csv")
```

Ou, para os casos onde seu arquivo não se encontra no diretório de trabalho:

```{r eval=FALSE}
dadosMater <- read.csv2 (file.choose())
```

#### Importando dados de um arquivo Excel

Existem várias formas de importar do Excel, recomenda-se usar a função `read_excel ()`  do pacote `readxl`.  
Quando o arquivo se encontra no diretório de trabalho, como é o caso do `dadosMater15.xlsx`, procede-se da seguinte maneira:

```{r eval=FALSE}
library(readxl)
dadosMater <- read_excel ("dadosMater15.xlsx", sheet = 1)
```

O argumento `sheet = 1`, significa que se está abrindo a planilha 1 do arquivo. Este argumento é importante se houver mais de uma planilha, caso contrário, ele é opcional.  
Se você não estiver no diretório de trabalho, proceda como visto na importação de dados CSV.

```{r eval=FALSE}
dadosMater <- read_excel (file.choose())
```


<!--chapter:end:07-manipulandoDados.Rmd-->

# Sumarização dos dados

Um conjunto de dados brutos devem ser descritos, organizando-os em forma de tabelas e de gráficos que dão uma “imagem” dos dados, permitindo que se observe o seu aspecto e como eles se comportam.  
As maneiras mais usadas para resumir o conjunto de dados são:

* Primeiro, um valor em torno do qual os dados têm uma tendência para se reunir ou se agrupar, denominado de medida sumária de localização ou medida de tendência central. 
* Em segundo lugar, um valor que mede o grau em que os dados se dispersam, denominado de medida de dispersão ou variabilidade.  

Para trabalhar nesta seção, vamos usar os seguintes pacotes:

```{r }
pacman::p_load(dplyr, readxl, psych)
```

E o arquivo `dadosMater15.xlsx`que pode ser obtido [aqui](https://github.com/petronioliveira/Arquivos/blob/main/dadosMater15.xlsx) e baixado para o seu diretório de trabalho.

Agora, vamos criar um objeto, `mater15`, para receber os dados, a partir do diretório de trabalho, executando o seguinte código:

```{r }
mater15 <- read_excel ("C:/Users/petro/Dropbox/Git_repositório/Arquivos/dadosMater15.xlsx")
```

O caminho (*path*), usado no comando, é o do arquivo no computador do autor. Você deverá escrever o caminho no seu computador. Observe o uso de barra comum (não invertida). Se o arquivo foi baixado no diretório de trabalho ativo, como vimos na Capítulo 7, basta escrever `"dadosMater15.xlsx"`.

## Medidas de tendência central
### Média

A média ( $\overline{x}$ ) é a mais usada medida de tendência central. Ela é calculada pela razão entre a soma de todas as observações de um conjunto de dados e o total de observações.  
Com os dados dos pesos dos recém-nascidos (`pesoRN`) do arquivo `dadosMater15.xlsx`, podemos calcular a média aritmética, usando a função `mean ()`. A média é mais adequada para medidas numéricas simétricas.

```{r}
mean(mater15$pesoRN)
```

Se no conjunto de dados houvesse algum valor ausente (*missing*), o comando mostraria o resultado como NA (*not available*). Para corrigir isto, basta colocar o argumento `na.rm = TRUE` na função `mean()`. Assim, o **R** vai retornar a média, ignorando os valores ausentes.  

```{r}
mean (mater15$pesoRN, na.rm = TRUE)
```

### Mediana

A mediana (Md) representa o valor central em uma série ordenada de valores. Assim, metade dos valores será igual ou menor que o valor mediano e a outra metade igual ou maior do que ele.  
No **R**, usa-se a função `median ()` para calcular o valor da mediana. Vanos utilizar a variável `mater15$apgar1`. Como o Apgar é um escore, a medida resumidora mais adequada é a mediana. Em primeiro lugar verifica-se a presença NA:  

```{r}
summary (mater15$apgar1)
```

Não existe dados omissos nessa amostra. Portanto, o uso do argumento `na.rm = TRUE` é desnecessário.

```{r}
median (mater15$apgar1)
```

### Moda

Moda (Mo) é o valor que ocorre com maior frequência em um conjunto de dados. Tem o menor nível de sofisticação. É usada primariamente para dados nominais porque há simplesmente contagem dos valores. Ao contrário das outras medidas de tendência central, a moda não informa nada sobre a ordem das variáveis ou variação dentro das variáveis.  
O **R** não tem uma função embutida padrão para calcular a moda. Portanto, há necessidade de ser criada uma função de usuário para calcular a moda.  

Foi criada uma função para calcular a moda:  

```{r}
moda <- function(x) {
  z <- table(as.vector(x))
  names(z)[z == max(z)]}
```

Usando esta função pode-se calcular a moda para a variável `mater15$apgar1`. 

```{r}
moda (mater15$apgar1) 
```

A moda para essa variável é igual a mediana.

### Quantil

Uma medida de localização bastante utilizada são os <font color="blue">quantis</font> que são pontos estabelecidos em intervalos regulares que dividem a amostra em subconjuntos iguais. Se estes subconjuntos são em número de 100, são denominados de <font color="blue">percentis</font>; se são em número de em 10, são os <font color="blue">decis</font> e em número de 4, são os <font color="blue">quartis</font>. 
A função apropriada no **R** para obter o quantil é `quantile ()`. Para determinar os três quartis do peso dos recém-nascidos (`mater15$pexoRN`), usa-se:

```{r}
quantile (mater15$pesoRN, c (0.25, 0.50, 0.75))
```

Observe que o percentil 50º é igual a mediana. O percentil 75º é o ponto do conjunto de dados onde 75% dos recém-nascidos têm um peso inferior a 3515,0g e 25% está acima deste valor.

### Média aparada

As médias aparadas são estimadores robustos da tendência central. Para calcular uma média aparada, é removida uma quantidade predeterminada de observações em cada lado de uma distribuição e realizada a média das observações restantes. Um exemplo de média aparada é a própria mediana.   
A base **R** tem como calcular a média aparada acrescentando o argumento `trim =`, proporção a ser aparada. Se for aparado 20%, usa-se `trim = 0.2`. isto significa que serão removidos 20% dos dados dos dois extremos. No caso da amostra de 15 recém-nascidos, serão removidos três valores mais baixos e três valores mais altos, passando a mostra a ter 9 valores, e a média aparada será a média destes 9 valores. O comando para obter a média aparada é:

```{r}
mean (mater15$pesoRN, na.rm = TRUE, trim = 0.20)
```

## Medidas de Dispersão
### Amplitude  

A amplitude de um grupo de medições é definida como a diferença entre a maior observação e a menor.  
No conjunto de dados dos pesos dos recém-nascidos, a amplitude pode ser obtida, no *R*, com a função `range ()`, que retorna o valor mínimo e o máximo.

```{r}
range (mater15$pesoRN, na.rm = TRUE)
```

### Intervalo Interquartil
      
A intervalo interquartil (IIQ), também conhecido como amplitude interquartil (AIQ) é uma forma de média aparada. É simplesmente a diferença entre o terceiro e o primeiro quartil, ou seja, a diferença entre o percentil 75 e o percentil 25. 
Considere a escolaridade (`anosEst`) das parturientes da amostra `dadosMater15.xlsx`. Os percentis 25 e 75 são obtidos por:

```{r}
quantile (mater15$anosEst, c(0.25,0.75))
```

Também podeser usada a função `summary ()`:

```{r}
summary(mater15$anosEst)
```

Portanto, o IIQ está entre 6 a 8 anos de estudo ou, 8 – 6 = 2 anos de estudos completos. Em outras palavras, 50% das mulheres desta amostra têm de 6 a 8 anos de estudo.

### Variância e Desvio Padrão

A variância e o desvio padrão fornecem uma indicação de quão aglomerados em torno da média os dados de uma amostra estão. Estes tipos de medidas representam desvios da média.  
No **R** existem as funções `sd ()` e `var ()`, também incluídas no **R** base, que facilmente calculam essas medidas de dispersão. Usando a variável `mater15$pesoRN`, tem-se:

```{r}
sd (mater15$pesoRN)
var(mater15$pesoRN)
```

O desvio padrão é a raiz quadrada da variância: $s = \sqrt var$

```{r}
sqrt (var(mater15$pesoRN))
```

A variância e desvio padrão são medidas de variabilidade. Representam quão bem a média representa os dados. Informa se ela está funcionando bem como modelo. Pequenos desvios padrão mostram que existe pouca variabilidade nos dados, que eles se aproximam da média. Quando existe um grande desvio padrão, a média não é muito precisa para representar os dados.

### Coeficiente de Variação

O desvio padrão por si só tem limitações. Um desvio padrão de duas unidades pode ser considerado pequeno para um conjunto de valores cuja média é 100. Entretanto, se a média for 5, ele se torna muito grande. Além disso, o desvio padrão por ser expresso na mesma unidade dos dados, não permite aplicá-lo na comparação de dois ou mais conjunto de dados que têm unidades diferentes.
Para eliminar essas limitações, é possível caracterizar a dispersão ou variabilidade dos dados em termos relativos, usando uma medida denominada Coeficiente de Variação (CV), também conhecido como como Desvio Padrão Relativo ou Coeficiente de Variação de Pearson. É expresso, em geral como uma porcentagem, sendo definido como a razão do desvio padrão pela média:

$$
CV = \frac{s}{\overline{x}}
$$

Multiplicando o valor da equação por 100 tem-se o CV percentual.  
O **R** não possui uma função específica para calcular o CV. Foi criada uma função específica para isso,já multiplicada por 100.

```{r}
coef_var <- function (valores) {
  (sd(valores, na.rm=T) / mean(valores, na.rm=T))*100}
```

Portanto, o CV da variável `mater15$pesoRN` é igual a:

```{r}
coef_var (mater15$pesoRN)
```

Se usarmos outra variável do banco de dados, por exemplo, `mater15$idadeMae`, o CV será igual a:

```{r}
coef_var (mater15$idadeMae)
```

O peso do recem-nascido tem um CV = `r round(coef_var (mater15$pesoRN), 1)` e a idade materna um CV = `r round(coef_var (mater15$idadeMae), 1)`, mostrando que esta tem uma maior variabilidade. Quanto menor o desvio padrão, menor o CV e, consequentemente, menor a variabilidade. Um CV $\ge$ 50%, sugere que a variável tenha uma distribuição assimétrica.

## Funções descritivas no R

### Funções `describe` e `describeBy`

Essas funções pertencem ao pacote `psych` e podem ser usada para se obter medidas descritivas, como média, desvion padrão, mediana, média aparada (padrão = 0.1),desvio absoluto mediano, , mínimo, máximo, assimetria (skew), curtose, erro padrão:

```{r}
describe (mater15$pesoRN)
```

A variável `sexo` do recém-nascido encontra-se no banco de dados como uma variável numérica:

```{r}
class (mater15$sexo)
```
E deve ser transformada para se conhecer o peso dos recém-nascidos por sexo:

```{r}
mater15$sexo <- factor (mater15$sexo, 
                        label = c ("masculino", "feminino"))
```

Depois da transformação, podemos usar a função describeBy () para obter o peso para cada sexo:

```{r}
describeBy (mater15$pesoRN, 
            group = mater15$sexo)
```

### Funções `group_by` e `summarise` 

Essas funções estão contidas no pacote `dplyr` (clique [aqui](https://www.dropbox.com/s/9geund7drwdvi2x/Manipulando-Dados-com-o-dplyr.html?dl=0) para explorar mais este pacote). Elas podem ser usadas juntas com o operador [pipe](anchor).  Este é utilizado para encadear funções, ou seja, chama-se uma função e, em seguida, passar o resultado para outra função e dessa para outra, de uma forma que seja facilmente legível. Por exemplo:

```{r}
mater15 %>% 
  group_by(sexo) %>% 
  summarise (n = n (),
             media = mean(pesoRN),
             dp = sd (pesoRN),
             mediana = median(pesoRN),
             IQQ = IQR (pesoRN),
             cv = coef_var (pesoRN))
```


Os comandos chamam o banco de dado `mater15`, filtram a variável `sexo` deste banco e depois calculam varias medidas decritivas da variável `pesoRN.`

### Função `summary`

A função `summary ()` fornece a os quantis, o máximo, o mínimo e a média de uma variável ou do banco de dados.

```{r}
summary(mater15$idadeMae)
```

## Leitura Adicional 

1. Kassambara A. Descriptive Statistics and Graphics. **STHDA - Statistical tools for high-throughput data analysis**. Disponível em: <http://www.sthda.com/english/wiki/descriptive-statistics-and-graphics> . Acesso em 24/08/2022

2. Oliveira Filho PF. **Epidemiologia e Bioestatística: fundamentos para a leitura crítica**. 2ª ed. Rio de Janeiro: Editora Rubio Ltda; 2022. Resumo dos Dados Numéricos;p.24-31.

3. Soettewey A. Descriptive statistics in R. **Stats and R**, Louvain-la-Neuve, Bélgica, 22 de janeiro de 2020. Disponível em: <https://statsandr.com/blog/descriptive-statistics-in-r/>. Acesso em: 13 de agosto de 2022.


</br>
</br>


<!--chapter:end:08-sumarizandoDados.Rmd-->

# Tabelas  

## Pacotes necessários  

carregue os bancos de dados que serão utilizados neste capítulo.

```{r message=FALSE, warning=FALSE}
pacman::p_load(readxl, dplyr, gmodels, gt, gtsummary, flextable)
```

## Carregar os dados

Para obter os dados você deve clicar [aqui](https://github.com/petronioliveira/Arquivos/blob/main/dadosMater.xlsx) e baixar para o seu diretório de trabalho o arquivo `dadosMater.xlsx`.

Crie um objeto `mater` para receber os dados, a partir do diretório de trabalho (no exemplo, é o diretório do autor): 

```{r}
mater <- read_excel ("C:/Users/petro/Dropbox/Git_repositório/Arquivos/dadosMater.xlsx")
```

## Exploração dos dados

### Visão Geral 

Uma visão geral do banco de dados pode ser conseguida com a função `glimpse ()` do pacote `dplyr`:

```{r}
glimpse (mater)
```

Temos 30 variáveis (colunas) que podem ser manipuladas, reduzidas ou aumentadas, de acordo com o objetivo da análise. Essas variáveis estão todas colocadas como numéricas (`dbl`), quando, na realidade, várias delas são categóricas. 

### Transformações das variáveis

A primeira tarefa é transformar algumas variáveis numéricas que se encontram como categóricas, usando a função `factor ()`.

```{r}
mater$sexo <- factor (mater$sexo,
                      levels = c(1,2),
                      labels = c ("masc", "fem")) 

mater$cor <- factor (mater$cor,
                     levels = c(1,2),
                     labels = c ("branca", "não branca"))

mater$tipoParto <- factor (mater$tipoParto,
                           levels = c(1,2),
                           labels = c ("normal", "cesareo"))

mater$utiNeo <- factor (mater$utiNeo,
                        levels = c (1, 2),
                        labels = c ("sim", "não"))

mater$eCivil <- factor (mater$eCivil,
                        levels = c (1, 2),
                        labels = c ("solteira", "casada"))

mater$fumo <- factor (mater$fumo,
                        levels = c (1, 2),
                        labels = c ("sim", "não"))

mater$obito <- factor (mater$obito,
                        levels = c (1, 2),
                        labels = c ("sim", "não"))
```

A seguir, vamos reduzir o número de variáveis, apenas como demostração didática, criando um novo banco de dados que será denominado de `mater1`. Isso será feito pela função `select ()` do pacote `dplyr`. Como argumentos da dunção, colocamos o nome da variável precedido do sinal de menos. Poderia ser feito, colocando como argumentos o nome das variáveis que permanecem no banco de dados.

```{r}
mater1 <- mater %>% 
  select (-quantFumo, -droga, -pcRN, -apgar5, -hiv, -sifilis, -rubeola, - toxo, -infCong)

glimpse (mater1)
```

Agora, temos um banco de dados com `r ncol(mater1)` colunas, onde as variáveis categóricas aparecem como fatores.

## Tabela de Frequência

Uma das maneiras mais frequentes de observar o comportamento de uma variável, ou de um conjunto de variáveis, é construir uma **tabela de frequência**.  
A tabela de frequência agrupa os dados por categorias ou classes, contabilizando o número de ocorrências em cada categoria.

### Tabela de frequência para dados categóricos

A maneira mais simples é usar a função `table ()` e `prop.table ()` que fornecem a frequência absluta e a relativa, respectivamente, associada a ele, vamos usar a função `round()` para reduzir os digitos decimais a 3:

```{r}
tab1 <- table(mater1$sexo)
tab1
```

```{r}
round (prop.table(tab1),3)
```

Ou seja, o banco de dados mater1 representa os nascimentos de 731 (53,4%) meninos e 637 meninas (45,6%).  

Outro exemplo,

```{r}
tab2 <- table(mater1$tipoParto)
tab2
```

```{r}
round (prop.table(tab2), 3)
```

Observamos que o índice de cesarianas, nesta maternidade, é bem alto e igual a 40,6% dos nascimentos.

### Tabela de contingência ou cruzada

Por exemplo, o cruzamento de duas variáveis, chamada de tabela 2 x 2. Podemos usar também a função `table ()` e `prop.table ()`:

```{r}
tab3 <- table(mater1$sexo, mater1$utiNeo)
tab3

round(prop.table(tab3), 3)
```

Existe uma função denominada `CrossTable ()`, do pacote  `gmodels`, bastante completa, que faz a tabulação cruzada com testes de independência para  fatores. Necessita de vários argumentos:

```{r}
CrossTable(mater1$sexo,
           mater1$utiNeo,
           prop.r = TRUE,
           prop.c = FALSE,
           prop.t = FALSE,
           chisq = TRUE,
           prop.chisq = FALSE)
```

Onde `prop.r = TRUE` é para que a função entregue as proporções na linha. O argumento `chisq = TRUE` exibirá o resultado de um teste de Qui-Quadrado. Os argumentos `prop.c` (proporções na coluna), `prop.t` (proporçõe no total) e `prop.chisq` (contribuição do qui-quadrado de cada célula será incluída) foram colocados como `FALSE`. Os demais argumentos serão melhor discutidos quando do estudo do Qui-Quadrado. Para mais informações consulte a ajuda da função.  
O Qui-Quadrado de Pearson com correção mostrou um valor *P*=0,46, ou seja, maior que 0,05 e, portanto, não existe, estatisticamente, uma diferença entre os meninos e as meninas quanto à ida para UTI Neonatal.  

### Tabela de frequência para dados numéricos

Quando se tem uma variável quantitativa, por exemplo, escolaridade (`anosEst`), fica difícil fazer uma distribuição como a feita anteriormente:

```{r}
table(mater1$anosEst)
```

A saída deste comando tem interpretação difícil. O ideal é categorizarmos a variável `anosEst` de acordo com os níveis escolares oficiais: fundamental, medio e superior. Para isso, seguimos alguns passos:

* **Passo 1**: analisar a amplitude da variável

```{r}
range (mater1$anosEst)
```

* **Passo 2**: estabelecer a quantidade de categorias. 

Escolhemos 3 categorias: *Fundamental*, *Médio* e *Superior*

* **Passo 3**: criação da tabela com as categorias, usando a função `cut ()`. Esta função tem vários argumentos:

Argumento | Significado
:--- | :-----------
x | um vetor numérico que será convertido em fator por classes;
breaks | vetor numérico de dois ou mais pontos de corte exclusivos ou um único número (maior ou igual a 2) dando o número de intervalos nos quais x deve ser cortado;
labels | rotulos para os n´veis das categorias;
include.lowest | argumento lógico, sendo [TRUE](anchor) indicativo de inclusão dos limites;
right | argumento lógico, sendo o padrão igual a [TRUE](anchor), indicando que os intervalos devem ser fechados à direita e aberto à esquerda ([[)](anchor)) ou se [FALSE](anchor), abertos à direita e fechados à esquerda;
ordered_result | argummento lógico, [TRUE](anchor) se o resultado deve ser ordenado.
      |

Vamos estabelecer que até 9 anos de estudo, temos o ensino fundamental; de 10 a 12 anos, o ensino médio e a partir de 13 anos, o ensino superior. Ou seja, o argumento `breaks = c(0, 10, 13, 18)`. No exemplo, foi usado `right = FALSE` e, em consequência, o intervalo 0 – 9, incluirá o 0 e excluirá o 9, o intervalo 9 a 12, incluirá o 9 e excluirá o 12 e o último intervalo incluirá o 12 e excluirá o 18, que é o valor mais alto. Em função disso, foi incluído mais um argumento `include.lowest=TRUE`, para incluir o valor 18. 

```{r}
escolaridade <- cut (mater1$anosEst,
                     breaks= c (0,10,13,18),
                     right = FALSE,
                     labels = c("Fundamental",
                                "Médio",
                                "Superior"),
                     include.lowest = TRUE)                 

table(escolaridade)
```
      
Quando se tem uma variável quantitativa e não se dispõe de um critério pré-estabelecido  do número de classes, como no caso da escolaridade, devemos estabelecer um número de classes. 
O número adequado de categorias pode ser dado pela *Regra de Sturges* ou por um outro critério que tenha alguma lógica, de acordo com o objetivo do estudo. A regra de Sturges tem a seguinte fórmula, onde *n* é total de observações (casos).  

$$
k = 1+1.322 \ log_{10}(n)
$$

O **R** possui a função `nclass.Sturges()` para este cálculo. Entretanto, ela é pouco usada. O bom-senso do pesquisador é a regra principal. Por exemplo, se quisermos ver a distribuição da renda familiar (em salários mínimos), variável `renda` no banco de dados `mater1`, podemos usar, os seguintes passos: 

* **Passo 1**: analisar a amplitude da variável

```{r}
range (mater1$renda)
```

* **Passo 2**: estabelecer a quantidade de categorias. 

Como a renda mais alta é 11, vamos criar 5 classes.

* **Passo 3**: criação da tabela com as categorias, usando a função `cut ()` e a função `seq()`, onde `by =` é o incremento da sequência. 

```{r}
rendaCateg <- cut (mater$renda,
              right = FALSE, 
              include.lowest = TRUE,
              seq(0, 12, by = 3)) 
tab_renda <- table(rendaCateg)
tab_renda
```

Este resultado mostra que 1144 dessas famílias tinham uma renda inferior a 3 salários mínimos e somente 5 famílias tinham uma renda acima de 9 salários mínimos. Ou seja, a distribuição da renda familiar é bastante assimétrica, com a maioria com uma renda abaixo de 3 salários mínimos.

## Construção de uma tabela com o pacote `gt`

Transformando a `tab_renda`, obtida anteriormente, usando a função `as.data.frame ()`, temos:

```{r}
tab_renda <- as.data.frame(tab_renda)

class (tab_renda)

colnames(tab_renda) <- c("Renda", "Frequência")

tab_renda
```

Após, usa-se a função `gt()` para construir a tabela:

```{r}
gt_renda <- gt(tab_renda) %>% 
  tab_header(title = md("**Renda Familiar**"),
             subtitle = "Salários Mínimos")

gt_renda
```

## Tabelas com o pacote `getsummary`

Vamos construir uma tabela com as informações dos recém-nascidos do banco de dados `mater`. Inicialmente, criaremos um banco de dados, `materRN`, da seguinte modo:

```{r}
materRN <- mater %>% 
  select(pesoRN, compRN, sexo, apgar1, ig, tipoParto, utiNeo, obito)

glimpse (materRN)
```

```{r}
tab <- materRN %>% 
  tbl_summary(by = sexo,
              label = list (pesoRN ~ "Peso de Nascimento (g)",
                            compRN ~ "Comprimento ao nascer (cm)",
                            apgar1 ~ "Escore de Apgar no 1º min",
                            ig ~ "Idade Gestacional",
                            tipoParto ~ "Tipo de Parto",
                            utiNeo ~ "Necessidade de UTI",
                            obito ~ "Mortalidade"),
              missing_text = "Dados ausentes") %>%
  bold_labels() %>% 
  modify_header(update = list(label ~ "**Características**",
                              stat_1 ~ "**Masculino** (N = 731)",
                              stat_2 ~ "**Feminino** (N = 637)")) %>% 
  add_p(pvalue_fun = function(x) style_pvalue(x, digits = 3))
tab
```
 
## Salvando a tabela 

```{r}
library (flextable)

tb <- as_flex_table(tab)

save_as_docx(tb, path = "RN.docx")
save_as_pptx(tb, path = "RN.pptx")
```

## Leitura Adicional  

1. Kabacof RI. **R in Action: Data analysis and graphics with R**. Shelter Island, NY: Manning Publications Co; 2011.Frequency and contingency tables;p.149-159.
2.	Oliveira Filho PF. **Epidemiologia e Bioestatística: fundamentos para a leitura crítica**. 2ª ed. Rio de Janeiro: Editora Rubio Ltda; 2022. Tabelas;p.9-12.
3. Sjoberg DD, Whiting K, Curry M, Lavery JA, Larmarange J. Reproducible summary tables with the gtsummary package. **The R Journal** 2021;13:570–80. https://doi.org/10.32614/RJ-2021-053.	
4. Soettewey A. Descriptive statistics in R. **Stats and R**, Louvain-la-Neuve, Bélgica, 22 de janeiro de 2020. Disponível em: <https://statsandr.com/blog/descriptive-statistics-in-r/>. Acesso em: 13 de agosto de 2022.


</br>
</br>


<!--chapter:end:09-tabelas.Rmd-->

# Gráficos  

## Pacotes necessários

```{r message=FALSE, warning=FALSE}
pacman::p_load(readxl, dplyr, plotrix, ggplot2, forcats, Hmisc, sciplot)
```

## Carregar os Dados

Para este capítulo, serão usados dados da maternidade escola do Hospital Geral de Caxias do Sul, incluídos nos arquivos [dadosMater](https://github.com/petronioliveira/Arquivos/blob/main/dadosMater.xlsx) e [dadosRNT](https://github.com/petronioliveira/Arquivos/blob/main/dadosRNT.xlsx).

Estes arquivos devem ser baixados para o seu diretório de trabalho.

Crie um objeto `mater` para receber os dadosMater.xlsx e um com o nome RNT para receber os dadosRNT, a partir do diretório de trabalho, executando os seguinte códigos:

```{r}
mater <- read_excel ("C:/Users/petro/Dropbox/Git_repositório/Arquivos/dadosMater.xlsx")
RNT <- read_excel ("C:/Users/petro/Dropbox/Git_repositório/Arquivos/dadosRNT.xlsx")
```

## Visão Geral do `dadosMater.xlsx`

Inicialmente, vamos ter uma visão geral do banco de dados, usando a função `glimpse ()`, do pacote `dplyr`. Ela nos mostra como os dados estão dispostos e a classe de cada variável. O banco tem 1368 linhas (casos) e 30 colunas (variáveis). Todas as variáveis estão como numéricas (dbl).

```{r}
glimpse (mater)
```

### Transformação e criação de variáveis

Vamos começar limitando o banco de dados, selecionando apenas  as variáveis que serão usados neste tutorial:  

```{r}
mater1 <- mater %>% 
  select(idadeMae, anosEst, fumo, para)

glimpse(mater1)
```
A seguir, vamos transformar a variável `fumo` como fator e criar duas novas variáveis a partir das variáveis `idadeMae` e `anosEst`, que também serão fatores:

```{r}
mater1$fumo <- factor (mater1$fumo,
                       levels = c(1, 2),
                       labels = c("sim", "não"))

mater1$categIdade <- cut (mater$idadeMae, 
                          breaks=c (13,20,36,46), 
                          labels = c ("<20a", "20-35a", ">35a"),
                          right = FALSE,
                          ordered_result = TRUE,
                          include.lowest = TRUE)

mater1$escolaridade <- cut (mater1$anosEst,
                            breaks= c (0,10,13,18),
                            right = FALSE,
                            labels = c("Fundamental",
                                       "Médio",
                                       "Superior"),
                            include.lowest = TRUE)

glimpse (mater1)
```
 
## Gráfico de Setores (Pizza)

Cada segmento (fatia) do gráfico de pizza deve ser proporcional à frequência da categoria que representa. A desvantagem do gráfico de pizza é que ele só pode representar uma variável, portanto, há necessidade de um gráfico separado para cada variável que se deseja representar. Além disso, um gráfico de pizza pode perder clareza se ele é usado para representar mais do que quatro ou cinco categorias.  
Os gráficos de pizza são amplamente conhecidos como uma maneira ruim de 
visualizar informações.  

Com variável `mater1$escolaridade` e, usando a função `table ()`, criamos uma tabela (`tab_escola`):

```{r}
tab_escola <- table(mater1$escolaridade)
tab_escola
```
Ou

```{r eval=FALSE}
tab_escola <- xtabs(~mater1$escolaridade, data = mater)
tab_escola
```

Usando as informações da `tab_escola`, cria-se o vetor `escola`:

```{r}
escola <- c(983, 358, 27)
```

Com a função `pie ()`, vamos construir o gráfico de setores:

```{r}
pie (escola, 
     labels = c ("Fundamental", 
                 "Médio", 
                 "Superior"),
     main = NULL,
     col = c ("skyblue", 
              "cyan", 
              "lightblue1"))
```

É possível, também, construir uma pizza em 3 D, usando a função `pie3D ()` do pacote `plotrix`:

```{r}
pie3D (escola, 
       labels = c("Fundamental", 
                  "Médio", 
                  "Superior"), 
       radius = 0.9, 
       explode = 0.1, 
       col = c ("skyblue", 
                "cyan", 
                "lightblue1"),  
       main="Grau de Instrução das Parturientes")
```

### Gráfico de setores com o ggplot2

Inicialmente, cria-se um dataframe, que chamaremos de `df_escola`, onde grupo são as categorias de escolaridade, n é a frequência de cada categoria e pro é a proporção de cada categoria (frequência de cada categoria dividido pelo total):

```{r}
df_escola <- data.frame(
  grupo = c("Fundamental", "Médio", "Superior"),
  n = c (983, 358, 27),
  prop = round(c((983/1368)*100, (358/1368)*100, (27/1368)*100),1))
df_escola
```

Vamos agora transformar o dataframe criado, usando as funções `arrange ()`, que colocará as categorias em ordem descentente, e `mutate ()`, que calculará a posição dos rótulos no eixo y. Ambas funções pertecem ao pacote `dplyr`:

```{r}
df_escola <- df_escola %>%
  arrange(desc(grupo)) %>%
  mutate(lab.ypos = cumsum(prop) - 0.5*prop)
df_escola
```

Para criar  gráfico de pizza com o ggplot2, usaremos como função chave o `geom_bar ()` + `coord_polar ()`. Adicionremos texto com a função `geom_text ()` e as cores de preenchimento com `scale_color_manual ()`. Será aplicado por último `theme_void ()` para remover eixos, fundos, etc.

As cores escolhidas são colocas em objeto `minhas_cores`:

```{r}
minhas_cores <- c("steelblue", "salmon", "yellow")
```

**Gráfico**

```{r}
ggplot(df_escola, aes(x = "", y = prop, fill = grupo)) +
  geom_bar(width = 1, stat = "identity", color = "white") +
  coord_polar("y", start = 0)+
  geom_text(aes(y = lab.ypos, label = prop), color = "black", size = 5)+
  scale_fill_manual(values = minhas_cores) +
  theme_void()
  
```

Voltaremos ao `ggplot2` mais adiante.

### Uma variação do gráfico de pizza: gráfico de rosca (*Donut chart*)

```{r}
ggplot(df_escola, aes(x = 2, y = prop, fill = grupo)) +
  geom_bar(stat = "identity", color = "white") +
  coord_polar(theta = "y", start = 0)+
  geom_text(aes(y = lab.ypos, label = prop), color = "black", size = 5)+
  scale_fill_manual(values = minhas_cores) +
  theme_void()+
  xlim(0.5, 2.5)
```


## Gráficos de Barras

### Gráfico de Barras Simples

Começamos construindo uma tabela usando a variável `mater1$categIdade`:

```{r}
tab_idade <- table(mater1$categIdade)
```

Após, usando a função `barplot ()`, construímos o gráfico de barras:

```{r}
barplot(tab_idade)
```

A seguir, usando outros argumentos próprios da função, melhoramos o aspecto do gráfico. O argumento `ylim =` vai corrigir o limite do eixo y que ficou em 800 e deveria ser 1000; `col =` tornará as barras de cor azul metálico (*steelblue*); `ylab =` e `xlab =` colocam rótulos nos eixos; `las = 1` faz o texto do eixo y ficar horizontal e `cex.lab = 1.2` aumenta o texto dos rótulos em 20%. A função `box (bty = "L")` (opcional) faz os eixos se encontraren em 0.

```{r}
barplot(tab_idade, 
        ylim = c (0,1000), 
        col= "steelblue", 
        border = "black", 
        ylab = "Frequência absoluta", 
        xlab = "Faixa etária", 
        cex.lab = 1.2,
        las = 1)
box(bty = "L")
```

Além disso, é possível fazer outras alterações para tornar o gráfico mais informativo, como as frequência de cada barra colocada no topo das mesmas:

* **1º Passo**: Criar um gráfico de barras , colocando-o em um objeto `x`, que conterá a coordenada *X* do centro de cada uma das barras. Para verificar isso basta executar o objeto `x`:

* **2º Passo**: colocar a tabela tab_idade com um objeto `y` da classe matriz:

* **3º Passo**: usar a funçãoo `text ()` para colocar os valores:

```{r}
x <- barplot(tab_idade, 
             ylim = c (0,1000), 
             col= "springgreen", 
             border = "black", 
             ylab = "Frequência absoluta", 
             xlab = "Faixa etária", 
             cex.lab = 1.2,
             las = 1)
box(bty = "L")

y <- as.matrix(tab_idade)

text (x, y, labels = as.character(y), adj = c(0.5, 2), col = "black")
```

O gráfico de barras simples pode ser construído com as barras horizontais. Basta usar o argumento `horiz = TRUE` e adaptando os eixoa *x* e *y*, para essa situação:

```{r}
barplot(tab_idade, 
        xlim = c (0,1000), 
        col= "salmon", 
        border = "black", 
        ylab= "", 
        xlab = "Frequência absoluta", 
        cex.lab = 1.3, 
        horiz=TRUE,
        las = 1)
box(bty = "L")
```

### Gráfico de Barras Empilhadas

Para este tipo de apresentação usamos, praticamente, os mesmos argumentos vistos para gerar um gráfico de barra simples. Como existem duas variáveis, há necessidade de avisar ao **R** como elas devem aparecer. Para isso, foi usado o argumento `beside = FALSE`, que informa que as barras não estarão uma ao lado da outra e sim empilhadas. O padrão é as barras ficarem uma ao lado da outra. Acresscenta-se uma legenda com a função `legend()` na parte superior esquerda (*topleft*). O argumento `bty = "n"` informa que não queremos um quadro ao redor da legenda e `fill = c ("dimgrey", "salmon")` são as cores das barras.

```{r}
tab_fumo <- table (mater1$fumo, mater1$categIdade)
tab_fumo

barplot (tab_fumo,  
         beside=FALSE, 
         ylim = c (0,1000), 
         xlab="Faixa Etária das gestantes", 
         ylab = "Frequência", 
         col = c ("dimgrey", "salmon"),  
         cex.lab = 1.2, 
         cex.axis = 1.2, 
         cex.names = 1.2)
box(bty = "L")

legend (legend=c ("Fumantes", "Não Fumantes"), 
        fill = c ("dimgrey", "salmon"), 
        bty="n", 
        cex = 1,
        "topleft")
```

### Gráfico de Barras Lado a Lado

É igual a anterior, apenas com o argumento `beside = TRUE`.

```{r}
barplot (tab_fumo,  
         beside=TRUE, 
         ylim = c (0,800), 
         xlab="Faixa Etária das gestantes", 
         ylab = "Frequência", 
         col = c ("dimgrey", "salmon"),  
         cex.lab = 1.2, 
         cex.axis = 1.2, 
         cex.names = 1.2)
box(bty = "L")

legend (legend=c ("Fumantes", "Não Fumantes"), 
        fill = c ("dimgrey", "salmon"), 
        bty="n", 
        cex = 1,
        "topleft")
```

### Gráfico de Barras com Variáveis Discretas

A variável para é uma variável numérica discreta e, para representá-la o mais adequado é usar um gráfico de barras simples.

```{r}
tab_filhos<- table (mater1$para) 

barplot (tab_filhos, 
         col = "salmon", 
         xlab="Número de filhos anteriores ao atual", 
         ylab = "Frequência",
         ylim = c(0, 500),
         cex.lab = 1.2, 
         cex.axis = 1.2, 
         cex.names = 1.2)
```

### Gráfico de Barras Simples com o ggplot2

Ele segue as seguintes etapas:

* Crie os dados como um data.frame

```{r}
table(mater1$categIdade)

df_idade <- data.frame (
  categ = c ("<20a", "20-35a", ">35a"),
  freq = c (219, 992, 157))

df_idade
```

Para a construção do gráfico:

* Comece chamando a função `ggplot ()`;
* Em seguida, especifique o objeto de dados, `df_idade`. Tem que ser um dataframe. Necessita uma variável numérica(`freq`) e outra categórica (`categ`);
* Então vem a estética, definida na função `aes ()`: defina a variável categórica para o eixo X, use a numérica para o eixo Y
* Finalmente, chame `geom_bar ()` . Você deve especificar `stat = "identity"` para este tipo de conjunto de dados e a largura das barras `width = 0.7`.
* Para controlar outros aspectos:
   - Cores: `color =` é para a borda da barra e `fill =` é a cor do preenchimento. Para estabelecer a cor de cada barra manualmnete, use `scale_fill_manual()`;
   - Para remover a legenda, use `theme(legend.position = "none")`
   - Pa um aspecto clássico, use `theme_classic ()`;
   - Para colocar as frequências no topo das barras, use `geom_text ()`;
   - para que as barras fiquem horizontais, usar `coord_flip ()`, fazendo ajustes para o texto das frequências e para os rótulos dos eixos.

```{r}
df_idade %>% 
  mutate(categ = factor(categ, levels=c("<20a", "20-35a", ">35a"))) %>% 
  ggplot(aes(x = categ, y=freq, fill = categ)) +
  geom_bar(stat = "identity", width = 0.7) +
  ylab("Frequência") +
  xlab("Idade da Parturiente") +
  scale_fill_manual(values = c("lightsalmon1", "salmon", "lightsalmon4")) +
  theme_classic() +
  theme(legend.position="none") +
  geom_text(aes(label=paste0(freq)), vjust=1.5, colour="white")
```

## Gráfico de Barra de Erro

### Exploração e Manipulação Arquivo `RNT.xlsx`

O arquivo `RNT.xlsx` tem a seguinte estruturs:

```{r}
glimpse (RNT)
```

Vamos selecionar apenas as variáveis `pesoRN` e `sexo` que serão recebidas por um objeto de nome `dados`:

```{r}
dados <- RNT %>% select(pesoRN, compRN, sexo)

glimpse (dados)
```

Observamos que a variável `sexo` está como numérica e deve ser transformada para fator:

```{r}
dados$sexo <- factor (dados$sexo, 
                levels = c(1, 2), 
                label = c("masc", "fem"))

glimpse (dados)
```

Agora, temos um conjunto de dados com uma variável numérica (`pesoRN`) e uma variável categórica (`sexo`), como fator.

#### Resumos Numericos

Vamos conhecer o resumo numérico da variável `pesoRN`, usando as funções `group_by ()` e `summarise ()` do pacote `dplyr`:  

```{r}
resumo <- dados %>% 
  group_by(sexo) %>% 
  summarise(n = n (),
            media = mean(pesoRN),
            dp = sd (pesoRN),
            mediana = median (pesoRN),
            IIQ = IQR (pesoRN)) %>% 
  mutate(ep = dp/sqrt(n)) %>% 
  mutate(me = ep * qt(1 - (0.05/2), n - 1))
resumo
```

Este resumo fornece o *n*, a *média*, o *desvio padrão*, a *mediana*, o *intervalo interquartil*, o *erro padrão* e a *margem de erro*.

#### Extrair Dois Subconjuntos de dados: meninos e meninas

```{r}
meninas <- dados %>% filter(sexo == "fem")

meninos <- dados %>% filter(sexo == "masc")
```

#### Resumos Numéricos dos dois subgrupos

```{r}
n1 <- nrow (meninos)
n2 <- nrow (meninas)

mu_m <- mean(meninos$pesoRN)
mu_f <- mean(meninas$pesoRN)

dp_m <- sd(meninos$pesoRN)
dp_f <- sd(meninas$pesoRN)

ep_m <- dp_m/sqrt(n1)
ep_f <- dp_f/sqrt(n2)
```

### Criação do Gráfico de Barra de Erro

Vamos seguir as seguintes etapas:

**1ª Etapa:**  

* Criação de um  vetor que recebe o nome `barras` com as médias dos subgrupos; 
* Este vetor será usado na construção do gráfico de barras;
* Incluir este em outro objeto, denominado de `bp`, que receberá o gráfico de barras.   

**2ª Etapa:**  

* Calcular a margem de erro ($me = 1.96 × dp$) em cada um dos grupos; 
* Com as margens de erro construir os limites do intervalo de confiança (${média} \pm {me}$).  

**3ª Etapa:**  

* Adcionar ao gráfico de barras os limites calculados, usando a função `errbar ()` do pacote `Hmisc`.

```{r}
barras <- c (mu_m, mu_f)

bp <- barplot(barras, 
              ylim=c(0,4500), 
              ylab = "Peso do Recém-nascido (g)",
              cex.lab = 1.3,
              cex.axis = 1.3,
              cex.names = 1.3,
              space = c(0,0.5),
              names.arg=c("Meninos", "Meninas"), 
              col = c("lightblue", " pink2"))
box(bty = "L")

me_m <-  1.96 * dp_m
me_f <- 1.96 * dp_f

lim_inf <- c(mu_m - me_m, mu_f - me_f)
round (lim_inf, 2)
lim_sup <- c(mu_m + me_m, mu_f + me_f)
round (lim_sup, 2)  

errbar(bp, barras, lim_sup, lim_inf, add=TRUE, xlab=NULL)
```

**OBS.:** Foram usados os desvios padrão na construção da margem de erro, mas o IC95% usa o erro padrão. Entretanto, como este é muito menor que o dp, optou-se pelo dp, por uma questão didática.

## Gráfico de Barra de Erro com o `ggplot2`

Vamos usar os mesmos dados anteriores e o resumo numérico do `resumo`.

### Construção do gráfico

Primeiro se constroi uma camada criando um gráfico de barra com a função `geom_bar ()`. Após, usando a função `geom_errorbar ()`, cria-se as barras de erro e a função `geom_point ()` coloca um ponto no valor das médias. Os demais comandos são os rótulos e tamanho dos textos, bem como o tema usado (`theme_classic()`):  

```{r}
p<- ggplot(resumo, aes(x=sexo, y=media, fill=sexo)) + 
  geom_bar(stat="identity", width = 0.4, color="black") +
  geom_point() +
  geom_errorbar(aes(ymin=media-dp, ymax=media+dp), width=0.1,
                position=position_identity()) +
  scale_fill_manual(values=c("lightskyblue1","pink2"))+
  theme(legend.position="none")
print(p)
# Final
p+labs(title="Peso do RN por Sexo", x="", y = "Peso do Recém-nascido (g)")+
  theme_classic() +
  theme(legend.position="none")
```

### Gráfico com apenas as barras superiores

```{r}
ggplot(resumo, aes(x=sexo, y=media, fill=sexo)) + 
  geom_bar(stat="identity", width = 0.4, color="black") +
  geom_point() +
  geom_errorbar(aes(ymin=media, ymax=media+dp), width=0.1,
                position=position_dodge(.9)) +
  labs(title="Peso do RN por Sexo", x="", y = "Peso do Recém-nascido (g)")+
  theme_classic() +
  theme(legend.position="none") +
  scale_fill_manual(values=c("lightskyblue1","pink2"))
```


## Gráfico de Barra de Erro com a Função `lineplot.CI ()`

Uma função simples para realizar um gráfico com barra de erro é a `lineplot.CI ()` do pacote `sciplot`.

Vamos criar o mesmo gráfico anterior, peso médio do recém-nascido por sexo, usando o erro padrão. O padrão é retornar ${média} \pm {ep}$. Entretanto, isto pode ser modificado com o argumento `ci.fun=` que usa a margem de erro, ou seja, $me = 1.96 × ep$.  

```{r}
lineplot.CI (dados$sexo, 
             dados$pesoRN,
             type = "p",
             xlab="", 
             ylab="Peso do RN (g)",
             lty = 2,
             las = 1,
             lwd = 3,
             err.col =  c("lightskyblue","pink3"),
             ci.fun= function(x) c(mean(x)-se(x)*qnorm(0.975),
                                   mean(x)+se(x)*qnorm(0.975)))
```

O argumento `type = "p"` determina um gráfico com pontos, mas sem linha de união. Se for substituído  por `type = "l"`, aparecem apenas as linhas de união e `type = "b"`, aparecem ambos.

## Histograma

O **histograma** é uma ferramenta gráfica que fornece informações sobre o formato da distribuição e dispersão dos dados, permitindo verificar se existe ou não simetria. É usado para dados contínuos.  
No histograma as frequências observadas são representadas por intervalos de classes de ocorrência que estão no eixo *x* e a altura das barras, representando a frequência de cada intervalo, no eixo *y*. A área de cada barra é proporcional à porcentagem de observações de cada intervalo.  
O **R** base possui uma função, denominada de hist () que constroi o histograma e possui vários argumentos:  

Argumento | Significado
:--- | :-----------
x | um vetor numérico usado na construção do histograma;
breaks | especifica a quantidade de barras;
freq | lógico; se [TRUE](anchor), o gráfico do histograma é uma representação de frequências, o componente de contagens do resultado; se [FALSE](anchor), densidades de probabilidade, densidade de componentes, são plotados. O padrão é [TRUE](anchor);
col | cor a ser usada para preencher as barras. O padrão de NULL produz barras não preenchidas;
border | cor da borda ao redor das barras. O padrão é usar a cor de primeiro plano padrão;
main, xlab, ylab | rótulo do título, do eixo *x* e do eixo *y*;
xlim, ylim  | limites do eixo *x* e do eixo *y*.
... |
     |
### Histograma Simples

Fazer um sumário dos dados para se ter uma ideia de como eles se comportam. Para isso, usar a função `summary ()` que nos entrega os valores mínimo, máximo, média, mediana e os percentis 25 e 75:

```{r}
summary(dados$pesoRN)
```

Vamos construir um histograma com a função `hist ()`:

```{r}
hist(dados$pesoRN)
```

Observando o histograma gerado, verifica-se alguns incovenientes que podem ser melhorados para tornar a sua aparência mais agradável.

* Os eixos apresentam textos com o nome da variável no eixo *x* e em língua inglesa no eixo *y*;
* O eixo *y* tem um limite superior menor do que a barra mais alta;
* O gráfico é entregue na cor cinza, que conforme o interesse pode ser modificada;
* O número de barras pode ser modificado com o argumento `breaks`. Existe uma função no **R** que permite calcular o número de intervalos, usando a *regra de Sturges*. Entretanto, na maioria das vezes, é o objetivo do estudo quem determina o número de barras e nem sempre o **R** obedece ao argumento `breaks =` . 

```{r}
nclass.Sturges(dados$pesoRN)
```

A função `nclass.Sturges()` fornece um resultado igual a 12.

```{r}
hist(dados$pesoRN,
     breaks = 12,
     ylim = c (0, 500),
     xlim = c (1000, 5000),
     main= NULL, 
     ylab = "Frequência", 
     xlab = "Peso do Recém-nascido (g)",
     col = "steelblue",
     las = 1)
box(bty = "L")
```

Observa-se que o histograma fica igual ao anterior, mudando a cor das barras, o limite do eixo *y* e os rótulos dos eixos. O **R** não modificou o número de barras. *Modifique o número de barras e veja o que acontece!*
     
### Histograma com curva normal sobreposta

Eventualmente, para melhor comparar a distribuição dos dados, usamos uma curva normal sobreposta que servirá de indicador.

**1º Passo:**   
Construir um histograma de densidade, que é a proporção de todas as observações que se enquadram dentro do intervalo. Na função `hist ()`, modificar o argumento  para `freq = TRUE`.

**2º Passo:**   
Adicionar uma curva normal ao histograma, usando a função `curve ()`. Calcular antes a média e o desvio padrão da variável `dados$pesoRN`.
Como os valores da densidade no eixo *y* estão como notação científica ($4e-04 = 4.10^{-4}$) , usamos a função `options(scipen = 999)` para remover e para retornar ao padrão, no final, usar `options (scipen = 0, digits = 7)`:

```{r}
mu <- mean(dados$pesoRN)
dp <- sd(dados$pesoRN)

options (scipen = 999)

hist(dados$pesoRN,
     xlim = c(1000, 5000),
     ylim = c(0, 0.001),
     main= NULL, 
     ylab = "Densidade", 
     xlab = "Peso do Recém-nascido (g)",
     col ="steelblue",
     freq = FALSE,            
     border = "white")
box (bty = "L")

curve (dnorm (x, 
              mean=mu, 
              sd=dp), 
       col="red", 
       lty=1,
       lwd=2,
       add=TRUE)

```

### Componentes do Histograma

Ao se criar um objeto da classe `histogram`, podemos verificar uma lista de componentes do mesmo, colocando o mesmo em um objeto, no exemplo, `h`.

```{r }
h <- hist(dados$pesoRN,
          breaks = 8,
          xlim = c(1000, 5000),
          ylim = c(0, 500),
          main= NULL, 
          ylab = "Frequência", 
          xlab = "Peso do Recém-nascido (g)",
          col ="seagreen2",
          freq = TRUE,           
          border = "white")
      box (bty = "L")
```

```{r}
h
```
Estes componentes podem ser usados para outras análises.

#### Construção de um histograma usando os componentes

Pode-se colocar os valores correspondentes às barras usando os componentes do histograma.

```{r}
hist(dados$pesoRN,
     breaks = 8,
     ylim = c(0, 500),
     xlim = c(1000, 5000),
     main= NULL, 
     ylab = "Frequência", 
     xlab = "Peso do Recém-nascido (g)",
     col = "salmon")
box (bty = "L")

text (h$mids, h$counts, labels = h$counts, adj= c(0.5, -0.5))
```


### Histograma usando o `ggplot2`

A função `geom_histogram ()` do pacote `ggplot2` é usada para a construção do histograma.

```{r}
dados %>% 
  ggplot(aes(x=pesoRN))+
  geom_histogram(color = "black", 
                 fill = "lightblue",
                 breaks = seq(1000, 5000, 250)) +
  theme_classic() +
  ylab("Frequência") +
  xlab("Peso do Recém-nascido (g)")
```

Podemos acrescentar uma linha na média com a função `geom_vline ()`: 

```{r}
dados %>% 
  ggplot(aes(x=pesoRN))+
  geom_histogram(color = "black", 
                 fill = "peachpuff",
                 breaks = seq(1000, 5000, 250)) +
  theme_classic() +
  ylab("Frequência") +
  xlab("Peso do Recém-nascido (g)") +
  geom_vline(aes (xintercept = mean(pesoRN)),
             color = "red", 
             linetype = "dashed", 
             size = 1)
```

### Histograma por grupos 

Usando o peso dos recém-nascidos(`pesoRN`) e o `sexo` do banco de dados `RNT`, vamos calcular a média e o desvio padrão por sexo, usando o pacote `dplyr`:

```{r}
medias <- dados %>% 
  group_by(sexo) %>% 
  summarise(media = mean(pesoRN),
            DP = sd (pesoRN))
medias 
```

Construção dos histogramas sobrepostos com suas respectivas médias:

```{r}
ggplot(dados, aes(x=pesoRN, fill=sexo)) +
  geom_histogram(position = "identity", bins = 20) +
  scale_fill_manual(values=c("lightskyblue1", "pink2")) +
  theme_classic() +
  geom_vline(data=medias, aes(xintercept=media, color=sexo),
             linetype="dashed") +
  xlab("Peso do Recém-nascido (g)") +
  ylab ("Frequência")
```

## Gráficos de Densidade

```{r}
plot (density(dados$pesoRN),
      frame = FALSE,
      ylim = c(0, 0.001),
      main = "",
      ylab = "Densidade",
      xlab = "Peso do recém-nascido (g)")
polygon (density (dados$pesoRN), col= "turquoise")
box (bty = "L")
```

**Restaurando o padrão de notação científica**

Como vimos no 2º Passo da construção do histograma com curva normal sobreposta, usou-se a função `options(scipen = 999)` que , agora, vamos voltar ao padrão, usando  o comando:

```{r}
options (scipen= 0, digits= 7)
```

## Boxplot

O **boxplot** descreve a distribuição de uma variável contínua exibindo o resumo de cinco números: mínimo, 1º quartil (percentil 25), mediana (percentil 50), 3ª quartil (percentil 75) e máximo. Pode também apresentar observações atípicas (*outliers*), valores fora do intervalo de ± 1,5 o intervalo interquartil, em geral, representados por (o). Valores que estão acima ou abaixo de 3 vezes o IIQ são considerados extremos, representados por (*). 

$~$
<center>

![](https://github.com/petronioliveira/Arquivos/blob/main/Boxplot.png)
 
</center> 
$~$

### Boxplot com a função nativa 

O **R** possui uma função no pacote básico denominada `boxplot ()` que constroi o gráfico.

```{r}
boxplot (dados$pesoRN)
```

Este boxplot pode ser modificado, alterando alguns argumentos como colocação de um título no gráfico, eótulos nos eixos e mudança na cor. Os argumento `cex.lab`, `cex.axis` e `cex.names` estabelecem o tamanho fontes. Por exemplo, está igual a 1 e para aumentar em 20%, usamos 1.2.

```{r}
boxplot (dados$pesoRN, 
         col = "lightblue2", 
         main = "RN a termo", 
         ylab = "Peso do Recém-nascido (g)",
         border = "black",
         cex.lab = 1, 
         cex.axis = 1, 
         cex.names = 1)
```

### Estatísticas do boxplot

A função `boxplot.stats ()` do pacote grDevices fornece as estatísticas do boxplot, facilitando a interpretação do mesmo, de modo semelhante ao visto para o histograma.

```{r}
boxplot.stats (dados$pesoRN)
```
* $stats = é o resumo dos 5 números: mínimo, percentil 25, mediana, percentil 75 e máximo
* $n = nº de obs; 
* $conf = limite inf/sup do entalhe se houver;
* $out = são os *outliers*


### Múltiplos boxplots

Os boxplots são muito usados na comparação de grupos. A necessidade mais comum é ordenar as categorias de acordo com o aumento da mediana, mas isto é opcional. Permite identificar rapidamente qual grupo tem o maior valor e como as categorias são classificadas.

```{r}
boxplot (dados$pesoRN ~ dados$sexo, 
         col = c("lightblue2", "pink"), 
         ylab = "Peso do Recém-nascido (g)", 
         xlab = "Sexo",
         ylim = c(1000, 5000),
         border = "black",
         cex.lab = 1, 
         cex.axis = 1, 
         cex.names = 1)
```

Podemos fazer um entalhe (*notch*) que podem ser interpretados como um intervalo de comparação em torno dos valores medianos. É calculado pela fórmula :$mediana \pm 1.57\times IIQ/\sqrt{n}$. No nosso exemplo, observe que o entalhe nos meninos está um pouco acima do das meninas..

```{r}
boxplot (dados$pesoRN ~ dados$sexo, 
         col = c("lightblue2", "pink"), 
         ylab = "Peso do Recém-nascido (g)", 
         xlab = "Sexo",
         ylim = c(1000, 5000),
         border = "black",
         cex.lab = 1, 
         cex.axis = 1, 
         cex.names = 1,
         notch = TRUE)
```

### Boxplots com `stripcharts`

A função `stripcharts ()` permite criar um gráfico de dispersão unidimensional sobre o boxplot. Você também pode personalizar o símbolo (pontos) para criar o gráfico, a largura da linha e sua cor com os argumentos `pch`, `lwd` e `col`, respectivamente. Alguns símbolos, como `pch = 21 a 25` permitem que você modifique a cor de fundo do símbolo com o argumento `bg`. O argumento `vertical = TRUE`, coloca os pontos na vertical sobreposto ao boxplot, quando o argumento `add = TRUE`. O argumento `cex = 0.3` é o tamanho dos pontos e `method = "jitter"`, espalha os pontos.

```{r}
boxplot (dados$pesoRN ~ dados$sexo, 
         col = c("lightblue2", "pink"), 
         ylab = "Peso do Recém-nascido (g)", 
         xlab = "Sexo",
         border = "black",
         cex.lab = 1, 
         cex.axis = 1, 
         cex.names = 1,
         pch = 20,
         cex = 0.8,
         outline = TRUE)

stripchart(dados$pesoRN ~ dados$sexo,
           method = "jitter",
           main=NULL,
           col = c("blue", "red"),
           vertical=TRUE,
           pch=16,
           cex = 0.3,
           add = TRUE)
```

### Boxplots horizontais

Para criar um boxplot horizontal, usamos o argumento `horizontal = TRUE` e invertemos os rotulos dos eixos *x* e *y*.

```{r}
boxplot (dados$pesoRN ~ dados$sexo, 
         col = c("lightblue2", "pink2"), 
         xlab = "Peso do Recém-nascido (g)", 
         ylab = "Sexo",
         horizontal = TRUE,
         border = "black",
         cex.lab = 1, 
         cex.axis = 1, 
         cex.names = 1,
         pch = 20,
         cex = 0.8)
```


### Boxplot com o `ggplot2`

#### Boxplot único

```{r}
dados %>% 
  ggplot(aes(x = "", y = pesoRN)) +
  geom_boxplot ()
```

Algumas modificações:

1. Adicionar a barra de erro com o `geom_errorbar ()`  
2. No `geom_boxplot()` os argumento que determinam a largura da caixa e o formato, o tamanho e a cor dos *outliers*.   
3. Acrescentar a camada `labs ()`, modificandor o nome dos eixos `y` e `x`.   
4. Para mudar o aspecto, removendo o fundo cinza do padrão do `ggplot2`, altera-se o `theme ()` para um dos múltiplos possíveis.

```{r}
dados %>% 
  ggplot(aes(x = "", y = pesoRN)) +
  geom_errorbar(stat = "boxplot", width = 0.2) +
  geom_boxplot (width = 0.6,
                fill = "grey90",
                outlier.color = "red", 
                outlier.shape = 1,
                outlier.size = 2) +
  labs(y = "Peso do Recém-nascido (g)",
       x = "Todos os RN") +
  theme_classic()
```

5. Para remover os *outliers* (apesar de não ser recomendado!), basta substituir a cor do argumento `outliers.color` por `NA`.

```{r}
dados %>% 
  ggplot(aes(x = "", y = pesoRN)) +
  geom_errorbar(stat = "boxplot", width = 0.2) +
  geom_boxplot (width = 0.6,
                fill = "grey90",
                outlier.color = "NA", 
                outlier.shape = 1,
                outlier.size = 2) +
  labs(y = "Peso do Recém-nascido (g)",
       x = "Todos os RN") +
  theme_classic()
```

6. Podemos inserir a média no gráfico, usando o `geom_point ()`, após a camafa do `geom_boxplot()`:

```{r}
dados %>% 
  ggplot(aes(x = "", y = pesoRN)) +
  geom_errorbar(stat = "boxplot", width = 0.2) +
  geom_boxplot (width = 0.6,
                fill = "grey90",
                outlier.color = "red", 
                outlier.shape = 1,
                outlier.size = 2) +
  geom_point(stat = "summary", 
             fun = "mean", 
             shape = 19,
             size = 3, 
             color = "red") +
  labs(y = "Peso do Recém-nascido (g)",
       x = "Todos os RN") +
  theme_classic()
```

7. Uma outra modificação que pode ser feita é alterar o comprimento dos "bigodes", cujo padrão é 1,5 vezes o intervalo interquartil (IIQ), usando o argumento `coef` do `geom_boxplot ()`. **Importante**: para coincidir com as barras de erro, devemos também alterar o `coef` do `geom_errorbar ()` para o mesmo valor.

```{r}
dados %>% 
  ggplot(aes(x = "", y = pesoRN)) +
  geom_errorbar(stat = "boxplot", 
                width = 0.2,
                coef = 3) +
  geom_boxplot (width = 0.6,
                fill = "grey90",
                outlier.color = "red", 
                outlier.shape = 1,
                outlier.size = 2,
                coef = 3) +
  geom_point(stat = "summary", 
             fun = "mean", 
             shape = 19,
             size = 3, 
             color = "red") +
  labs(y = "Peso do Recém-nascido (g)",
       x = "Todos os RN") +
  theme_classic()
```

Observe que os *outliers* desapareceram, significando que não existem *outliers* extremos.  

8. Da mesma forma que nos comandos básicos, é possível colocar o boxplot na posição horizontal, usando a camada `coord_flip()`:

```{r}
dados %>% 
  ggplot(aes(x = "", y = pesoRN)) +
  geom_errorbar(stat = "boxplot", 
                width = 0.2,
                coef = 1.5) +
  geom_boxplot (width = 0.6,
                fill = "grey90",
                outlier.color = "red", 
                outlier.shape = 1,
                outlier.size = 2,
                coef = 1.5) +
  geom_point(stat = "summary", 
             fun = "mean", 
             shape = 19,
             size = 3, 
             color = "red") +
  labs(y = "Peso do Recém-nascido (g)",
       x = "Todos os RN") +
  coord_flip() + 
  theme_classic()
```

**Obs.**: O `coef` voltou para o padrão de 1.5, como idealizado pelo importante estatístico americano John Wilder Tukey (1915 - 2000).  
9. Para evitar a sobreposição dos *outliers* pode-se usar o `geom_boxplot_jitter ()`, do pacote `ggrastr`, no lugar da camada `geom_boxplot ()`.

```{r}
pacman::p_load(ggrastr)

dados %>% 
  ggplot(aes(x = "", y = pesoRN)) +
  geom_errorbar(stat = "boxplot", 
                width = 0.2,
                coef = 1.5) +
  geom_boxplot_jitter (width = 0.6, 
                       fill = "grey90",
                       outlier.color = "red", 
                       outlier.shape = 1,
                       outlier.size = 2,
                       coef = 1.5,
                       outlier.jitter.height = 0,
                       outlier.jitter.width = 0.02) +
  geom_point(stat = "summary", 
             fun = "mean", 
             shape = 19,
             size = 3, 
             color = "red") +
  labs(y = "Peso do Recém-nascido (g)",
       x = "Todos os RN") +
  theme_classic()
```

#### Boxplot por grupos

A função `geom_boxplot ()`, usada para criar o boxplot único, permite criar mais de um boxplot, colocando no eixo `x` a variável separadora, no exemplo, `sexo`: 

```{r}
dados %>% 
  ggplot(aes(x = sexo, y = pesoRN)) +
  geom_errorbar(stat = "boxplot", 
                width = 0.2,
                coef = 1.5) +
  geom_boxplot (width = 0.6,
                fill = "grey90",
                outlier.color = "red", 
                outlier.shape = 1,
                outlier.size = 2,
                coef = 1.5) +
  geom_point(stat = "summary", 
             fun = "mean", 
             shape = 19,
             size = 3, 
             color = "red") +
  labs(y = "Peso do Recém-nascido (g)",
       x = "") + 
  theme_classic()
```

Podemos mudar o rótulos do eixo `x` sem mudar no banco de dados, substituindo `masc` por `Meninos` e `fem` por `Meninas`, simplemente modificando os rótulos no argumento `labels` da função `scale_x_discrete ()` em uma nova camada.

```{r}
dados %>% 
  ggplot(aes(x = sexo, y = pesoRN)) +
  geom_errorbar(stat = "boxplot", 
                width = 0.2,
                coef = 1.5) +
  geom_boxplot (width = 0.6, 
                fill = "grey90",
                outlier.color = "red", 
                outlier.shape = 1,
                outlier.size = 2,
                coef = 1.5) +
  geom_point(stat = "summary", 
             fun = "mean", 
             shape = 19,
             size = 3, 
             color = "red") +
  labs(y = "Peso do Recém-nascido (g)",
       x = "") + 
  scale_x_discrete (labels = c("Meninos", "Meninas")) +
  theme_classic()
```

Se quisermos colocar cores diferentes para cada uma das caixas, adicionamos o argumento `fill` no `aes ()`, removendo o mesmo argumento do `geom_boxplot ()`:

```{r}
dados %>% 
  ggplot(aes(x = sexo, y = pesoRN, fill = sexo)) +
  geom_errorbar(stat = "boxplot", 
                width = 0.2,
                coef = 1.5) +
  geom_boxplot (width = 0.6,
                outlier.color = "red", 
                outlier.shape = 1,
                outlier.size = 2,
                coef = 1.5) +
  geom_point(stat = "summary", 
             fun = "mean", 
             shape = 19,
             size = 3, 
             color = "red") +
  labs(y = "Peso do Recém-nascido (g)",
       x = "") + 
  scale_x_discrete (labels = c("Meninos", "Meninas")) +
  theme_classic()
```

Agora, vamos remover a legenda com a função `theme(legend.position = "none"`,  estabelecer as cores para o preenchimento das caixas manualmente com a função `scale_fill_manual ()`:

```{r}
dados %>% 
  ggplot(aes(x = sexo, y = pesoRN, fill = sexo)) +
  geom_errorbar(stat = "boxplot", 
                width = 0.2,
                coef = 1.5) +
  geom_boxplot (width = 0.6,
                outlier.color = "red", 
                outlier.shape = 1,
                outlier.size = 2,
                coef = 1.5) + 
  scale_fill_manual(values = c("cyan", "salmon")) +
  geom_point(stat = "summary", 
             fun = "mean", 
             shape = 19,
             size = 3, 
             color = "red") +
  labs(y = "Peso do Recém-nascido (g)",
       x = "") + 
  scale_x_discrete (labels = c("Meninos", "Meninas")) +
  theme_classic() +
  theme(legend.position="none")
```

## Gráfico de Dispersão (`Scatterplot`)  

Um gráfico de dispersão (**Scatterplot**) exibe a relação entre duas variáveis numéricas. Cada ponto representa uma observação. Suas posições nos eixos x (horizontal) e y (vertical) representam os valores das duas variáveis. 
O **R* Base é uma boa opção para construir um gráfico de dispersão, usando a função `plot ()`. Ambas as variáveis numéricas do banco de dados devem ser especificadas nos argumentos *x* e *y*.  
Vamos verificar se existe uma correlação entre o comprimento e o peso dos recém-nascidos:

```{r}
plot (x = dados$compRN,
      y = dados$pesoRN,
      ylab = "Peso de Recém-nascido (g)",
      xlab = "Comprimento do Recém-nascido (cm)",
      las = 1)
```

Este mesmo gráfico pode ser obtido, usando uma fórmula `y~x`:

```{r eval=FALSE}
plot (pesoRN ~ compRN,
      data = dados,
      ylab = "Peso de Recém-nascido (g)",
      xlab = "Comprimento do Recém-nascido (cm)",
      las = 1,
      bty = "L")
```

Como acontece na maioria dos gráficos básicos, também podemos melhorar o aspecto do *scatterplot*, tornando os pontos sólidos, cloridos, etc.

```{r}
plot (pesoRN ~ compRN,
      data = dados,
      col = "steelblue",
      ylab = "Peso de Recém-nascido (g)",
      xlab = "Comprimento do Recém-nascido (cm)",
      las = 1,
      bty = "L",
      pch = 19,
      cex = 1,
      cex.lab = 1,
      cex.axis = 0.8)
```

Como os pontos estão aglomerados, devido a quantidade, pode tentar espalhar, usando a função `jitter ()` na variável `compRN`. O argumento 10 é variável e significa o grau de espalhamento:

```{r}
plot (jitter(dados$compRN,10),
      dados$pesoRN,
      col = "steelblue",
      ylab = "Peso de Recém-nascido (g)",
      xlab = "Comprimento do Recém-nascido (cm)",
      las = 1,
      bty = "L",
      pch = 19,
      cex = 1,
      cex.lab = 1.2,
      cex.axis = 0.8)
```

### Mapeamento dos pontos de acordo com uma variável categórica

Inicialmente, vamos criar um vetor para representar as cores, de acordo com o sexo (meninos = azul; meninas = rosa). Usamos a função `unclass(dados$sexo)` para discriminar os sexos.



```{r}
cores <- c("steelblue", "pink3")

plot(x = jitter(dados$compRN, 10), 
  y = dados$pesoRN,
  bg = cores[ unclass(dados$sexo) ],
  ylab = "Peso de Recém-nascido (g)",
  xlab = "Comprimento do Recém-nascido (cm)",
  las = 1,
  bty = "L",
  cex = 2,
  pch=21,
  cex.lab = 1,
  cex.axis = 0.8)

legend (legend=c ("Meninos", "Meninas"), 
        fill = cores, 
        bty="n", 
        cex = 1,
        "topleft")
```


### Adição da reta de ajuste

Uma linha reta de ajuste dos dados pode ser acrescentada usando a função `abline ()`, associada a função `lm ()`. Um modelo típico lm (*linear model*) tem o formato resposta (*y*) ~ preditor (*x*). Mais detalhes sobre o modelo de ajuste linear na regressão linear.

```{r}
# Construção do gráfico de dispersão
plot (jitter(dados$compRN,10),
      dados$pesoRN,
      col = "steelblue",
      ylab = "Peso de Recém-nascido (g)",
      xlab = "Comprimento do Recém-nascido (cm)",
      las = 1,
      bty = "L",
      pch = 16,
      cex = 1,
      cex.lab = 1,
      cex.axis = 0.8)

# Criação do modelo de ajuste
modelo <- lm (dados$pesoRN ~ dados$compRN)

# Adição da reta, usando o modelo
abline (modelo, 
        col="red", 
        lwd=2, 
        lty = 2)
```

Se executarmos o modelo, obtemos os parâmetros para a construção da equação da regressão linear:

```{r}
summary(modelo)
```

A equação de predição da regressão linear permite que sabendo o valor do comprimento é possível prever o peso do recem-nascido:

$$
\hat{y} = b_{0}+ b_{1}\times x
$$
Desta forma, substituindo pelos valores contidos nas estimativas da tabela dos coeficientes do sumário do modelo, um bebê com 50 cm terá um peso de aproximadamente:

$$
\hat{y} = -3416.45 + 137.67\times 50 = 3467.05
$$

### Gráfico de Dispersão com o `ggplot2`

Para a construção de um gráfico de dispersão, usando o ggplot2, usamos a função `geom_point ()`. Um gráfico de dispersão simples é obtido como se segue:

```{r}
dados %>% 
  ggplot(aes(x = compRN,  y = pesoRN)) +
  geom_point()
```

Modifica-se o tamanho e formato do ponto com:

```{r}
dados %>% 
  ggplot(aes(x = compRN,  y = pesoRN)) +
  geom_point(size = 2, shape = 16) +
  ylab("Peso do RN (g)") +
  xlab("Comprimento do RN (cm)") +
  theme_classic()
```


## Leitura Adicional  

1. Holtz Y. Barplot.**The R Graph Gallery.  ** Disponível em: <https://www.r-graph-gallery.com/barplot.html>. Acesso em 14/08/2022.  

2. Holtz Y. Barplot.**The R Graph Gallery.  ** Disponível em: <https://www.r-graph-gallery.com/4-barplot-with-error-bar.html>. Acesso em 14/08/2022.  

3. H. Wickham. **ggplot2: Elegant Graphics for Data Analysis**. Springer-Verlag New York, 2016. Disponível em: <https://ggplot2.tidyverse.org/reference/geom_bar.html> Acesso em 14/08/2022.

4. H. Wickham. **ggplot2: Elegant Graphics for Data Analysis**. Springer-Verlag New York, 2016. Disponível em: <https://ggplot2.tidyverse.org/reference/geom_boxplot.html> Acesso em 17/08/2022.

5. H. Wickham. **ggplot2: Elegant Graphics for Data Analysis**. Springer-Verlag New York, 2016. Disponível em: <https://ggplot2.tidyverse.org/reference/geom_point.html> Acesso em 17/08/2022.

6. Kassambara A. ggplot2 histogram plot : Quick start guide. **STHDA - Statistical tools for high-throughput data analysis**. Disponível em: <http://www.sthda.com/english/wiki/ggplot2-histogram-plot-quick-start-guide-r-software-and-data-visualization>. Acesso em 15/08/2022.

7. Oliveira Filho PF. **Epidemiologia e Bioestatística: fundamentos para a leitura crítica**. 2ª ed. Rio de Janeiro: Editora Rubio Ltda; 2022. Gráficos;p.13-24.


</br>
</br>

<!--chapter:end:10-graficos.Rmd-->

# Distribuição Normal

## Pacotes necessários

```{r message=FALSE, warning=FALSE}
pacman::p_load(readxl, dplyr, ggplot2, tidyr, rcompanion)
```
## Carregar o Banco de Dados

O banco de dados a ser carregado encontra-se [aqui](https://github.com/petronioliveira/Arquivos/blob/main/dadosAltura.xlsx). Ele é constituído por medidas de altura (em metros) de dois grupos de mulheres, pertencentes a duas regiões geográficas diferentes. Salve o mesmo no diretório de trabalho.  
Crie um objeto `dados` para recebê-lo, a partir do diretório de trabalho, executando o seguinte código:

```{r}
dados <- read_excel ("C:/Users/petro/Dropbox/Git_repositório/Arquivos/dadosAltura.xlsx")
```
## Exploração e manipulação do banco de dados

```{r}
head (dados, 10)
```

Os `dados` estão dispostos no formato longo e vamos transformá-los no formato amplo (grupos lado a lado), usando a função `spread ()` do pacote `tidyr`.

```{r}
dados1 <- spread(dados, pop, value="altura")
head (dados1,10)
```

Renomear as colunas, denominadas de 1 e 2, do novo banco de dados (2ª e 3ª colunas, respectivamente), usando a função `names ()`:

```{r}
names(dados1)[2:3] <- c("pop1", "pop2")
head (dados1, 10) 
```

Agora, temos duas populações de 300 mulheres, colocadas lado a lado, como `pop1` e `po2.`

### Resumo dos dados

```{r}
summary (dados1)
```
#### Média e desvios padrão das populações

```{r}
mu1 <- mean(dados1$pop1)
dp1 <- sd(dados1$pop1)
mu1
dp1

mu2 <- mean(dados1$pop2)
dp2 <- sd(dados1$pop2)
mu2
dp2
```

### Visualização dos dados através do histograma
#### População 1

```{r}
dados1 %>% 
  ggplot(aes(x=pop1))+
  geom_histogram(color = "black", 
                 fill = "peachpuff",
                 breaks = seq(1.3, 1.9, 0.04)) +
  theme_classic() +
  ylab("Frequência") +
  xlab("Altura de mulheres - população 1 (m)") +
  geom_vline(aes (xintercept = mean(pop1)),
             color = "red", 
             linetype = "dashed", 
             size = 1)
```

Colocando uma curva normal sobreposta, usando a função `plotNormalHistogram()` do pacote `rcompanion.` O gráfico resultante pode ser usado para comparar rapidamente a distribuição de dados a uma distribuição normal. Se `prob = [TRUE](anchor)`, a densidade é mostrada, caso contrário é mostrada a frequência.


```{r}
plotNormalHistogram(dados1$pop1,
                    prob = TRUE,
                    breaks = seq(1.3, 1.9, 0.04),
                    col = "peachpuff",
                    main = "",
                    linecol = "red",
                    lwd = 2,
                    length = 1000,
                    ylab = "Densidade",
                    xlab = "Altura de mulheres - população 1 (m)")
box(bty = "L")
abline (v= (mean(dados1$pop1)), lwd = 2, lty = 2, col = "red")
```

#### População 2

```{r}
dados1 %>% 
  ggplot(aes(x=pop2))+
  geom_histogram(color = "black", 
                 fill = "salmon",
                 breaks = seq(1.1, 1.7, 0.04)) +
  theme_classic() +
  ylab("Frequência") +
  xlab("Altura de mulheres - população 2(m)") +
  geom_vline(aes (xintercept = mean(pop2)),
             color = "red", 
             linetype = "dashed", 
             size = 1)
```

E colocando uma curva normal sobreposta:

```{r}
plotNormalHistogram(dados1$pop2,
                    prob = TRUE,
                    breaks = seq(1.1, 1.7, 0.04),
                    col = "salmon",
                    main = "",
                    linecol = "red",
                    lwd = 2,
                    length = 1000,
                    ylab = "Densidade",
                    xlab = "Altura de mulheres - população 2(m)")
box(bty = "L")
abline (v= (mean(dados1$pop2)), lwd = 2, lty = 2, col = "red")
```

A distribuição de uma variável em um conjunto de dados fornece informações 
sobre:

* Todos os valores que a variável assume em seu conjunto de dados, quando os dados são divididos em grupos de tamanhos razoáveis
* Com que frequência cada valor ocorre
* A forma, centro e quantidade de variabilidade nos dados

Verificar a distribuição dos dados é sempre uma das primeiras etapas da análise dos dados. Ao conhecer o formato dos dados, você obtém conhecimento sobre algumas das propriedades estatísticas dos mesmos.

Observando os histograma das duas populações, verificamos que ambos têm uma distribuição bastante simétrica, com as médias (linha tracejada em vermelho) praticamente no centro das distribuições.

## Distribuição normal

Analisando as curvas sobrepostas às distribuições das populações 1 e 2, verificamos que elas possuem algumas características importantes:

* Existe um único pico;
* A massa da distribuição está no centro;
* Há simetria em relação à linha central, representada pela média do conjunto de dados;
* O formato da curva é semelhante a um sino, ou seja, à medida que os dados se afastam da média, diminui a probabilidade de serem encontrados. 
  - Este formato, portanto, depende da variabilidade dos dados (magnitude do desvio padrão)
  
```{r echo=FALSE}
curve (dnorm (x, 
              mean=mu1, 
              sd=dp1), 
       col="steelblue", 
       lty=1,
       lwd=2,
       add=F,
      xlim = c(1,2),
      ylab = "Densidade",
      xlab = "Altura de mulheres (m)",
      bty = "n")
box(bty = "L")
abline (v= (mean(dados1$pop1)), lwd = 2, lty = 2, col = "red")
text(1.73, 5.5, "População 1", cex = 1, col = "steelblue")

curve (dnorm (x, 
              mean=mu2, 
              sd=dp2), 
       col="darkred", 
       lty=1,
       lwd=2,
       add=T)
box(bty = "L")
abline (v= (mean(dados1$pop2)), lwd = 2, lty = 2, col = "red")
text(1.25, 5.5, "População 2", cex = 1, col = "darkred")
```
  
As curvas de distribuição de dados que se comportam desta maneira são conhecidas por **curva normal** ou **curva gaussiana**. Os parâmetros da curva normal são a *média* e o *desvio padrão*.  

Observe no gráfico anterior das curvas de distribuição das duas populações sendo estudadas. Elas têm o mesmo formato, porque como calculado acima, elas têm o mesmon desvio padrão, a diferença está na média mais baixa da população 2.

Se tivéssemos uma terceira população, com média igual a população 1 (`r round(mean (dados1$pop1), 3)` m), mas com maior desvio padrão, por exemplo 10 cm, teríamos uma curva sobreposta a da população 1, mas mais achatada.

```{r echo=FALSE}
curve (dnorm (x, 
              mean=mu1, 
              sd=dp1), 
       col="steelblue", 
       lty=1,
       lwd=2,
       add=F,
      xlim = c(1,2),
      ylab = "Densidade",
      xlab = "Altura de mulheres (m)",
      bty = "n")
box(bty = "L")
abline (v= (mean(dados1$pop1)), lwd = 2, lty = 2, col = "red")
text(1.73, 5.5, "População 1", cex = 1, col = "steelblue")

curve (dnorm (x, 
              mean=mu2, 
              sd=dp2), 
       col="darkred", 
       lty=1,
       lwd=2,
       add=T)
abline (v= (mean(dados1$pop2)), lwd = 2, lty = 2, col = "red")
text(1.25, 5.5, "População 2", cex = 1, col = "darkred")

curve (dnorm (x, 
              mean=mu1, 
              sd=0.1), 
       col="green3", 
       lty=1,
       lwd=2,
       add=T)
text(1.8, 2.5, "População 3", cex = 1, col = "green3")
```


Como estamos observando, se tivermos um desvio padrão pequeno, ele torna a curva mais pontiaguda; desvio padrão grande, achata a curva (população 3). Se as médias são diferentes, mas com mesmo desvio padrão, elas são iguas, mas em posições diferentes. Se for uma média menor, ficará a esquerda da curva com média maior ( população 2 vs população 1). 
Em outras palavras, as curvas normais dependem da média e de seu desvio padrão. Modificando qualquer um deles, teremos curvas distintas.

### Curva Normal Padronizada

Cada variável aleatória contínua tem a sua média e seu desvio padrão e, portanto, a sua curva normal correspondente. Para facilitar a comparação entre variáveis, foi criado o conceito de **curva normal padronizada**, que é uma curva normal com média 0 e desvio padrão 1. A distribuição normal padrão também pode ser chamada de *distribuição normal centrada* ou *reduzida*.  
A métrica usada para a padronização é denominada de **escore *Z*** que é uma medida de posição que indica o número de desvios padrão em que um valor se encontra a partir da sua média. 

$$
Z =\frac{x-\overline{x}}{s}
$$

Desta forma, podemos verificar quantos desvios padrão uma mulher da população 1 que mede 1,725 m está distante da média de 1,598 m. Assim:

$$
Z =\frac{1.725-1.598}{0.0656}\approx 1.959
$$

Ao invés de usarmos a fórmula manualmente, podemos escrevê-la no *R Script* para que ele faça o trabalho por nós:

```{r}
x <- 1.725
z <- (x-mean(dados1$pop1))/sd(dados1$pop1)
z
```

Portanto, esta mulher está distante praticamente 2 desvios padrão acima da média. Para esta população, ela é considerada alta. Por que? 

Para responder a essa pergunta, precisamos calcular a probabilidade de encontrar uma mulher com esta altura na população1.  

O **R** tem uma função que faz este cálculo, rapidamente, sem necessidade de consultar tabelas: é a função `pnorm ()`. Esta função retorna a probabilidade abaixo do valor de *Z* questionado, pressupondo média 0 e desvio padrão 1, baseado na distruição normal padronizada $$X \sim {\sf Norm}(0, 1) \\$$.
```{r}
z <- pnorm(1.959, mean = 0, sd = 1)
z
```

Como abaixo de 1,725 m, temos 0,975 ou 97,5% das mulheres, acima seriam 1 - 97,5 = 2,5% das mulheres. Ou seja, comparativamente, uma mulher com 1,725 m, na população 1, é considerada alta.

Qual a probabilidade de se encontrar mulheres que tenham altura abaixo da média?

```{r}
x <- mean(dados1$pop1)
z <- (x-mean(dados1$pop1))/sd(dados1$pop1)
z
z <- pnorm(0, mean = 0, sd = 1)
z
```

Ou seja, a probabilidade de se encontrar mulheres abaixo da média é igual a 50%.

Vimos, até agora, que um uso extremamante útil da distribuição normal padronizada é ,facilmente, permitir o cálculo das probabilidades dentro de uma variável aleatória.  
Isso permite que, usando a função `pnorm()`, se calcule a probabilidade entre quaiquer valores de z escore. Por exemplo, a probabilidade de se encontrar valores que se situem entre -1 e +1 escore z é:

```{r}
z1 <- pnorm(-1, mean = 0, sd = 1)
z1

z2 <- pnorm(1, mean = 0, sd = 1)
z2

abs(z1 - z2)
```

portanto, entre -1 e +1 escores z, encontramos 68,3% dos valores da ditribuição normal.  

Se repetirmos os cálculos para os escores  z -2 e +2, qual a probabiidade?

```{r}
z1 <- pnorm(-2, mean = 0, sd = 1)
z1
z2 <- pnorm(2, mean = 0, sd = 1)
z2
abs(z1 - z2)
```

Entre, -2 e +2 escores z, encontramos 95,5% dos valores da ditribuição normal.

E entre -3 e +3?

```{r}
z1 <- pnorm(-3, mean = 0, sd = 1)
z1
z2 <- pnorm(3, mean = 0, sd = 1)
z2
abs(z1 - z2)
```

Entre, -3 e +3 escores z, encontramos 99,7% dos valores da ditribuição normal.

#### Regra Empírica 68-95-99.7

A regra empírica diz que, se uma população de um conjunto de dados tem uma distribuição normal com média 0 e desvio padrão 1 (X ~ Norm (0,1)) podemos afirmar que:
* Aproximadamente, 68% dos valares entram-se dentro de $\pm$ 1 desvio padrão da média;
$$
\mu \pm \sigma
$$
* Aproximadamente, 95% dos valores encontram-se dentreo de $\pm$ 2 desvios padrão da média; 
$$
\mu \pm 2 \sigma
$$
* Cerca de 99,7% dos valores encontram-se dentro de $\pm$ 3 desvios padrão da média.
$$
\mu \pm 3 \sigma
$$

Esta regra pode ser usada para descrever uma população, em vez de uma amostra, mas você também pode usá-la para ajudar a decidir se uma amostra de dados veio de uma distribuição normal. Se uma amostra é grande o suficiente e você observar que o seu histograma tem um formato parecido com um sino, você pode verificar se os dados seguem as especificações 68-95-99,7%. Se sim, é razoável concluir que os dados vieram de uma distribuição normal.

Se usarmos a população 1  e voltarmos a observar o histograma com uma curva normal sobreposta, temos:

```{r echo=FALSE}
plotNormalHistogram(dados1$pop1,
                    prob = TRUE,
                    col = "peachpuff",
                    main = "",
                    linecol = "red",
                    lwd = 2,
                    length = 1000,
                    ylab = "Densidade",
                    xlab = "Altura de mulheres (m)")
box(bty = "L")

abline (v = 1.598, lwd = 2, lty = 3, col = "red")
text(1.598, 2, "0", cex = 2, col = "red")
text(1.598, 6.2, "1.598", cex = 1, col = "red")

abline (v = 1.663, lwd = 2, lty = 3, col = "green4")
text(1.663, 2, "1", cex = 2, col = "green4")
text(1.663, 6.2, "1.663", cex = 1, col = "green4")

abline (v = 1.532, lwd = 2, lty = 3, col = "green4")
text(1.532, 2, "-1", cex = 2, col = "green4")
text(1.532, 6.2, "1.532", cex = 1, col = "green4")

abline (v = 1.729, lwd = 2, lty = 3, col = "magenta")
text(1.729, 2, "2", cex = 2, col = "magenta")
text(1.729, 6.2, "1.729", cex = 1, col = "magenta")

abline (v = 1.467, lwd = 2, lty = 3, col = "magenta")
text(1.467, 2, "-2", cex = 2, col = "magenta")
text(1.467, 6.2, "1.467", cex = 1, col = "magenta")

abline (v = 1.794, lwd = 2, lty = 3, col = "salmon")
text(1.794, 2, "3", cex = 2, col = "salmon")
text(1.794, 6.2, "1.794", cex = 1, col = "salmon")


abline (v = 1.402, lwd = 2, lty = 3, col = "salmon3")
text(1.402, 2, "-3", cex = 2, col = "salmon3")
text(1.402, 6.2, "1.402", cex = 1, col = "salmon3")
```

Olhando gráfico e sem realizar nenhum cálculo, sabemos, pela regra empírica, que entre 1.532 m (Z = -2) e 1.663 m (Z = 2) encontramos aproximadamente 68% das mulheres desta população 1. Isto ajuda no dia ao se observar dados.

## Exercício

Suponha que eu esteja atendendo uma mulher que mede 1,50 m, a qual população existe maior probabilidade de ela pertencer?

**População 1**

Verificar a probabilidade de se encontra mulheres com esta altura na população 1, calculando o seu escore z na população 1.

```{r}
x <-  1.50
z1 <-  (x - mu1)/dp1
z1 
p1 <- pnorm (z1)
p1
```
Na população 1, apenas 7% das mulhres tem altura abaixo de 1,50, 97% é mais alta do que este valor.

**População 2**

```{r}
x <-  1.50
z2 <-  (x - mu2)/dp2
z2 
p2 <- pnorm (z2)
p2
```
Na população 2, esta mulher estaria a 1,73 desvios padrão distante da média. Isto significa que se ela pertence a população 2, ela seria considerada alta, pois, praticamente 96% das mulheres desta população seriam menores do que ela.  

Na realidade, ela pode pertencer a qualquer uma das populações. Entretanto, como poucas mulheres na população 1 tem altura dessa magnitude e muitas mulheres da população 2 tem esta altura ou menos, poucas estão acima, seria mais provável ela ser da população 2, mas poderia ser uma "baixinha" da população 1!

## Leitura Adicional  

1. Altman DG. **Practical Statistics for Medical Research**. Boca Raton, FL: Chapman & Hall/CRC; 1991. The Normal Distribution; 51-60.

2. Oliveira Filho PF. **Epidemiologia e Bioestatística: fundamentos para a leitura crítica**. 2ª ed. Rio de Janeiro: Editora Rubio Ltda; 2022. Distribuição de  Probabilidades;p.113-121.

3. Vu J, Harrington D. **Introductory Statistics for the
Life and Biomedical Sciences**. Openintro; 2021. Normal distribution; p.152-67. Disponível em: <https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_OpenIntro_Statistics_(Diez_et_al)./03%3A_Distributions_of_Random_Variables/3.01%3A_Normal_Distribution>


</br>
</br>

<!--chapter:end:11-distNormal.Rmd-->

# Estimação
## Pacotes necessários

```{r message=FALSE, warning=FALSE}
pacman::p_load(readxl, dplyr, ggplot2, Rmisc, DescTools)
```

Além desses pacotes, vamos usar uma função denominada `shadeform ()` que desenha uma curva normal com áreas sombreadas. Ela foi criada por [Tony Cookson](http://novicemetrics.blogspot.com/) e  pode ser encontrada [aqui](https://github.com/petronioliveira/Arquivos/blob/main/shadeform.R) para ser salva em seu diretório de trabalho. Ela deve ser ativada com a função `source ("caminho no diretório de trabalho")`. Por exemplo, no nosso computador o caminho é:

```{r}
source("C:/Users/petro/Dropbox/Git_repositório/Arquivos/shadeform.R")
```

## Carregar o dados

Serão usados dados do arquivo [dadosMater](https://github.com/petronioliveira/Arquivos/blob/main/dadosMater.xlsx) que devem ser baixados para o diretório de trabalho.

Crie um objeto `mater` para receber os dados, a partir do diretório de trabalho, executando:

```{r}
mater <- read_excel ("C:/Users/petro/Dropbox/Git_repositório/Arquivos/dadosMater.xlsx")
```

## Exploração e manipulação do banco de dados

Este banco de dados contém informações de 30 variáveis de 1368 nascimentos consecutivos, em um período de 18 meses, da Maternidade Escola do Hospital Geral de Caxias Sul (HGCS).  
Neste momento, usaremos apenas a variável `mater$altura`, altura das gestantes em metros.

```{r}
dados <- mater %>% select (altura)
glimpse (dados)
```

### Resumo dos dados

```{r}
summary(dados$altura)
```

```{r}
mu <- mean(mater$altura)
dp <- sd(mater$altura)
mu
dp
```

### Visualização gráfica 

```{r echo=TRUE}
hist(mater$altura,
     xlim = c (1.4, 1.85),
     main= NULL,
     freq = FALSE,
     ylab = "Densidade", 
     xlab = "Altura (m)",
     col = "salmon",
     las = 1)
box (bty = "L")

curve (dnorm (x, 
              mean=mu, 
              sd=dp), 
       col="red", 
       lty=1,
       lwd=2,
       add=TRUE)
```

Observamos que a variável altura tem uma distribuição simétrica com média = `r round(mean (dados$altura),3)`m e desvio padrão = `r round(sd (dados$altura), 3)`m, onde a altura mínima = `r min (dados$altura)`m e a máxima = `r max (dados$altura)`m.

## Distribuição Amostral

A principal preocupação da *inferência estatística* é com a qualidade das estimativas dos parâmetros. Procura responder a pergunta: "Quão certos estamos de que a média $\overline{x}$ está proxima da verdadeira média $\mu$. A compreensão deste conhecimento é a base da estatística.  

Vamos considerar, para fins didáticos, as 1368 mulheres como a **população-alvo** para qual queremos fazer inferência. Dessa forma, vamos extrair uma amostra de n = 30, dessa população, usando a função `sample ()`. 

```{r}
amostra1 <- sample (dados$altura, 30)
```

Se queremos estimar a média da população com base na `amostra1` , a maneira mais intuitiva de fazer isso é simplesmente calcular a média.

```{r}
mu1 <- mean(amostra1)
mu1

dp1 <- sd(amostra1)
dp1
```

A média da amostra $\overline{x}$ = `r round (mean(amostra1),3)` é chamada de **estimativa pontual** da média da população. Se pudermos escolher apenas um valor para estimar a média da população, essa é nossa melhor estimativa.  

Suponha que uma nova amostra de 30 gestantes seja selecionada e a média recalculada. Provavelmente, não obteremos exatamente a mesma resposta que obtivemos, usando o conjunto de dados `amostra1.` 

```{r}
amostra2 <- sample (dados$altura, 30)

mu2 <- mean(amostra2)
mu2
```

As estimativas geralmente variam de uma amostra para outra e, essa **variação amostral**, sugere que nossa estimativa pode ser próxima, mas não será exatamente igual ao parâmetro, $\mu$. O conjunto das possíveis médias amostrais de uma população constituem uma **distribuição amostral das médias**. 
Isto também é valido para as estimativas pontuais de outros parâmetros populacionais, como mediana, coeficiente de variação, desvio padrão, por exemplo.  

As estimativas geralmente não são exatamente iguais à verdade, mas ficam melhores à medida que mais dados se tornam disponíveis. Ou seja, a média de uma sequência de médias amostrais se aproxima da verdadeira média e a média de todas as possíveia médias é igual a média verdadeira.  

> <font size=2>A **distribuição amostral** representa a distribuição das estimativas pontuais com base em amostras de tamanho fixo de uma determinada população. É útil pensar em uma estimativa pontual específica como sendo extraída de tal distribuição. Compreender o conceito de uma distribuição amostral é fundamental para compreender a inferência estatística.</font>

## Erro Padrão

Suponha que se selecione uma quantidade grande de amostras dessa população de gestantes, por exemplo 5000 amostras. Somente podemos realizar isso porque temos disponível todo o conjunto de dados da população, definido, para fins didático, como sendo as alturas das 1368 gestantes. Na prática, isto é muito difícil de acontecer pela quase impossibilidade de se analisar toda a população.  

Se fizermos isso, podemos construir uma distribuição amostral para a média da amostra quando o tamanho da amostra é 30, mostrado na Figura.

```{r echo=FALSE}
amostra30 <- rep (0, 5000)
for (i in 1:5000) {
  amostra <- sample (dados$altura, 30)
  amostra30 [i] <- mean (amostra)
}

hist(amostra30,
     breaks=20,
     col = "springgreen",  
     border = "black",
     main = "Distribuição de 5000 amostras - n = 30",
     xlab = "Altura (m)",
     ylab = "Frequência",
     #xlim = c (1.56, 1.65),
     ylim = c (0, 900),
     cex.lab = 1.2,
     cex.axis = 1.2,
     las = 1)
abline (v = round(mean(dados$altura), 3), col = "red", lwd = 2, lty = 2)
box(bty = "L")
```

A distribuição amostral exibida é unimodal e praticamente simétrica. Também está centrada exatamente na média real da população: $\mu$ = `r round(mean(dados$altura), 3)`, linha vertical vermelha. Isso faz sentido. As médias da amostra devem tender a "cair em torno" da média da população.  

Podemos ver que as médias amostrais possuem alguma variabilidade em torno da média da população, que pode ser quantificada usando o desvio padrão desta distribuição de médias amostrais: $\sigma_\overline{x}$= `r round(sd(amostra30), 3)`. O desvio padrão das médias amostrais nos diz o quão longe a estimativa típica está da média real da população, 1,598 m. Também descreve o erro típico da estimativa pontual e, por esse motivo, costumamos chamar esse desvio padrão de **erro padrão (EP)** da estimativa.

> <font size=2>O desvio padrão associado às estimativas é chamado de **erro padrão**. Descreve o erro ou incerteza típica associada à estimativa. Está associado à **precisão** com que estimamos o parâmetro da população.</font>

 
No exemplo que estamos trabalhando, conhecemos o desvio padrão da população, ($\sigma$ = `r round(sd(dados$altura), 3)`). Matematicamente, o erro padrão é calculado, usando a fórmula

$$
\sigma_\overline{x}=\frac{\sigma}{\sqrt{n}}=\frac{0,065}{\sqrt{30}}=0.012
$$

O **desvio padrão da população é tipicamente desconhecido**. Ao considerar o caso da estimativa pontual $\overline{x}$, há um problema: não há como estimar o erro padrão a partir de uma única amostra. No entanto, a teoria estatística, usando o teorema do limite central, fornece uma solução para esse problema. A estimativa pontual tende a ser suficientemente boa quando o tamanho da amostra é de pelo menos 30 e a distribuição da população não é fortemente assimétrica.   
Assim, geralmente, usamos apenas o desvio padrão da amostra, $s$, em vez de $\sigma$. Quando o tamanho da amostra for menor que 30, precisaremos usar um método para contabilizar a incerteza extra no erro padrão (ver adiante).   
Usando o desvio padrão, $s$, da amostra no lugar do desvio padrão, $\sigma$, da população, a equação acima, fica assim:


$$
EP_\overline{x}=\frac{s}{\sqrt{n}}
$$

## Intervalo de Confiança com Desvio Padrão Populacional Conhecido

Vimos que fornecer uma estimativa pontual para um parâmetro populacional, como a média, raramente é uma medida exata, perfeita. Logo, a atitude lógica é fornecer uma faixa plausível de valores para o parâmetro populacional.  

Este intervalo de valores plausíveis para o parâmetro da população é chamado de **intervalo de confiança**. De acordo com a interessante imagem do *OpenIntro Statistics* (2015), usar apenas uma estimativa pontual é como pescar em um lago turvo com uma lança e usar um intervalo de confiança é como pescar com uma rede. Ou seja, se usarmos apenas uma estimativa pontual, provavelmente, não atingiremos o parâmetro populacional, entretanto, se usarmos uma gama de valores - um intervalo de confiança - aumentamos a probabilidade de incluirmos o parâmetro.

A estimativa pontual é o mais provável valor do parâmetro e, portanto, faz sentido construir um intervalo ao redor desta estimativa. O erro padrão, que é uma medida da incerteza associada à estimativa pontual, fornece uma orientação para a magnitude do intervalo de confiança.  

O erro padrão representa o desvio padrão associado à estimativa e, aproximadamente, 95% das vezes, a estimativa estará dentro de 2 erros padrão do parâmetro. Se o intervalo tiver um tamanho $\pm$ 2 erros padrão da estimativa pontual, podemos ter cerca de 95% de certeza de que o parâmetro verdadeiro estará incluido nele:

$$
estimativa\ pontual\pm 2\times EP 
$$
Este valor de $\pm2\times EP$ é denominado de **margem de erro (me)** e é um valor aproximado. No modelo normal, podemos tornar isso mais preciso usando `r round(qnorm(0.975),2)` no lugar de 2. 
 
$$
estimativa\ pontual\pm 1,96\times EP 
$$

### Interpretação do Intervalo de Confiança

Qual o significado de *95% de confiança*? Para compreender isso, vamos selecionar 20 amostras de n = 30 da população de mulheres e calcular, para cada amostra, a média da `altura` e o seu intervalo de confiança de 95%. Então, 95% dos intervalos devem conter a média populacional, $\mu$. Em outras palavras, das 20 amostras que selecionamos, aleatoriamente, existe probabilidade de que uma delas (5%) não contenha a média da população, linha vermelha horizontal, na figura.

```{r echo=FALSE}
ic <- read_excel ("C:/Users/petro/Dropbox/Git_repositório/Arquivos/dadosIC.xlsx")
ic <- ic %>% select(x, y, linf, lsup)
```

```{r echo=FALSE}
ggplot(ic, aes(x, y)) +   
  geom_point() +
  geom_errorbar(aes(ymin = linf, ymax = lsup)) +
  geom_hline(yintercept=1.598, color = "red") +
  theme_classic() +
  ylab("Altura (m)") +
  xlab ("Nº de Amostras")
```

A média dessas médias amostrais é igual `r round(mean(ic$y), 3)`m, a mesma média da população `r round(mean(dados$altura), 3)`m, com arredondamento até a terceira casa decimal, um erro da ordem de milimetros na altura. 

> <font size=2> OBSERVAÇÃO: Havendo curiosidade, o banco de dados usado, nestes cálculos e construção do gráfico acima, encontra-se [aqui](https://github.com/petronioliveira/Arquivos/blob/main/dadosIC.xlsx). Onde *x* são as amostras, *y* é a média de cada amostra e *linf* e *lsup* sãos os limites inferior e superior dos intervalos de confiança de cada amostra, respectivamente.</font>

### Exercício 1

Extraia amostras de n = 30, 50, 100 e 1000 da população de gestantes, usada anteriormente, e calcule a média e o $IC_{95\%}$ para cada amostra e interprete os resutados.

#### Solução

**Amostra A - n = 30**
```{r}
amostra_A <- sample(dados$altura, 30)
mu_A <- mean (amostra_A)
mu_A
dp_A <- sd (amostra_A)
EP_A <- dp_A/sqrt(30)
alpha <- 0.05                         # Nível de significância
zc <- qnorm (1 - (alpha/2))           # z crítico
me_A <- zc * EP_A

linf_A <- mu_A - me_A 
lsup_A <- mu_A + me_A
ic_A <- c(linf_A, lsup_A)
ic_A
```

**Amostra B - n = 50**
```{r}
amostra_B <- sample(dados$altura, 50)
mu_B <- mean (amostra_B)
mu_B
dp_B <- sd (amostra_B)
EP_B <- dp_B/sqrt(50)
alpha <- 0.05                         # Nível de significância
zc <- qnorm (1 - (alpha/2))           # z crítico
me_B <- zc * EP_B

linf_B <- mu_B - me_B 
lsup_B <- mu_B + me_B
ic_B <- c(linf_B, lsup_B)
ic_B
```

**Amostra C - n = 100**
```{r}
amostra_C <- sample(dados$altura, 100)
mu_C <- mean (amostra_C)
mu_C
dp_C <- sd (amostra_C)
EP_C <- dp_C/sqrt(100)
alpha <- 0.05                         # Nível de significância
zc <- qnorm (1 - (alpha/2))           # z crítico
me_C <- zc * EP_C

linf_C <- mu_C - me_C 
lsup_C <- mu_C + me_C
ic_C <- c(linf_C, lsup_C)
ic_C
```

**Amostra D - n = 1000**
```{r}
amostra_D <- sample(dados$altura, 1000)
mu_D <- mean (amostra_D)
mu_D
dp_D <- sd (amostra_D)
EP_D <- dp_D/sqrt(1000)
alpha <- 0.05                         # Nível de significância
zc <- qnorm (1 - (alpha/2))           # z crítico
me_D <- zc * EP_D

linf_D <- mu_D - me_D 
lsup_D <- mu_D + me_D
ic_D <- c(linf_D, lsup_D)
ic_D
```
**Gráfico**  

*[1ª Etapa](anchor)*: Criar um dataframe com as médias e os limites inferiores e superiores de cada amostra:

```{r}
x <- c("A_30", "B_50", "C_100", "D_1000")
y <- c(mu_A, mu_B, mu_C, mu_D)
linf <- c(linf_A, linf_B, linf_C, linf_D)
lsup <- c(lsup_A, lsup_B, lsup_C, lsup_D)

df <- data.frame(x, y, linf, lsup)
```

*[2ª Etapa](anchor)*: Criar o gráfico:

```{r}
ggplot(df, aes(x, y)) +   
  geom_point(size = 4) +
  geom_errorbar(aes(ymin = linf, ymax = lsup), width = 0.2) +
  geom_hline(yintercept=1.598, color = "red", linetype = "dashed", size = 1) +
  theme_classic() +
  ylab("Altura (m)") +
  xlab ("Amostras")+
  coord_flip()
```

**Interpretação**

O gráfico mostra, claramente, que à medida que o tamanho amostral aumenta, diminui o intervalo de confiança, tornando as estimativas mais precisas.

### Outros Intervalos de Confiança

É possível considerar intervalos de confiança em que o nível de confiança é um pouco superior a 95%, por exemplo 99%. Pense novamente na analogia de tentar pegar um peixe: se quisermos ter mais certeza de que vamos pegar o peixe, devemos usar uma rede mais larga. Portanto, para criar um nível de confiança de 99%, também devemos ampliar nosso intervalo de 95%.  
Por outro lado, se quisermos um intervalo com menor confiança, como 90%, precisamos tornar nosso intervalo original de 95% um pouco mais estreito.

A estrutura do intervalo de confiança de 95%, visto anteriormente é igual a:

$$
estimativa\ pontual\pm 1,96\times EP 
$$
Como vemos o intervalo de confiança é determinado pela margem de erro (me) e esta é dependente do valor crítico de z que é igual a 1,96 quando o nível de confiança é 95%.  
Para outros níveis de confiança, o $z_{crítico}$ se modifica de acordo o modelo normal e pode ser verificado no **R** com a função `qnorm ()`:

> <font size=2> * Nível de confiança 99%: $z_{crítico}$ = `r round(qnorm(0.995),2)`    
* Nível de confiança 90%: $z_{crítico}$ = `r round(qnorm(0.95),2)`</font>
 
Dessa forma, a probabilidade de Z estar entre -1,64 e +1,64 é de 90%, entre -1,96 e +1,96 é de 95% e entre -2,58 e +2,58 é de 99%. Observa-se que à medida que se aumenta o nível de confiança o aumento o intervalo entre os limite inferior e superior.

### Exercício 2
 Use a amostra A do exercício 1 e calcule o intervalo de confiança de de 90 e 99%. Compare os resultados.
 
#### Solução

**$IC_{99\%}$**

```{r}
alpha <- 0.01                         # Nível de significância
zc <- qnorm (1 - (alpha/2))           # z crítico
```


```{r}
me_A2 <- zc * EP_A

ic_A2 <- c((mu_A - me_A2), (mu_A + me_A2))
ic_A2
```

**$IC_{90\%}$**

```{r}
alpha <- 0.10                         # Nível de significância
zc <- qnorm (1 - (alpha/2))           # z crítico
me_A3 <- zc * EP_A

ic_A3 <- c((mu_A - me_A3), (mu_A + me_A3))
ic_A3
``` 

**Interpretação**

Repetindo a intervalo de confiança de 95% para comparar:

```{r}
ic_A
```

Observamos que os intervalos aumentam progressivamente com o aumento da confiança. Veja os gráficos abaixo, criados com a função `shadeform ()`, carregada no início do capítulo.

```{r echo=TRUE}
par(mfrow = c(1, 3))

shadenorm(outside = c(1.64, -1.64), color = "steelblue")
abline (h = 0)
text(0, 0.1, "90%", cex = 1.5, col = "black")

shadenorm(outside = c(1.96, -1.96), color = "steelblue")
abline (h = 0)
text(0, 0.1, "95%", cex = 1.5, col = "black")

shadenorm(outside = c(2.58, -2.58), color = "steelblue")
abline (h = 0)
text(0, 0.1, "99%", cex = 1.5, col = "black")

par(mfrow = c(1,1))
```

## Intervalo de Confiança com Desvio Padrão Populacional Desconhecido

Com amostras pequenas, usar o modelo normal para construir intervalos de confiança, gera um erro, pois os pressupostos do teorema do limite central não são respeitados. 
Quando o desvio padrão populacional, $\sigma$, é desconhecido e o tamanho amostral é pequeno (< 30), a estimação da média populacional é feita usando a distribuição *t*.  

### Distribuição *t*  

A distribuição *t*, desenvolvida por *William Sealy Gosset*, em 1908, é semelhante à distribuição normal. Como a curva de distribuição normal, a curva de distribuição *t* é unimodal, simétrica (em forma de sino) em torno da média e nunca encontra o eixo horizontal. A área total sob uma curva de distribuição *t* é 1 ou 100%. A curva da distribuição *t* é mais plana do que a curva de distribuição normal padrão. Em outras palavras, ela é mais achatada e mais espalhada. No entanto, conforme o tamanho da amostra aumenta, a distribuição *t* aproxima-se da distribuição normal padrão.  

O formato de uma curva de distribuição *t* particular depende do número de graus de liberdade. O número de graus de liberdade (*gl*) para uma distribuição *t* é igual ao tamanho da amostra menos um, ou seja, $gl=n-1$.  

O número de graus de liberdade é o único parâmetro da distribuição *t*. Há uma diferente distribuição *t* para cada número de graus de liberdade, portanto, a distribuição *t* se constitui em uma família de distribuições.  

```{r echo=FALSE}
x <- seq(-4, 4, length=100)
hx <- dnorm(x)

gl <- c(1, 3, 8, 30)
cores <- c("red", "blue", "darkgreen", "gold", "black")
rotulos <- c("gl=1", "gl=3", "gl=8", "gl=30", "normal")

plot(x, hx, type="l", lty=2, xlab="X",
     ylab="Densidade", main="")

for (i in 1:4){
  lines(x, dt(x,gl[i]), lwd=2, col=cores[i])
}

legend("topright", inset=.05, title="Distribuições",
       rotulos, lwd=2, lty=c(1, 1, 1, 1, 2), col=cores)
```

Como a distribuição normal padrão, a média da distribuição padrão *t* é 0. Entretanto, diferente da distribuição normal padrão, cujo desvio padrão é 1, o desvio padrão de uma distribuição *t* é $\sqrt gl⁄(gl-2)$ , para gl > 2, que sempre é maior do que 1. Por exemplo, se $gl = 8$, o desvio padrão será:
```{r}
dp = sqrt(8/(8-2))
dp
```
Assim, o desvio padrão de uma distribuição *t* é maior do que o desvio padrão da distribuição normal padrão.  
Os valores de $t_{crítico}$ podem ser obtidos usando a função `qt ()` que usa os seguintes argumentos:

Argumento | Significado
:--- | :-----------
p | probabilidade, igual a $1-\alpha/2$, considerando-se bicaudal e $1-\alpha$ quando unicaudal;
df | graus de liberdade;
lower.tail | lógico; se [TRUE](anchor), informa a probabilidade da cauda inferior. O padrão é [TRUE](anchor).
     |
Assim, o valor do $t_{crítico}$ para $gl=10$ é:

```{r}
qt(0.975, 10, lower.tail = TRUE)
```

Dessa forma, a área compreendida entre $t=\pm 2,23$ é igual a 95%:

$$
p(-2,23\le t\le 2,23)=0,95
$$
```{r echo=FALSE}
# 1º Gráfico
x <- seq (-4, 4, length = 1000)
y <- dnorm(x)
plot(x, y, axes = FALSE, type = 'l', xlab = '',
     ylab = '',main = "")
abline(h = 0)
abline (v = 0, col = 2, lty ="dashed")
x1 <- x[x >= 2.23]
y1 <- dnorm(x1)
x2 <- c(4, x1, x1[length(x1)], 4)
y2 <- c(0,0, y1, 0)
polygon(x2, y2, col = "lightblue2")

x3 <- x[x <= -2.23]
y3 <- dnorm(x3)
x4 <- c(-4, x3, x3[length(x3)], -4)
y4 <- c(0,y3, 0, 0)
polygon(x4, y4, col = "lightblue2")

axis(1, at = c(-2.23, 0, 2.23), font = 10, labels = c("-2.23", "0", "2.23"))
text(0, 0.1, cex = 1.0, col = "black",expression(italic(0.95)))
text(3, 0.04, cex = 1.0, col = "black",expression(italic(0.025)))
text(-3, 0.04, cex = 1.0, col = "black",expression(italic(0.025)))
```

Quando se considera apenas uma das caudas (unicaudal ou unilateral), o valor do $t_{crítico}$ para $gl=10$ é

```{r}
qt(0.95, 10, lower.tail = TRUE)
```

Assim, a área $t \le 1,81$ é igual a 95%

$$
p(t\le 1,81)=0,95
$$

```{r echo=FALSE}
x <- seq (-4, 4, length = 1000)
y <- dnorm(x)
plot(x, y, axes = FALSE, type = 'l', xlab = '',
     ylab = '',main = "")
abline(h = 0)
abline (v = 0, col = 2, lty ="dashed")
x1 <- x[x >= 1.81]
y1 <- dnorm(x1)
x2 <- c(4, x1, x1[length(x1)], 4)
y2 <- c(0,0, y1, 0)
polygon(x2, y2, col = "lightblue2")

axis(1, at = c(-5, 0, 1.81), font = 10, labels = c("","0", "1.81"))
text(0, 0.1, cex = 1.0, col = "black",expression(italic(0.95)))
text(3, 0.04, cex = 1.0, col = "black",expression(italic(0.05)))
```


### Dados para o cálculo do intervalo de confiança

Vamos continuar com o banco de dados das altursa de 1368 gestantes, que consideramos a nossa população. Agora iremos trabalhar com uma amostra de 30 mulheres e fazer inferência para essa população, supondo que os parâmetros dessa população sejam desconhecidos.

```{r}
amostra <- sample (dados$altura, 30)
```

Se queremos estimar a média da população com base na amostra, a maneira mais intuitiva de fazer isso é, simplesmente, calcular a média e o desvio padrão da amostra.

```{r}
mu <- mean(amostra)
mu
dp <- sd(amostra)
dp
```

Para termos maior precisão, vamos calcular os intervalos de confiança para esta estimativa, usando a distribuição *t*.

### Cálculo do Intervalo de Confiança com $\sigma$ desconhecido

#### Cálculo manual

Temos uma amostra de $n = 30$,  $\overline x = `r round(mean (amostra), 3)`$ e 
$s = `r round(sd (amostra), 3)`$. Vamos calcular os outros dados para obter o intervalo de confiança, usando uma distribuição *t* bicaudal e um nível de significância $\alpha = 0.05$: 

```{r}
n <-  30
alpha <- 0.05
p <- 1 - alpha/2
p
gl <- n - 1
gl
tc <-  qt(p, gl, lower.tail = TRUE)
tc
EP <- round(dp/sqrt(n),3)
EP
```

Onde *p* é a probabilidade decorrente do nível de significância, *gl* são os graus de liberdade e *EP* é o erro padrão. 
Com dados necessátios, podemos calcular o intervalo de confiança de 95%:

```{r}
ic <- c((mu - tc * EP), (mu + tc * EP))
round (ic,2)
```
Ou seja, temos uma confiança 95% de que a média populacional desconhecida se encontra entre `r round(mu - tc * EP,2)` m e `r round(mu + tc * EP,2)` m.

#### Cálculo usando uma função do R

O **R** possui algumas funções que calculam o intervalo de confiança para variáveis numéricas, baseadas na distribuição *t*. Entre elas, a função `CI (x, ci = 0.95)`, incluída no pacote `Rmisc`:

```{r}
ic <- CI (amostra, ci = 0.95)
round(ic, 2)
```

## Intervalo de Confiança para uma proporção populacional

Com frequência , necessitanos estimar uma proporção populacional. Como não é possível realizar um censo cada vez que se necessita encontrar o valor de uma proporção da população, normalmente se obtém resultados de pesquisas por amostragem. Portanto, para levar em conta a variabilidade nos resultados obtidos em diferentes pesquisas por amostragem, precisamos conhecer os procedimentos para estimar uma proporção da população

### Dados para estimar a proporção populacional

Vamos usar uma amostra aleatória de n = 60 da variável mater$fumo para estimar a proporção de mulheres fumantes.

```{r}
fumo <- sample (mater$fumo, 60)
glimpse (fumo)
```

A função `glimpse ()` nos mostra que temos 60 observações da variável `fumo` e que a mesma é do tipo numérica (*dbl*), 1 = sim e 2 = não, fumante e não fumante, respectivamente. Portanto, ela é uma variável categórica e deve ser transformada para fator.

```{r}
fumo <- factor (fumo, 
                ordered=TRUE, 
                levels = c (1,2), 
                label = c ("sim", "não"))
```

### Cálculo da estimativa pontual da proporção 

Nesta amostra, a proporção de fumantes é:

```{r}
tab <- table(fumo)
tab
tabFumo <- round (prop.table (tab), 3)
tabFumo
```

### Cálculo do intervalo de confiança para a proporção

#### Cálculo Manual com Aproximação Normal

**1ª etapa**: verificar a premissa de que quando a proporção populacional é desconhecida a proporção pontual ($\hat p$) e o seu complemento ($\hat q = 1 - \hat p$) multiplicados, cada um, por $n$, devem ser maior do que 5.

```{r}
n <- 60
(tabFumo) * n
```

Ambos valores são maiores do que 5. Vamos adiante!

**2ª Etapa**: O intervalo pode ser estimado pela distribuição normal. O $z_{crítico}$ é calculado:

```{r}
alpha <- 0.05
p <-  1 - alpha/2
zc <- qnorm (p, mean = 0, sd = 1)
zc <- round(zc, 2)
zc
```

**3ª Etapa**: Cálculo do erro padrão da proporção ($\sqrt \frac {\hat p \times \hat q}{n}$) e da margem de erro:

```{r}
prop <- tabFumo [1]
EP <- sqrt((prop * (1 - prop))/n)
me <- zc * EP
me
```

**4ª Etapa**: Intervalo de confiança

```{r}
ic_prop <- c((prop - me), (prop + me))
round(ic_prop, 3)
```

#### Cálculo usando uma função do R

O chamado *Intervalo de Confiança Exato* corrigem as deficiências da aproximaçãonormal. O R tem uma função para este cálculo: `BinomCI ()` do pacote `DescTools.` É preferível usar o método de Clopper e Pearson que fornece o IC exato.  
Os argumentos da função `BinomCI` são:

Argumento | Significado
:--- | :-----------
x | é o número de desfechos, sucessos;
n | é o tamanho da amostra, número de ensaios;
p | probabilidade, hipótese nula; se ignorada o padrão é 0,50;
conf.level | nível de confiança, o padrão é 0.95;
method | possui vários métodos para calcular intervalos de confiança para uma proporção binomial como: “clopper-pearson” (exact interval), "wilson", "wald", "agresti-coull", "jeffreys", "modified wilson", "modified jeffreys", "arcsine", "logit", "witting", "pratt". O método padrão é o de “wilson”. Qualquer outro método, há necessidade de solicitar;
sides |  hipótese alternativa padrão “two.sided” (bilateral), mas pode ser “right” ou “left” (unilateral a direita ou a esquerda, respectivamente).
     |
     
```{r}
IC <- BinomCI (tab[1], n, 
               conf.level = 0.95, 
               method = "clopper-pearson")
round(IC, 3)
```

Observe que existe uma pequena diferença entre os valores da aproximação normal e o exato, com método de “clopper-pearson”.

## Leitura Adicional  

1. <https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/07%3A_Estimation>

2. Daniel WD, Cross CL. Biostatistics: A Foundation for Analysis in the Health Sciences. Tenth Edition. Hoboken, NJ: Wiley; 2013.Estimation; p. 161-213.

3. Oliveira Filho PF. **Epidemiologia e Bioestatística: fundamentos para a leitura crítica**. 2ª ed. Rio de Janeiro: Editora Rubio Ltda; 2022. Intervalo de Confiança e Valor P;p.123-133.

4. Diez DM, Barr CD, Çetinkaya-Rundel M. **OpenIntro Statistics**. Third Edition. Victoria, British Columbia: OpenIntro; 2015. Foudations for Inference; p. 168-218.

</br>

</br>

<!--chapter:end:12-estimacao.Rmd-->

# Teste de Hipóteses

O **Teste de hipóteses** é um dos procedimentos básicos para a inferência estatística. Em um teste de hipóteses, testa-se uma teoria ou crença sobre um parâmetro populacional.  
Quase sempre, as informações são obtidas a partir de uma amostra em função da quase impossibilidade de se conseguir trabalhar com toda a população. Portanto, extrapolar ou estender os resultados, obtidos de uma amostra, para a população, significa aceitá-los como representações adequadas da mesma.  
Sabe-se que as estimativas amostrais diferem dos valores reais (populacionais) e o objetivo dos testes de hipóteses é estabelecer a probabilidade de essa *diferença ser explicada pelo acaso*. 

## Pacotes necessários

```{r}
pacman::p_load(readxl,
               dplyr,
               car,
               lsr,
               dabestr,
               pwr,
               knitr)
```

## Dados

Considere o exemplo de uma turma de 40 alunos de Bioestatística, onde metade dos alunos são do sexo feminino. Como tem sido a regra, a minha hipótese é que o desempenho das mulheres continuará a ser superior. Vamos usar o banco de dados `dadosNotas.xlsx`.
Para baixar o banco de dados, clique [aqui](https://github.com/petronioliveira/Arquivos/blob/main/dadosNotas.xlsx). Salve o mesmo no seu diretório de trabalho.

## Leitura e manipulação do banco de dados

Crie o objeto `dados` para receber o arquivo, a partir do diretório de trabalho.

```{r Leitura dos dados}
dados <- read_excel("C:/Users/petro/Dropbox/Git_repositório/Arquivos/dadosNotas.xlsx")
```

A função `read_excel()` do pacote `readxl` abre o arquivo e podemos ver a sua estrutura, usando a função `glimpse ()` do pacote `dplyr`.

```{r}
glimpse (dados)
```

### Amostra

Este banco de dados será a nossa amostra. A partir dela faremos inferência a população de alunos da disciplina de Bioestatística do curso de Medicina
Como a variável `sexo` está como caractere, é melhor transformá-la para fator:

```{r}
dados$sexo <- as.factor(dados$sexo)

glimpse(dados)
```

### Sumarização dos dados na amostra

As principais medidas resumidoras serão colocadas no objeto `resumo`:

```{r}
resumo <- dados %>% 
  group_by(sexo) %>% 
  summarise(n = n (),
            media = mean(notas),
            dp = sd (notas),
            mediana = median (notas),
            IIQ = IQR (notas)) %>% 
  mutate(ep = dp/sqrt(n)) %>% 
  mutate(me = ep * qt(1 - (0.05/2), n - 1))
resumo
```

Assim, temos uma amostra, onde nota média das mulheres foi `r round((mean(dados[which(dados$sexo=='F'),]$notas)),1)` e dos homens `r round((mean(dados[which(dados$sexo=='M'),]$notas)),1)`. Aparentemente, a afirmação de que as mulheres têm um melhor desempenho na prova de Bioestatística, parece fazer sentido. Como não se sabe o que ocorre na população, esta diferença de `r round((mean(dados[which(dados$sexo=='F'),]$notas)- mean(dados[which(dados$sexo=='M'),]$notas)),1)` pode ter ocorrido por *acaso* e pode não existir! 

## Hipótese nula e alternativa

No teste de hipóteses (TH), existem dois tipos de hipóteses, definidas como:  

**Hipótese nula ($H_{0}$)**: é a hipótese que afirma não existir diferença e que a diferença observada é atribuível ao acaso. É a hipótese a ser testada, aquela que se busca afastar. É escrita como:

$$
H_0: μ_1=μ_2 \ ou \  μ_1-μ_2=0
$$
**Hipótese alternativa ($H_{A}$)**: é a hipótese contrária, como o nome diz, alternativa à $H_0$.  Representa a posição de uma nova perspectiva, a conclusão que será apoiada se $H_0$ for rejeitada. Ela supõe que realmente exista uma diferença entre os grupos. É a hipótese que o pesquisador pretende comprovar. É escrita, em geral, simplesmente como havendo uma diferença entre os grupos, sem indicar uma direção, hipótese bilateral ou bicaudal:

$$
H_0: μ_1≠μ_2 \ ou \ μ_1-μ_2≠0
$$
Ou, se houver uma suspeita, através de um conhecimento prévio, apontar uma direção para a diferença, ou seja, usar uma hipótese unilateral ou monocaudal:

**1. $\mu_1>\mu_2$**

$$
H_0: μ_1>μ_2 \ ou \ μ_1-μ_2>0\\
$$
Neste caso, a $H_0$ passa a ser:

$$
H_0: μ_1 \le μ_2
$$
**2.$\mu_1<\mu_2$**

$$
H_0: μ_1<μ_2 \ ou \ μ_1-μ_2<0
$$
Aqui, a $H_0$ passa a ser:

$$
H_0: μ_1 \ge μ_2
$$

A $H_0$ e $H_A$ são opostas e mutuamente exclusivas. No TH, calcula-se a probabilidade de obter os resultados encontrados, caso não haja efeito na população, ou seja, caso a $H_0$ seja verdadeira. Portanto, o TH é um teste de significância para a $H_0$.  

Considere o exemplo das notas de Bioestatística, conforme o sexo. As hipóteses seriam escritas da seguinte maneira, considerando uma $H_A$ monocaudal:

$$
H_0: μ_{mulheres} \le μ_{homens} \\  
H_A: μ_{mulheres} > μ_{homens}  
$$

## Regra de decisão

O objetivo do TH é rejeitar ou não a $H_0$, partindo do pressuposto de que ela é verdadeira. Portanto, é fundamental estabelecer uma **regra de decisão** que permita uma declaração em relação à $H_0$.  

Essa regra de decisão cria duas regiões, uma **região de rejeição** e uma **região de não rejeição** da $H_0$, demarcadas por um **valor crítico**. Este valor de referência é determinado pelo nível de significância, $\alpha$, e deve ser claramente mencionado *antes* de se iniciar a pesquisa, pois é baseado nele que se fundamentam as conclusões da mesma.   

O **nível de significância** corresponde a probabilidade de rejeitar uma hipótese nula verdadeira.  Quando a hipótese alternativa não tem uma direção definida, a área de incerteza, $\alpha$, é colocada nas duas caudas, dividindo a probabilidade ($\alpha/2$); quando houver indicação prévia de um sentido, a área de rejeição ficará a direita  ou a esquerda dependendo da direção escolhida. No exemplo dos notas dos alunos de Bioestatística, a área escolhida está à direita.

Para verificar se as notas, na média, das mulheres são maiores do que as dos homens, vamos usar $\alpha = 0,05$ e uma $H_A$ monocaudal. Desta forma, usando a função qt(), com um p = 0.95 e gl = n1 + n2 - 2 = 20 + 20 - 2 = 38.

```{r}
tc <- qt(0.95, 38)
round (tc,3)
```
Se o teste estatístico retornar um valor *t* > *$t_{crítico}$*, ou seja, à direita da linha tracejada azul, na figura abaixo, rejeitaremos a $H_0$ e concluiremos que as mulheres têm um melhor desempenho.

```{r echo=FALSE}
source("C:/Users/petro/Dropbox/Git_repositório/Arquivos/shadeform.R")

shadenorm(outside = c(-4, 1.69), color = "steelblue")
abline (h = 0)
abline (v =1.69, lty =2, col = "steelblue")
text(0, 0.1, "95%", cex = 1.5, col = "black")
text(1.69, -0.008, "1.69", cex = 0.8, col = "red")
text(2.7, 0.05, "5%", cex = 1.3, col = "steelblue")
text(2.7, 0.11, "Região de", cex = 1.0, col = "steelblue")
text(2.7, 0.08, "Rejeição", cex = 1.0, col = "steelblue")
```


## Erro tipo I e Erro Tipo II

Quando se toma uma decisão existe a possibilidade de se cometer erros. Um erro, denominado de **erro tipo I**, ocorre quando, baseado na regra de decisão escolhida, uma $H_0$ verdadeira é rejeitada.  
Nesse caso, tem-se um resultado **falso positivo**. Há uma conclusão de que existe um efeito quando na verdade ele não existe. A probabilidade de cometer esse tipo de erro é $\alpha$, o mesmo usado como nível de significância no estabelecimento da regra de decisão.

$$
P(rejeitar \ H_0│H_0 \ verdadeira)=\alpha
$$

Qual o valor de $\alpha$ que pode representar forte evidencia contra $H_0$, reduzindo a possibilidade de erro tipo I?   

O valor de α escolhido, apesar de arbitrário, deve corresponder a importância do que se pretende demonstrar, quanto mais importante, menor deve ser o valor de $\alpha$. Nesses casos, não se quer rejeitar incorretamente $H_0$ mais de 5% das vezes. Isso corresponde ao nível de significância mais usado de 0,05 ($\alpha$ = 0,05). Em algumas situações também são utilizados 0,01 e 0,10.  

Existe uma outra possibilidade de erro, denominado de **erro tipo II**, que ocorre quando a $H_0$ é realmente falsa, mas com base na regra de decisão escolhida, não se rejeita essa hipótese nula. Nesse caso, o resultado é um **falso negativo**; não se conseguiu encontrar um efeito que realmente existe. A probabilidade de cometer esse tipo de erro é chamada de $\beta$. 

$$
P(não \ rejeitar \ H_0│H_0 \ falsa)= \beta
$$
										
Na construção de um teste de hipótese, o erro tipo II é considerado menos grave que o erro tipo I. Entretanto, ele também é importante. Tradicionalmente, adota-se o limite de 0,10 a 0,20 para o erro tipo II.
O Quadro abaixo resume as consequências possíveis na tomada de decisão em um teste de hipótese.

$~$
<center>
![](https://github.com/petronioliveira/Arquivos/raw/main/TH_Erros.png)
</center> 
$~$

## Teste estatístico

O teste estatístico é usado para saber se a média obtida através de uma amostra se afasta de forma significativa da média populacional. Para isso é usado o erro padrão da média  {$\sigma_\overline{x}$ que padroniza essa diferença em números de erros padrão. 
O teste estatístico é escolhido em função das características dos dados e objetivo do estudo. 
No exemplo, do desempenho dos alunos na disciplina de Bioestatística de acordo com o sexo, estamos comparando duas médias e o teste indicado é o teste *t* para amostras independentes.    

### Pressupostos do teste

#### Avaliar a normalidade dos dados

Vamos usar o teste de Shapiro-Wilk dentro da função `by()`:

```{r}
by (data = dados$notas, 
    INDICES = dados$sexo, 
    FUN = shapiro.test) 
```

Os valores *P* são > 0,05 e, portanto, não rejeitamos a $H_0$ e declaramos que os dados, tanto das mulheres como dos homens se ajustam à distribuição normal. 

#### Verificação da igualdade das variâncias

Usaremos o teste de Levene com a função `leveneTest()` do pacote `car`: 

```{r}
levene <- leveneTest (notas~sexo, center = mean, data = dados)
levene
```

O Teste de Levene retorna um valor *P* > 0,05, significando que não é possível rejeitar a igualdade das variâncias.  

### Cálculo do teste estatístico

Como os pressupostos básicos do teste foram atendidos, usamos a função  `t.test()` que tem os seguintes argumentos:

```{r}
t <- t.test(notas ~ sexo,
            data = dados,
            alternative = "greater",
            paired = FALSE,
            conf.level = 0.95,
            var.equal=TRUE)
t
```

-	*t* é o valor estatístico do teste *t*,
-	*df* são os graus de liberdade ,
-	*p-value* é o valor *P* do teste *t*.
-	*conf.int* é o IC95% da diferença média;
-	*sample estimates* são o valores médios das populações 1 e 2.

### Conclusão
Conclui-se, portanto, que o desempenho das mulheres na disciplina de Bioestatística é superior ao dos homens , a diferença (`r round((mean(dados[which(dados$sexo=='F'),]$notas))-(mean(dados[which(dados$sexo=='M'),]$notas)),1)`) encontrada é estatisticamente significativa (*t* = `r round(t$statistic, 4)`, gl = `r (nrow(dados[which(dados$sexo=='F'),]))+(nrow(dados[which(dados$sexo=='M'),])) - 2`, *P* = $`r t$p.value`$, com uma confiança de 95%.

### Apresentação gráfica dos resultados
Podemos exibir o gráfico da diferença média, descrito por Gardner-Altman, em 1986 (BMJ. 292(6522):746–750), usando o pacote `dabestr` com as funções `dabest ()`, `mean_diff ()` e `plot () `com um objeto `dabest_effsize` (`mean_diff`, por exemplo). Para detalhes consulte [dabestr](https://cran.r-project.org/web/packages/dabestr/dabestr.pdf). 

```{r}
dois.grupos <- 
  dados %>%
  dabest(sexo, notas, 
         idx = c("M", "F"), 
         paired = FALSE)

difMedia <- mean_diff(dois.grupos, ci = 95)

plot(difMedia, 
     color.column = sexo,
     palette = c("pink4", "salmon3"),
     show.legend = F,
     rawplot.ylabel = "Nota em Bioestatística",
     effsize.ylabel = "Diferença Média")
```


## Poder do teste estatístico

Considera-se **poder do teste estatístico** a probabilidade de o teste rejeitar uma $H_0$ quando ela é realmente falsa. Corresponde, na Figura abaixo, a região à direita da linha vertical azul, isto é, a área de rejeição da $H_0$, para um teste monocaudal à direita e é igual a:

$$
Poder = 1 - \beta
$$

$~$
<center>
![](https://github.com/petronioliveira/Arquivos/raw/main/Poder.png)
</center> 
$~$

### Cálculo do Poder usando a distribuição *t*  

A função `pwr.t.test()` do pacote `pwr` permite fazer o cálculo do pode, usando os seguintes argumentos:

**Argumento** | **Significado**
:--- | :-----------
n | número de observações (por grupo);
d | tamanho do efeito (d de Cohen);
sig.level| nível de significância ($\alpha$);
power | poder do teste;
type  | “one.sample”, “two.sample” ou “paired”;
alternative | "two.sided", "less", "greater".
      |
  
Um dos parâmetros *n*, *d*, *power*, *sd* e *sig.level* deve ser escrito como [NULL](anchor) e esse parâmetro é determinado a partir dos outros.       
      
Para calcular poder, precisamos do d de Cohen que pode ser calculado usando a função `cohensD ()` do pacote `lsr`. Para maiores informações sobre d de Cohen, veja [aqui](https://www.dropbox.com/s/0rgc0nckmq7esr3/Teste-para-Duas-M%C3%A9dias-I.html?dl=0).

```{r}
d <- cohensD (notas ~ sexo, data = dados)
d

```

Um tamanho de efeito pequeno tem um d ao redor de 0.2, um d médio está em torno de 0.5 e um d grande está $\ge$ 0.8.

```{r}
poder <- pwr.t.test(n = 20, 
                    d=d, 
                    sig.level=0.05, 
                    power = NULL, 
                    type="two.sample", 
                    alternative="greater")
poder
```

O poder do teste rejeitar uma $H_0$ falsa é igual a `r round(poder$power*100, 1)`%.Na pratica, em geral, quando se calcula o tamanho amostral usamos um poder entre 80 a 90%, o que significa um erro $\beta$ de 10 a 20$.

## Valor *P*

Foi mostrado no TH um procedimento onde encontramos o valor da probabilidade que pode ser usada como critério para rejeitar ou não a hipótese nula. Este ponto crítico, fixado, pelo pesquisador, no início da pesquisa, é o nível de significância, $\alpha$. Essa abordagem do valor de probabilidade é, com frequência, chamada de **abordagem através do valor P**. Uma vez realizada a pesquisa, o pesquisador calcula a probabilidade de obter um resultado tão ou mais extremo que o observado, uma vez que a $H_0$ seja verdadeira que é o **valor *P***. O valor *P* também é conhecido como nível descritivo do teste. O objetivo de um teste estatístico é transformar em probabilidade a magnitude do desvio verificado em relação ao valor esperado, fornecendo o valor *P*. A partir daí pode-se definir a regra de decisão, usando esse valor *P*. Toma-se o valor predeterminado (em geral, 0,05) de $\alpha$ e, então, compara-se o valor *P* com este $\alpha$ e toma-se uma decisão. Usando essa abordagem, rejeita-se a $H_0$ se o valor P < $\alpha$ e não se rejeita $H_0$ se o valor P > $\alpha$. Costuma-se dizer que se o valor P < $\alpha$, o resultado é significativo e não significativo quando P > $\alpha$.
Uma boa parte dos pesquisadores, principalmente no início da carreira, fica excitado pelo conhecimento do valor *P*. Entretanto, deve ser sempre lembrado que encontrar o valor *P* não deve ser o único foco da pesquisa. O foco deve estar dirigido ao tamanho do efeito (*effect size*). O valor *P* obtido pelo teste estatístico, vai informar apenas sobre a probabilidade de se cometer erro ao rejeitar ou não rejeitar a $H_0$.

## Leitura Adicional  

1. <https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/08%3A_Testing_Hypotheses>

2. Daniel WD, Cross CL. **Biostatistics: A Foundation for Analysis in the Health Sciences**. Tenth Edition. Hoboken, NJ: Wiley; 2013. Hypothesis testing; p. 214-303.

3. Diez DM, Barr CD, Çetinkaya-Rundel M. **OpenIntro Statistics**. Third Edition. Victoria, British Columbia: OpenIntro; 2015. Foudations for Inference; p. 168-218.

4. Gardner MJ, Altman DG. Confidence intervals rather than P values: estimation rather than hypothesis testing. **BMJ** 1996; 292:746-50.

3. Oliveira Filho PF. **Epidemiologia e Bioestatística: fundamentos para a leitura crítica**. 2ª ed. Rio de Janeiro: Editora Rubio Ltda; 2022. teste de Hipótese;p.127-133.

</br>
</br>

<!--chapter:end:13-teste-de-hipoteses.Rmd-->

# Teste *t* para Amostras Independentes

Também conhecido como **teste *t* de medidas independentes** ou **teste *t* de amostras independentes**. O teste *t* é usado quando há duas condições experimentais e participantes diferentes foram designados para cada condição.  

## Pacotes necessários

```{r}
pacman::p_load(readxl,
               dplyr,
               car,
               rstatix,
               ggplot2,
               knitr,
               kableExtra,
               lsr,
               dabestr)
```

## Dados

O banco de dados a ser carregado encontra-se [aqui](https://github.com/petronioliveira/Arquivos/blob/main/dadosPop.xlsx). Ele é constituído por medidas de altura (em metros) de dois grupos de mulheres, pertencentes a duas regiões geográficas hipotéticas diferentes. Salve o mesmo no diretório de trabalho.  
Crie um objeto `dados` para recebê-lo, a partir do diretório de trabalho, executando o seguinte código:

```{r}
dados <- read_excel ("C:/Users/petro/Dropbox/Git_repositório/Arquivos/dadosPop.xlsx")
```
A função `read_excel()` do pacote `readxl` carregou o arquivo `dadosPop.xlsx`. Os dados podem ser visualizados, usando a função `glimpse()` do pacote `dplyr`.

```{r}
glimpse (dados)
```

Observa-se que temos `r nrow(dados)` mulheres, sendo `r nrow(dados[which(dados$pop=="1"),])` moradoras na região 1 e  `r nrow(dados[which(dados$pop=="2"),])` na região 2. Foram coletadas `as alturas em metros de todas as participantes.

Se quisermos exibir os dados de uma forma, visualmente, mais elegante e em uma apresentação mais amigável, pode-se usar a função `kable()` do pacote `knitr` e a função `kable_styling()` do pacote `kableExtra`. A função `kable ()` usa a função `head()` embutida. Ao executar os códigos, serão exibido apenas 10 linhas do banco de dados (se não for especificado, mostra apenas 6 linhas). Isto evita uma poluição visual:

```{r Visualização do banco}
kable(head(dados, 10), 
      col.names = c("Id", "Altura", "População")) %>% kable_styling(full_width = FALSE, bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```

O argumento `full_width =FALSE`, reduz a largura da tabela e a `boostrap_options =` admite vários opções além da `basic`, isoladas ou combinadas:

* *striped*: adiciona listras zebradas à tabela;
* *hover*: adiciona cor de fundo cinza nas linhas da tabela;
* *condensed*: torna a tabela mais compacta;
* *responsive*: faz rolagem horizontal quando há menos de 768 px (20,32 cm).

## Exploração dos dados

Observando a saída da função `glimpse ()`, verifica-se que todas as variáveis estão como variáveis numéricas (*dbl = double*). A variável `pop` deve ser transformada para fator:

```{r}
dados$pop <- as.factor(dados$pop)
```

Agora, se observarmos, novamente, a estrutura do banco de dados, usando a função `glimse ()`, novamente,  a variável `pop` está como fator.


```{r}
glimpse (dados)
```

### Medidas resumidoras de interesse  

Será calculada a média e o desvio padrão da variável `altura` de acordo com a população (`pop`), usando a função `group_by ()` do pacote `dplyr` e `get_summary_stats()` do pacote `rstatix`:

```{r}
dados %>%
  group_by (pop) %>%
  get_summary_stats (altura, 
                     type = "mean_sd")
```

Para maiores informações sobre estes pacotes acione a ajuda.  
### Observação visual dos dados, através de boxplots

```{r}
boxplot(dados$altura~dados$pop,
        ylab = "Altura de mulheres (m)",
        xlab = "População",
        col = c("peachpuff", "salmon"),
        las = 1)
stripchart (dados$altura~dados$pop, 
            method = "jitter",
            jitter = 0.05,
            vertical = TRUE,
            col = "red", 
            pch = 20, 
            add = TRUE)
```

## Definição das hipóteses estatísticas

Será usado um teste bicaudal: 

$H_{0}$: $\mu_{pop1} = \mu_{pop2}$ 

$H_{A}$: $\mu_{pop1} ≠ \mu_{pop2}$ 

## Regra de decisão

O nível significância, $\alpha$, escolhido é igual a `0.05`. A distribuição *t* é dependente dos graus de liberdade, dados por:

No exemplo,

```{r}
n1 <- length(which(dados$pop == "1"))
n1
n2 <- length(which(dados$pop == "2"))
n2
```

```{r}
gl <- n1 + n2 -2
gl
```


Para um $\alpha$ = 0.05, o valor crítico de *t* para gl = `r gl` e uma hipótese alternativa bicaudal é obtido com a função `qt (p, df)`, onde

$df = gl$  e   
$p = 1 - \alpha/2$

```{r}
alpha <- 0.05
round (qt((1-alpha/2), gl), 3)
```

Portanto, se

$|t_{calculado}| < t_{crítico}|$ -> não rejeitar $H_{0}$

$|t_{calculado}| > t_{crítico}|$ -> rejeitar $H_{0}$  

## Avaliação dos pressupostos
O teste *t* assume que:

(1)	As amostras são independentes;
(2)	Deve haver distribuição normal. Entretanto, quando as amostras são grandes (teorema do limite central), isso não é muito importante;
(3)	Exista homocedasticidade, ou seja, as variâncias devem ser iguais.

### Avaliação da normalidade

```{r}
qqnorm(dados$altura[dados$pop == "1"], 
       pch = 1, 
       frame = FALSE,
       main = "Gráfico Q-Q - População 1",
       ylab = "Quantis amostrais", 
       xlab = "Quantis teóricos",
       cex.lab = 1, 
       cex.axis = 1,
       cex.main = 1,
       las = 1)
qqline(dados$altura[dados$pop == "1"], 
       col = "red",
       lty = 2)
box()
```

```{r}
qqnorm(dados$altura[dados$pop == "2"], 
       pch = 1, 
       frame = FALSE,
       main = "Gráfico Q-Q - População 2",
       ylab = "Quantis amostrais", 
       xlab = "Quantis teóricos",
       cex.lab = 1, 
       cex.axis = 1,
       cex.main = 1,
       las = 1)
qqline(dados$altura[dados$pop == "2"], 
       col = "red",
       lty = 2)
box()
```

```{r}
by (data = dados$altura, 
    INDICES = dados$pop, 
    FUN = shapiro.test) 
```

Tanto o *QQPlot* como o teste de *Shapiro-Wilk* mostram que os dados se ajustam à distribuição normal.

### Avaliação da homogeneidade das variâncias, usando o teste de Levene

```{r}
leveneTest(altura ~ pop, center = mean, data = dados)
```

O valor *P* do teste de *Levene* é > 0.05, indicando que não é possível rejeitar a hipóteses nula de igualdade das variâncias.

## Cálculo da estatística do teste

Usamos a função  `t.test()` que tem os seguintes argumentos:

```{r}
t.test(altura ~ pop, 
       data = dados,
       alternative = "two.sided",
       paired = FALSE,
       conf.level = 0.95,
       var.equal=TRUE)
```

-	*t* é o valor estatístico do teste t,
-	*df* são os graus de liberdade ,
-	*p-value* é o valor *P* do teste t.
-	*conf.int* é o IC95% da diferença média;
-	*sample estimates* são o valores médios das populações 1 e 2.

NOTA: Quando as variâncias não forem homogêneas, mas houver normalidade, pode ser usado o teste *t* trocando o argumento `var.equal=TRUE` por `var.equal=FALSE` que corresponde a aproximação de Welch para os graus de liberdade.

## Conclusão

Conclui-se, portanto, que a altura das mulheres da população 1 é diferente da altura das mulheres da população 2, a diferença ($\mu_{pop1} - \mu_{pop2}$) encontrada é estatisticamente significativa (t = 12,06, gl = 58, P = 2,2 x 10^-16), com uma confiança de 95%.  

### Apresentação gráfica dos resultados
Podemos exibir o gráfico da diferença média, descrito por Gardner-Altman (1986), usando o pacote `dabestr` com as funções `dabest ()`, `mean_diff ()` e `plot ()` com um objeto `dabest_effsize` (`mean_diff`, por exemplo). Para detalhes consulte [dabestr](https://cran.r-project.org/web/packages/dabestr/dabestr.pdf). 

```{r}
dois.grupos <- 
  dados %>%
  dabest(pop, altura, 
         idx = c("2", "1"), 
         paired = FALSE)

difMedia <- mean_diff(dois.grupos, ci = 95)

plot(difMedia, 
     color.column = pop,
     palette = c("pink4", "salmon3"),
     show.legend = F,
     rawplot.ylabel = "Altura de Mulheres (m)",
     effsize.ylabel = "Diferença Média")
```

## Tamanho do efeito

O tamanho do efeito (*effect size*) é uma medida quantitativa da magnitude do efeito. Quanto maior o tamanho do efeito, mais forte é a relação entre duas variáveis. 
No exemplo mostrado, como não há uma diferença estatisticamente significativa, não faz sentido se verificar o tamanho do efeito.
Quando existe um efeito significativo (*P* < 0.05), o valor do tamanho do efeito mostrará se o efeito foi pequeno, médio ou grande. Isso tem mais relevância do que simplesmente informar o tamanho do valor *P*.
Comumente, calcula-se o `d de Cohen` para encontrar a magnitude do efeito na comparação entre duas médias. É também conhecida como **diferença média padronizada**.

$$
d = \frac{\overline{x}_{1} - \overline{x}_{2}}{s_0}
$$

Onde $s_{0}$ é o desvio padrão combinado das duas médias:

$$
s_0 = \sqrt\frac{(n_1-1)s_1^2 + (n_2-1)s_2^2}{n_1+n_2 -2}
$$

O **R** tem uma função `cohensD ()` do pacote `lsr` para calcular a magnitude do efeito.

```{r}
cohensD (altura ~ pop, data = dados)
```

Os pesquisadores costumam usar as seguintes diretrizes (LAKENS, 2013) para interpretar o resultado:

d |Tamanho do Efeito 
:---: | :---: 
$< 0.2$ | insignificante; negligenciável
$0.2 < 0.5$ | pequeno 
$0.5 < 0.8$ | médio 
$\ge 0.8$   | grande

O pacote `dabestr` fornece funções que permitem também calcular a magnitude do efeito. São as funções `cohens_d ()` e `hedges_g ()` que é correção exata de Hedges para o d de Cohen, ambas usam um objeto gerado pela função `dabest ()`. Têm a vantagem de liberarem os intervalos de confiança. 

```{r}
cohens_d(dois.grupos, ci = 95)

hedges_g(dois.grupos, ci = 95)
```

## Exercício

Suponha que eu esteja atendendo uma mulher que mede 1,50 m, a qual população existe maior probabilidade de ela pertencer?

**População 1**

Verificar a probabilidade de se encontra mulheres com esta altura na população 1, calculando o seu escore z na população 1.

```{r}
x <-  1.50
z1 <-  (x - mu1)/dp1
z1 
p1 <- pnorm (z1)
p1
```
Na população 1, apenas 7% das mulhres tem altura abaixo de 1,50, 97% é mais alta do que este valor.

**População 2**

```{r}
x <-  1.50
z2 <-  (x - mu2)/dp2
z2 
p2 <- pnorm (z2)
p2
```
Na população 2, esta mulher estaria a 1,73 desvios padrão distante da média. Isto significa que se ela pertence a população 2, ela seria considerada alta, pois, praticamente 96% das mulheres desta população seriam menores do que ela.  

Na realidade, ela pode pertencer a qualquer uma das populações. Entretanto, como poucas mulheres na população 1 tem altura dessa magnitude e muitas mulheres da população 2 tem esta altura ou menos, poucas estão acima, seria mais provável ela ser da população 2, mas poderia ser uma "baixinha" da população 1!

## Leitura Adicional  

1. Altman DG. **Practical Statistics for Medical Research**. Boca Raton, FL: Chapman & Hall/CRC; 1991. The Normal Distribution; 51-60.

2. Gardner MJ, Altman DG.Confidence intervals rather than P values: estimation rather than hypothesis testing.BMJ 1986; 292:746-50.

3. Oliveira Filho PF. **Epidemiologia e Bioestatística: fundamentos para a leitura crítica**. 2ª ed. Rio de Janeiro: Editora Rubio Ltda; 2022. Distribuição de  Probabilidades;p.113-121.

4. Vu J, Harrington D. **Introductory Statistics for the
Life and Biomedical Sciences**. Openintro; 2021. Normal distribution; p.152-67. Disponível em: <https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_OpenIntro_Statistics_(Diez_et_al)./03%3A_Distributions_of_Random_Variables/3.01%3A_Normal_Distribution>


</br>
</br>

<!--chapter:end:14-teste-t-Student.Rmd-->

