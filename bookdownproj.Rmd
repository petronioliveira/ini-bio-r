--- 
title: "BIOESTATÍSTICA USANDO O R"
author: "Petrônio Fagundes de Oliveira Filho"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---

# Dados

Placeholder


## O que são dado? 
## População e Amostra
## Estimativas e Parâmetros  
## Escalas de medição
### Escala Nominal  
### Escala Ordinal
### Escala Intervalar  
### Escala de Razão  
## Tipos de Variáveis  
### Variáveis Numéricas  
### Variáveis Categóricas  
## Variáveis dependentes e independentes  
## Leitura Adicional  

<!--chapter:end:index.Rmd-->


# Ambiente do R

Placeholder


## Instalação do software R no Windows
## Instalação do R Studio no Windows

<!--chapter:end:02-ambienteR.Rmd-->


# Iniciando o *RStudio*

Placeholder


## Interface do *RStudio*
## Iniciando um novo projeto
## Primeiro Script

<!--chapter:end:03-iniRStudio.Rmd-->


# Matemática Básica no *RStudio*

Placeholder


## Operadores  
### Operadores aritméticos
### Operadores de atribuição
### Operadores de comparação
### Operadores lógicos
## Logarítimo
## Raiz quadrada
## Resultado absoluto
## Potenciação
## Exercícios

<!--chapter:end:04-matematica.Rmd-->


# Pacotes

Placeholder


## Repositórios de pacotes
## Instalação de um pacote
## Carregar um pacote
### Carregar mais de um pacote

<!--chapter:end:05-pacotes.Rmd-->


# Funções

Placeholder


## O que são funções?
## Criando funções
### Fórmula geral
### Outros exemplos
### Ativação de uma função

<!--chapter:end:06-funcoes.Rmd-->


# Manipulando Dados no RStudio

Placeholder


## Vetores
## Objetos
## Manipulando dados numéricos
## Manipulando dados categóricos
## Dataframes ou Banco de dados
### Criando um banco de dados
### Salvando os arquivos no seu diretório
### Importando um banco de dados
#### Importando dados de um arquivo CSV
#### Importando dados de um arquivo Excel

<!--chapter:end:07-manipulandoDados.Rmd-->


# Sumarização dos dados

Placeholder


## Medidas de tendência central
### Média
### Mediana
### Moda
### Quantil
### Média aparada
## Medidas de Dispersão
### Amplitude  
### Intervalo Interquartil
### Variância e Desvio Padrão
### Coeficiente de Variação
## Funções descritivas no R
### Funções `describe` e `describeBy`
### Funções `group_by` e `summarise` 
### Função `summary`

<!--chapter:end:08-sumarizandoDados.Rmd-->


# Tabelas  

Placeholder


## Pacotes necessários  
## Carregar os dados
## Exploração ddos dados
### Visão Geral 
### Transformações das variáveis
## Tabela de Frequência
### Tabela de frequência para dados categóricos
### Tabela de contingência ou cruzada
### Tabela de frequência para dados numéricos
## Construção de uma tabela com o pacote `gt`
## Tabelas com o pacote `getsummary`
## Salvando a tabela 
## Leitura Adicional  

<!--chapter:end:09-tabelas.Rmd-->


# Gráficos  

Placeholder


## Pacotes necessários
## Carregar os Dados
## Visão Geral do `dadosMater.xlsx`
### Transformação e criação de variáveis
## Gráfico de Setores (Pizza)
### Gráfico de setores com o ggplot2
### Uma variação do gráfico de pizza: gráfico de rosca (*Donut chart*)
## Gráficos de Barras
### Gráfico de Barras Simples
### Gráfico de Barras Empilhadas
### Gráfico de Barras Lado a Lado
### Gráfico de Barras com Variáveis Discretas
### Gráfico de Barras Simples com o ggplot2
## Gráfico de Barra de Erro
### Exploração e Manipulação Arquivo `RNT.xlsx`
#### Resumos Numericos
#### Extrair Dois Subconjuntos de dados: meninos e meninas
#### Resumos Numéricos dos dois subgrupos
### Criação do Gráfico de Barra de Erro
## Gráfico de Barra de Erro com o `ggplot2`
### Construção do gráfico
### Gráfico com apenas as barras superiores
## Gráfico de Barra de Erro com a Função `lineplot.CI ()`
## Histograma
### Histograma Simples
### Histograma com curva normal sobreposta
### Componentes do Histograma
#### Construção de um histograma usando os componentes
### Histograma usando o `ggplot2`
### Histograma por grupos 
## Gráficos de Densidade
## Boxplot
### Boxplot com a função nativa 
### Estatísticas do boxplot
### Múltiplos boxplots
### Boxplots com `stripcharts`
### Boxplots horizontais
### Boxplot com o `ggplot2`
#### Boxplot único
#### Boxplot por grupos
## Gráfico de Dispersão (`Scatterplot`)  
### Mapeamento dos pontos de acordo com uma variável categórica
### Adição da reta de ajuste
### Gráfico de Dispersão com o `ggplot2`
## Leitura Adicional  

<!--chapter:end:10-graficos.Rmd-->


# Distribuição Normal

Placeholder


## Pacotes necessários
## Carregar o Banco de Dados
## Exploração e manipulação do banco de dados
### Resumo dos dados
#### Média e desvios padrão das populações
### Visualização dos dados através do histograma
#### População 1
#### População 2
## Distribuição normal
### Curva Normal Padronizada
#### Regra Empírica 68-95-99.7
## Exercício
## Leitura Adicional  

<!--chapter:end:11-distNormal.Rmd-->

# Estimação
## Pacotes necessários

```{r message=FALSE, warning=FALSE}
pacman::p_load(readxl, dplyr, ggplot2, Rmisc, DescTools)
```

Além desses pacotes, vamos usar uma função denominada `shadeform ()` que desenha uma curva normal com áreas sombreadas. Ela foi criada por [Tony Cookson](http://novicemetrics.blogspot.com/) e  pode ser encontrada [aqui](https://github.com/petronioliveira/Arquivos/blob/main/shadeform.R) para ser salva em seu diretório de trabalho. Ela deve ser ativada com a função `source ("caminho no diretório de trabalho")`. Por exemplo, no nosso computador o caminho é:

```{r}
source("C:/Users/petro/Dropbox/Git_repositório/Arquivos/shadeform.R")
```

## Carregar o dados

Serão usados dados do arquivo [dadosMater](https://github.com/petronioliveira/Arquivos/blob/main/dadosMater.xlsx) que devem ser baixados para o diretório de trabalho.

Crie um objeto `mater` para receber os dados, a partir do diretório de trabalho, executando:

```{r}
mater <- read_excel ("C:/Users/petro/Dropbox/Git_repositório/Arquivos/dadosMater.xlsx")
```

## Exploração e manipulação do banco de dados

Este banco de dados contém informações de 30 variáveis de 1368 nascimentos consecutivos, em um período de 18 meses, da Maternidade Escola do Hospital Geral de Caxias Sul (HGCS).  
Neste momento, usaremos apenas a variável `mater$altura`, altura das gestantes em metros.

```{r}
dados <- mater %>% select (altura)
glimpse (dados)
```

### Resumo dos dados

```{r}
summary(dados$altura)
```

```{r}
mu <- mean(mater$altura)
dp <- sd(mater$altura)
mu
dp
```

### Visualização gráfica 

```{r echo=TRUE}
hist(mater$altura,
     xlim = c (1.4, 1.85),
     main= NULL,
     freq = FALSE,
     ylab = "Densidade", 
     xlab = "Altura (m)",
     col = "salmon",
     las = 1)
box (bty = "L")

curve (dnorm (x, 
              mean=mu, 
              sd=dp), 
       col="red", 
       lty=1,
       lwd=2,
       add=TRUE)
```

Observamos que a variável altura tem uma distribuição simétrica com média = `r round(mean (dados$altura),3)`m e desvio padrão = `r round(sd (dados$altura), 3)`m, onde a altura mínima = `r min (dados$altura)`m e a máxima = `r max (dados$altura)`m.

## Distribuição Amostral

A principal preocupação da *inferência estatística* é com a qualidade das estimativas dos parâmetros. Procura responder a pergunta: "Quão certos estamos de que a média $\overline{x}$ está proxima da verdadeira média $\mu$. A compreensão deste conhecimento é a base da estatística.  

Vamos considerar, para fins didáticos, as 1368 mulheres como a **população-alvo** para qual queremos fazer inferência. Dessa forma, vamos extrair uma amostra de n = 30, dessa população, usando a função `sample ()`. 

```{r}
amostra1 <- sample (dados$altura, 30)
```

Se queremos estimar a média da população com base na `amostra1` , a maneira mais intuitiva de fazer isso é simplesmente calcular a média.

```{r}
mu1 <- mean(amostra1)
mu1

dp1 <- sd(amostra1)
dp1
```

A média da amostra $\overline{x}$ = `r round (mean(amostra1),3)` é chamada de **estimativa pontual** da média da população. Se pudermos escolher apenas um valor para estimar a média da população, essa é nossa melhor estimativa.  

Suponha que uma nova amostra de 30 gestantes seja selecionada e a média recalculada. Provavelmente, não obteremos exatamente a mesma resposta que obtivemos, usando o conjunto de dados `amostra1.` 

```{r}
amostra2 <- sample (dados$altura, 30)

mu2 <- mean(amostra2)
mu2
```

As estimativas geralmente variam de uma amostra para outra e, essa **variação amostral**, sugere que nossa estimativa pode ser próxima, mas não será exatamente igual ao parâmetro, $\mu$. O conjunto das possíveis médias amostrais de uma população constituem uma **distribuição amostral das médias**. 
Isto também é valido para as estimativas pontuais de outros parâmetros populacionais, como mediana, coeficiente de variação, desvio padrão, por exemplo.  

As estimativas geralmente não são exatamente iguais à verdade, mas ficam melhores à medida que mais dados se tornam disponíveis. Ou seja, a média de uma sequência de médias amostrais se aproxima da verdadeira média e a média de todas as possíveia médias é igual a média verdadeira.  

> <font size=2>A **distribuição amostral** representa a distribuição das estimativas pontuais com base em amostras de tamanho fixo de uma determinada população. É útil pensar em uma estimativa pontual específica como sendo extraída de tal distribuição. Compreender o conceito de uma distribuição amostral é fundamental para compreender a inferência estatística.</font>

## Erro Padrão

Suponha que se selecione uma quantidade grande de amostras dessa população de gestantes, por exemplo 5000 amostras. Somente podemos realizar isso porque temos disponível todo o conjunto de dados da população, definido, para fins didático, como sendo as alturas das 1368 gestantes. Na prática, isto é muito difícil de acontecer pela quase impossibilidade de se analisar toda a população.  

Se fizermos isso, podemos construir uma distribuição amostral para a média da amostra quando o tamanho da amostra é 30, mostrado na Figura.

```{r echo=FALSE}
amostra30 <- rep (0, 5000)
for (i in 1:5000) {
  amostra <- sample (dados$altura, 30)
  amostra30 [i] <- mean (amostra)
}

hist(amostra30,
     breaks=20,
     col = "springgreen",  
     border = "black",
     main = "Distribuição de 5000 amostras - n = 30",
     xlab = "Altura (m)",
     ylab = "Frequência",
     #xlim = c (1.56, 1.65),
     ylim = c (0, 900),
     cex.lab = 1.2,
     cex.axis = 1.2,
     las = 1)
abline (v = round(mean(dados$altura), 3), col = "red", lwd = 2, lty = 2)
box(bty = "L")
```

A distribuição amostral exibida é unimodal e praticamente simétrica. Também está centrada exatamente na média real da população: $\mu$ = `r round(mean(dados$altura), 3)`, linha vertical vermelha. Isso faz sentido. As médias da amostra devem tender a "cair em torno" da média da população.  

Podemos ver que as médias amostrais possuem alguma variabilidade em torno da média da população, que pode ser quantificada usando o desvio padrão desta distribuição de médias amostrais: $\sigma_\overline{x}$= `r round(sd(amostra30), 3)`. O desvio padrão das médias amostrais nos diz o quão longe a estimativa típica está da média real da população, 1,598 m. Também descreve o erro típico da estimativa pontual e, por esse motivo, costumamos chamar esse desvio padrão de **erro padrão (EP)** da estimativa.

> <font size=2>O desvio padrão associado às estimativas é chamado de **erro padrão**. Descreve o erro ou incerteza típica associada à estimativa. Está associado à **precisão** com que estimamos o parâmetro da população.</font>

 
No exemplo que estamos trabalhando, conhecemos o desvio padrão da população, ($\sigma$ = `r round(sd(dados$altura), 3)`). Matematicamente, o erro padrão é calculado, usando a fórmula

$$
\sigma_\overline{x}=\frac{\sigma}{\sqrt{n}}=\frac{0,065}{\sqrt{30}}=0.012
$$

O **desvio padrão da população é tipicamente desconhecido**. Ao considerar o caso da estimativa pontual $\overline{x}$, há um problema: não há como estimar o erro padrão a partir de uma única amostra. No entanto, a teoria estatística, usando o teorema do limite central, fornece uma solução para esse problema. A estimativa pontual tende a ser suficientemente boa quando o tamanho da amostra é de pelo menos 30 e a distribuição da população não é fortemente assimétrica.   
Assim, geralmente, usamos apenas o desvio padrão da amostra, $s$, em vez de $\sigma$. Quando o tamanho da amostra for menor que 30, precisaremos usar um método para contabilizar a incerteza extra no erro padrão (ver adiante).   
Usando o desvio padrão, $s$, da amostra no lugar do desvio padrão, $\sigma$, da população, a equação acima, fica assim:


$$
EP_\overline{x}=\frac{s}{\sqrt{n}}
$$

## Intervalo de Confiança com Desvio Padrão Populacional Conhecido

Vimos que fornecer uma estimativa pontual para um parâmetro populacional, como a média, raramente é uma medida exata, perfeita. Logo, a atitude lógica é fornecer uma faixa plausível de valores para o parâmetro populacional.  

Este intervalo de valores plausíveis para o parâmetro da população é chamado de **intervalo de confiança**. De acordo com a interessante imagem do *OpenIntro Statistics* (2015), usar apenas uma estimativa pontual é como pescar em um lago turvo com uma lança e usar um intervalo de confiança é como pescar com uma rede. Ou seja, se usarmos apenas uma estimativa pontual, provavelmente, não atingiremos o parâmetro populacional, entretanto, se usarmos uma gama de valores - um intervalo de confiança - aumentamos a probabilidade de incluirmos o parâmetro.

A estimativa pontual é o mais provável valor do parâmetro e, portanto, faz sentido construir um intervalo ao redor desta estimativa. O erro padrão, que é uma medida da incerteza associada à estimativa pontual, fornece uma orientação para a magnitude do intervalo de confiança.  

O erro padrão representa o desvio padrão associado à estimativa e, aproximadamente, 95% das vezes, a estimativa estará dentro de 2 erros padrão do parâmetro. Se o intervalo tiver um tamanho $\pm$ 2 erros padrão da estimativa pontual, podemos ter cerca de 95% de certeza de que o parâmetro verdadeiro estará incluido nele:

$$
estimativa\ pontual\pm 2\times EP 
$$
Este valor de $\pm2\times EP$ é denominado de **margem de erro (me)** e é um valor aproximado. No modelo normal, podemos tornar isso mais preciso usando `r round(qnorm(0.975),2)` no lugar de 2. 
 
$$
estimativa\ pontual\pm 1,96\times EP 
$$

### Interpretação do Intervalo de Confiança

Qual o significado de *95% de confiança*? Para compreender isso, vamos selecionar 20 amostras de n = 30 da população de mulheres e calcular, para cada amostra, a média da `altura` e o seu intervalo de confiança de 95%. Então, 95% dos intervalos devem conter a média populacional, $\mu$. Em outras palavras, das 20 amostras que selecionamos, aleatoriamente, existe probabilidade de que uma delas (5%) não contenha a média da população, linha vermelha horizontal, na figura.

```{r echo=FALSE}
ic <- read_excel ("C:/Users/petro/Dropbox/Git_repositório/Arquivos/dadosIC.xlsx")
ic <- ic %>% select(x, y, linf, lsup)
```

```{r echo=FALSE}
ggplot(ic, aes(x, y)) +   
  geom_point() +
  geom_errorbar(aes(ymin = linf, ymax = lsup)) +
  geom_hline(yintercept=1.598, color = "red") +
  theme_classic() +
  ylab("Altura (m)") +
  xlab ("Nº de Amostras")
```

A média dessas médias amostrais é igual `r round(mean(ic$y), 3)`m, a mesma média da população `r round(mean(dados$altura), 3)`m, com arredondamento até a terceira casa decimal, um erro da ordem de milimetros na altura. 

> <font size=2> OBSERVAÇÃO: Havendo curiosidade, o banco de dados usado, nestes cálculos e construção do gráfico acima, encontra-se [aqui](https://github.com/petronioliveira/Arquivos/blob/main/dadosIC.xlsx). Onde *x* são as amostras, *y* é a média de cada amostra e *linf* e *lsup* sãos os limites inferior e superior dos intervalos de confiança de cada amostra, respectivamente.</font>

### Exercício 1

Extraia amostras de n = 30, 50, 100 e 1000 da população de gestantes, usada anteriormente, e calcule a média e o $IC_{95\%}$ para cada amostra e interprete os resutados.

#### Solução

**Amostra A - n = 30**
```{r}
amostra_A <- sample(dados$altura, 30)
mu_A <- mean (amostra_A)
mu_A
dp_A <- sd (amostra_A)
EP_A <- dp_A/sqrt(30)
alpha <- 0.05                         # Nível de significância
zc <- qnorm (1 - (alpha/2))           # z crítico
me_A <- zc * EP_A

linf_A <- mu_A - me_A 
lsup_A <- mu_A + me_A
ic_A <- c(linf_A, linf_B)
ic_A
```

**Amostra B - n = 50**
```{r}
amostra_B <- sample(dados$altura, 50)
mu_B <- mean (amostra_B)
mu_B
dp_B <- sd (amostra_B)
EP_B <- dp_B/sqrt(50)
alpha <- 0.05                         # Nível de significância
zc <- qnorm (1 - (alpha/2))           # z crítico
me_B <- zc * EP_B

ic_B <- c((mu_B - me_B), (mu_B + me_B))
ic_B
```

**Amostra C - n = 100**
```{r}
amostra_C <- sample(dados$altura, 100)
mu_C <- mean (amostra_C)
mu_C
dp_C <- sd (amostra_C)
EP_C <- dp_C/sqrt(100)
alpha <- 0.05                         # Nível de significância
zc <- qnorm (1 - (alpha/2))           # z crítico
me_C <- zc * EP_C

ic_C <- c((mu_C - me_C), (mu_C + me_C))
ic_C
```

**Amostra D - n = 1000**
```{r}
amostra_D <- sample(dados$altura, 1000)
mu_D <- mean (amostra_D)
mu_D
dp_D <- sd (amostra_D)
EP_D <- dp_D/sqrt(1000)
alpha <- 0.05                         # Nível de significância
zc <- qnorm (1 - (alpha/2))           # z crítico
me_D <- zc * EP_D

ic_D <- c((mu_D - me_D), (mu_D + me_D))
ic_D
```
**Gráfico**  

*[1ª Etapa](anchor)*: Criar um dataframe com as médias e os limites inferiores e superiores de cada amostra:

```{r}
x <- c("A_30", "B_50", "C_100", "D_1000")
y <- c(1.611333, 1.6004, 1.593, 1.59726)
linf <- c(1.590096, 1.582861, 1.5816, 1.593206)
lsup <- c(1.632571, 1.617939, 1.6044, 1.601314)

df <- data.frame(x, y, linf, lsup)
```

*[2ª Etapa](anchor)*: Criar o gráfico:

```{r}
ggplot(df, aes(x, y)) +   
  geom_point(size = 4) +
  geom_errorbar(aes(ymin = linf, ymax = lsup), width = 0.2) +
  geom_hline(yintercept=1.598, color = "red", linetype = "dashed", size = 1) +
  theme_classic() +
  ylab("Altura (m)") +
  xlab ("Amostras")+
  coord_flip()
```

**Interpretação**

O gráfico mostra, claramente, que à medida que o tamanho amostral aumenta, diminui o intervalo de confiança, tornando as estimativas mais precisas.

### Outros Intervalos de Confiança

É possível considerar intervalos de confiança em que o nível de confiança é um pouco superior a 95%, por exemplo 99%. Pense novamente na analogia de tentar pegar um peixe: se quisermos ter mais certeza de que vamos pegar o peixe, devemos usar uma rede mais larga. Portanto, para criar um nível de confiança de 99%, também devemos ampliar nosso intervalo de 95%.  
Por outro lado, se quisermos um intervalo com menor confiança, como 90%, precisamos tornar nosso intervalo original de 95% um pouco mais estreito.

A estrutura do intervalo de confiança de 95%, visto anteriormente é igual a:

$$
estimativa\ pontual\pm 1,96\times EP 
$$
Como vemos o intervalo de confiança é determinado pela margem de erro (me) e esta é dependente do valor crítico de z que é igual a 1,96 quando o nível de confiança é 95%.  
Para outros níveis de confiança, o $z_{crítico}$ se modifica de acordo o modelo normal e pode ser verificado no **R** com a função `qnorm ()`:

> <font size=2> * Nível de confiança 99%: $z_{crítico}$ = `r round(qnorm(0.995),2)`    
* Nível de confiança 90%: $z_{crítico}$ = `r round(qnorm(0.95),2)`</font>
 
Dessa forma, a probabilidade de Z estar entre -1,64 e +1,64 é de 90%, entre -1,96 e +1,96 é de 95% e entre -2,58 e +2,58 é de 99%. Observa-se que à medida que se aumenta o nível de confiança o aumento o intervalo entre os limite inferior e superior.

### Exercício 2
 Use a amostra A do exercício 1 e calcules o intervalo de confiança de de 90 e 99%. Compare os resultados.
 
#### Solução

**$IC_{99\%}$**

```{r}
alpha <- 0.01                         # Nível de significância
zc <- qnorm (1 - (alpha/2))           # z crítico
```


```{r}
me_A2 <- zc * EP_A

ic_A2 <- c((mu_A - me_A2), (mu_A + me_A2))
ic_A2
```

**$IC_{90\%}$**

```{r}
alpha <- 0.10                         # Nível de significância
zc <- qnorm (1 - (alpha/2))           # z crítico
me_A3 <- zc * EP_A

ic_A3 <- c((mu_A - me_A3), (mu_A + me_A3))
ic_A3
``` 

**Interpretação**

Repetindo a intervalo de confiança de 95% para comparar:

```{r}
ic_A
```

Observamos que os intervalos aumentam progressivamente com o aumento da confiança. Veja os gráficos abaixo, criados com a função `shadeform ()`, carregada no início do capítulo.

```{r echo=TRUE}
par(mfrow = c(1, 3))

shadenorm(outside = c(1.64, -1.64), color = "steelblue")
abline (h = 0)
text(0, 0.1, "90%", cex = 1.5, col = "black")

shadenorm(outside = c(1.96, -1.96), color = "steelblue")
abline (h = 0)
text(0, 0.1, "95%", cex = 1.5, col = "black")

shadenorm(outside = c(2.58, -2.58), color = "steelblue")
abline (h = 0)
text(0, 0.1, "99%", cex = 1.5, col = "black")

par(mfrow = c(1,1))
```

## Intervalo de Confiança com Desvio Padrão Populacional Desconhecido

Com amostras pequenas, usar o modelo normal para construir intervalos de confiança, gera um erro, pois os pressupostos do teorema do limite central não são respeitados. 
Quando o desvio padrão populacional, $\sigma$, é desconhecido e o tamanho amostral é pequeno (< 30), a estimação da média populacional é feita usando a distribuição *t*.  

### Distribuição *t*  

A distribuição *t*, desenvolvida por *William Sealy Gosset*, em 1908, é semelhante à distribuição normal. Como a curva de distribuição normal, a curva de distribuição *t* é unimodal, simétrica (em forma de sino) em torno da média e nunca encontra o eixo horizontal. A área total sob uma curva de distribuição *t* é 1 ou 100%. A curva da distribuição *t* é mais plana do que a curva de distribuição normal padrão. Em outras palavras, ela é mais achatada e mais espalhada. No entanto, conforme o tamanho da amostra aumenta, a distribuição *t* aproxima-se da distribuição normal padrão.  

O formato de uma curva de distribuição *t* particular depende do número de graus de liberdade. O número de graus de liberdade (*gl*) para uma distribuição *t* é igual ao tamanho da amostra menos um, ou seja, $gl=n-1$.  

O número de graus de liberdade é o único parâmetro da distribuição *t*. Há uma diferente distribuição *t* para cada número de graus de liberdade, portanto, a distribuição *t* se constitui em uma família de distribuições.  

```{r echo=FALSE}
x <- seq(-4, 4, length=100)
hx <- dnorm(x)

gl <- c(1, 3, 8, 30)
cores <- c("red", "blue", "darkgreen", "gold", "black")
rotulos <- c("gl=1", "gl=3", "gl=8", "gl=30", "normal")

plot(x, hx, type="l", lty=2, xlab="X",
     ylab="Densidade", main="")

for (i in 1:4){
  lines(x, dt(x,gl[i]), lwd=2, col=cores[i])
}

legend("topright", inset=.05, title="Distribuições",
       rotulos, lwd=2, lty=c(1, 1, 1, 1, 2), col=cores)
```

Como a distribuição normal padrão, a média da distribuição padrão *t* é 0. Entretanto, diferente da distribuição normal padrão, cujo desvio padrão é 1, o desvio padrão de uma distribuição *t* é $\sqrt gl⁄(gl-2)$ , para gl > 2, que sempre é maior do que 1. Assim, o desvio padrão de uma distribuição *t* é maior do que o desvio padrão da distribuição normal padrão.  
Os valores de $t_{crítico}$ podem ser obtidos usando a função `qt ()` que usa os seguintes argumentos:

Argumento | Significado
:--- | :-----------
p | probabilidade, igual a $1-\alpha/2$, considerando-se bicaudal e $1-\alpha$ quando unicaudal;
df | graus de liberdade;
lower.tail | lógico; se [TRUE](anchor), informa a probabilidade da cauda inferior. O padrão é [TRUE](anchor).
     |

Assim, o valor do $t_{crítico}$ para $gl=10$ é:

```{r}
qt(0.975, 10, lower.tail = TRUE)
```

Dessa forma, a área compreendida entre $t=\pm 2,23$ é igual a 95%:

$$
p(-2,23\le t\le 2,23)=0,95
$$
```{r echo=FALSE}
# 1º Gráfico
x <- seq (-4, 4, length = 1000)
y <- dnorm(x)
plot(x, y, axes = FALSE, type = 'l', xlab = '',
     ylab = '',main = "")
abline(h = 0)
abline (v = 0, col = 2, lty ="dashed")
x1 <- x[x >= 2.23]
y1 <- dnorm(x1)
x2 <- c(4, x1, x1[length(x1)], 4)
y2 <- c(0,0, y1, 0)
polygon(x2, y2, col = "lightblue2")

x3 <- x[x <= -2.23]
y3 <- dnorm(x3)
x4 <- c(-4, x3, x3[length(x3)], -4)
y4 <- c(0,y3, 0, 0)
polygon(x4, y4, col = "lightblue2")

axis(1, at = c(-2.23, 0, 2.23), font = 10, labels = c("-2.23", "0", "2.23"))
text(0, 0.1, cex = 1.0, col = "black",expression(italic(0.95)))
text(3, 0.04, cex = 1.0, col = "black",expression(italic(0.025)))
text(-3, 0.04, cex = 1.0, col = "black",expression(italic(0.025)))
```

Quando se considera apenas uma das caudas (unicaudal ou unilateral), o valor do $t_{crítico}$ para $gl=10$ é

```{r}
qt(0.95, 10, lower.tail = TRUE)
```

Assim, a área $t \le 1,81$ é igual a 95%

$$
p(t\le 1,81)=0,95
$$

```{r echo=FALSE}
x <- seq (-4, 4, length = 1000)
y <- dnorm(x)
plot(x, y, axes = FALSE, type = 'l', xlab = '',
     ylab = '',main = "")
abline(h = 0)
abline (v = 0, col = 2, lty ="dashed")
x1 <- x[x >= 1.81]
y1 <- dnorm(x1)
x2 <- c(4, x1, x1[length(x1)], 4)
y2 <- c(0,0, y1, 0)
polygon(x2, y2, col = "lightblue2")

axis(1, at = c(-5, 0, 1.81), font = 10, labels = c("","0", "1.81"))
text(0, 0.1, cex = 1.0, col = "black",expression(italic(0.95)))
text(3, 0.04, cex = 1.0, col = "black",expression(italic(0.05)))
```


### Dados para o cálculo do intervalo de confiança

Vamos continuar com o banco de dados das altursa de 1368 gestantes, que consideramos a nossa população. Agora iremos trabalhar com uma amostra de 30 mulheres e fazer inferência para essa população, supondo que os parâmetros dessa população sejam desconhecidos.

```{r}
set.seed(123)
amostra <- sample (dados$altura, 30)
```

Se queremos estimar a média da população com base na amostra, a maneira mais intuitiva de fazer isso é, simplesmente, calcular a média e o desvio padrão da amostra.

```{r}
mu <- mean(amostra)
mu
dp <- sd(amostra)
dp
```

Para termos maior precisão, vamos calcular os intervalos de confiança para esta estimativa, usando a distribuição *t*.

### Cálculo do Intervalo de Confiança com $\sigma$ desconhecido

#### Cálculo manual

Temos uma amostra de $n = 30$,  $\overline x = `r round(mean (amostra), 3)`$ e 
$s = `r round(sd (amostra), 3)`$. Vamos calcular os outros dados para obter o intervalo de confiança, usando uma distribuição *t* bicaudal e um nível de significância $\alpha = 0.05$: 

```{r}
n <-  30
alpha <- 0.05
p <- 1 - alpha/2
p
gl <- n - 1
gl
tc <-  qt(p, gl, lower.tail = TRUE)
tc
EP <- round(dp/sqrt(n),3)
EP
```

Onde *p* é a probabilidade decorrente do nível de significância, *gl* são os graus de liberdade e *EP* é o erro padrão. 
Com dados necessátios, podemos calcular o intervalo de confiança de 95%:

```{r}
ic <- c((mu - tc * EP), (mu + tc * EP))
round (ic,2)
```
Ou seja, temos uma confiança 95% de que a média populacional desconhecida se encontra entre `r round(mu - tc * EP,2)` m e `r round(mu + tc * EP,2)` m.

#### Cálculo usando uma função do R

O **R** possui algumas funções que calculam o intervalo de confiança para variáveis numéricas, baseadas na distribuição *t*. Entre elas, a função `CI (x, ci = 0.95)`, incluída no pacote `Rmisc`:

```{r}
ic <- CI (amostra, ci = 0.95)
round(ic, 2)
```

## Intervalo de Confiança para uma proporção populacional

Com frequência , necessitanos estimar uma proporção populacional. Como não é possível realizar um censo cada vez que se necessita encontrar o valor de uma proporção da população, normalmente se obtém resultados de pesquisas por amostragem. Portanto, para levar em conta a variabilidade nos resultados obtidos em diferentes pesquisas por amostragem, precisamos conhecer os procedimentos para estimar uma proporção da população

### Dados para estimar a proporção populacional

Vamos usar uma amostra aleatória de n = 60 da variável mater$fumo para estimar a proporção de mulheres fumantes.

```{r}
set.seed(123)
fumo <- sample (mater$fumo, 60)
glimpse (fumo)
```

A função `glimpse ()` nos mostra que temos 60 observações da variável `fumo` e que a mesma é do tipo numérica (*db *l), 1 = sim e 2 = não, fumante e não fumante, respectivamente. Portanto, ela é uma variável categórica e deve ser transformada para fator.

```{r}
fumo <- factor (fumo, 
                ordered=TRUE, 
                levels = c (1,2), 
                label = c ("sim", "não"))
```

### Cálculo da estimativa pontual da proporção 

Nesta amostra, a proporção de fumantes é:

```{r}
tab <- table(fumo)
tab
tabFumo <- round (prop.table (tab), 3)
tabFumo
```

### Cálculo do intervalo de confiança para a proporção

#### Cálculo Manual com Aproximação Normal

**1ª etapa**: verificar a premissa de que quando a proporção populacional é desconhecida a proporção pontual ($\hat p$) e o seu complemento ($\hat q = 1 - \hat p$) multiplicados, cada um, por $n$, devem ser maior do que 5.

```{r}
n <- 60
(tabFumo) * n
```

Ambos valores são maiores do que 5. Vamos adiante!

**2ª Etapa**: O intervalo pode ser estimado pela distribuição normal. O $z_{crítico}$ é calculado:

```{r}
alpha <- 0.05
p <-  1 - alpha/2
zc <- qnorm (p, mean = 0, sd = 1)
zc <- round(zc, 2)
zc
```

**3ª Etapa**: Cálculo do erro padrão da proporção ($\sqrt \frac {\hat p \times \hat q}{n}$) e da margem de erro:

```{r}
prop <- tabFumo [1]
EP <- sqrt((prop * (1 - prop))/n)
me <- zc * EP
me
```

**4ª Etapa**: Intervalo de confiança

```{r}
ic_prop <- c((prop - me), (prop + me))
round(ic_prop, 3)
```

#### Cálculo usando uma função do R

O chamado *Intervalo de Confiança Exato* corrigem as deficiências da aproximaçãonormal. O R tem uma função para este cálculo: `BinomCI ()` do pacote `DescTools.` É preferível usar o método de Clopper e Pearson que fornece o IC exato.  
Os argumentos da função `BinomCI` são:

Argumento | Significado
:--- | :-----------
x | é o número de desfechos, sucessos;
n | é o tamanho da amostra, número de ensaios;
p | probabilidade, hipótese nula; se ignorada o padrão é 0,50;
conf.level | nível de confiança, o padrão é 0.95;
method | possui vários métodos para calcular intervalos de confiança para uma proporção binomial como: “clopper-pearson” (exact interval), "wilson", "wald", "agresti-coull", "jeffreys", "modified wilson", "modified jeffreys", "arcsine", "logit", "witting", "pratt". O método padrão é o de “wilson”. Qualquer outro método, há necessidade de solicitar;
sides |  hipótese alternativa padrão “two.sided” (bilateral), mas pode ser “right” ou “left” (unilateral a direita ou a esquerda, respectivamente).
     |
     
```{r}
IC <- BinomCI (tab[1], n, 
               conf.level = 0.95, 
               method = "clopper-pearson")
round(IC, 3)
```

Observe que existe uma pequena diferença entre os valores da aproximação normal e o exato, com método de “clopper-pearson”.

## Leitura Adicional  

1. <https://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/07%3A_Estimation>

2. Daniel WD, Cross CL. Biostatistics: A Foundation for Analysis in the Health Sciences. Tenth Edition. Hoboken, NJ: Wiley; 2013.Estimation; p. 161-213.

3. Oliveira Filho PF. **Epidemiologia e Bioestatística: fundamentos para a leitura crítica**. 2ª ed. Rio de Janeiro: Editora Rubio Ltda; 2022. Intervalo de Confiança e Valor P;p.123-133.

4. Diez DM, Barr CD, Çetinkaya-Rundel M. **OpenIntro Statistics**. Third Edition. Victoria, British Columbia: OpenIntro; 2015. Foudations for Inference; p. 168-218.

</br>

</br>

<!--chapter:end:12-estimacao.Rmd-->

